<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/di-blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/di-blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/di-blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/di-blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/di-blog/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jokerdii.github.io","root":"/di-blog/","images":"/di-blog/images","scheme":"Muse","darkmode":true,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/di-blog/js/config.js"></script>

    <meta name="description" content="Substack  the more the AV competition globally heats up, and the more large players invest in the technology, including Tesla, the higher the demand for the Uber platform will become for these AV play">
<meta property="og:type" content="article">
<meta property="og:title" content="2024 December - What I Have Read">
<meta property="og:url" content="https://jokerdii.github.io/di-blog/2024/12/01/2024-December/index.html">
<meta property="og:site_name" content="Di&#39;s Blog">
<meta property="og:description" content="Substack  the more the AV competition globally heats up, and the more large players invest in the technology, including Tesla, the higher the demand for the Uber platform will become for these AV play">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jokerdii.github.io/di-blog/2024/12/01/2024-December/agentforce.jpeg">
<meta property="og:image" content="https://jokerdii.github.io/di-blog/2024/12/01/2024-December/genai_impact_on_workers.png">
<meta property="og:image" content="https://jokerdii.github.io/di-blog/2024/12/01/2024-December/mitigate_halluciation.png">
<meta property="og:image" content="https://jokerdii.github.io/di-blog/2024/12/01/2024-December/a16z_ideas_in_tech_2025.png">
<meta property="og:image" content="https://jokerdii.github.io/di-blog/2024/12/01/2024-December/openai_o3_comparison.png">
<meta property="article:published_time" content="2024-12-02T02:54:34.000Z">
<meta property="article:modified_time" content="2024-12-02T02:54:34.000Z">
<meta property="article:author" content="Di Zhen">
<meta property="article:tag" content="readings">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jokerdii.github.io/di-blog/2024/12/01/2024-December/agentforce.jpeg">


<link rel="canonical" href="https://jokerdii.github.io/di-blog/2024/12/01/2024-December/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jokerdii.github.io/di-blog/2024/12/01/2024-December/","path":"2024/12/01/2024-December/","title":"2024 December - What I Have Read"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>2024 December - What I Have Read | Di's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/di-blog/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/di-blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Di's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#substack"><span class="nav-number">1.</span> <span class="nav-text">Substack</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#articles-and-blogs"><span class="nav-number">2.</span> <span class="nav-text">Articles and Blogs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#papers-and-reports"><span class="nav-number">3.</span> <span class="nav-text">Papers and Reports</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#youtube-and-podcasts"><span class="nav-number">4.</span> <span class="nav-text">YouTube and Podcasts</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#news"><span class="nav-number">5.</span> <span class="nav-text">News</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Di Zhen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/di-blog/archives/">
          <span class="site-state-item-count">44</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/di-blog/2024/12/01/2024-December/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/di-blog/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="2024 December - What I Have Read | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          2024 December - What I Have Read
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2024-12-01 21:54:34" itemprop="dateCreated datePublished" datetime="2024-12-01T21:54:34-05:00">2024-12-01</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h3 id="substack">Substack</h3>
<blockquote>
<p><em>the more the AV competition globally heats up, and the more large
players invest in the technology, including Tesla, the higher the demand
for the Uber platform will become for these AV players.</em></p>
<p><strong>― Uber Technologies – A brilliant business executing to
perfection (Quarterly Update) - Rijnberk InvestInsights</strong> [<a
target="_blank" rel="noopener" href="https://rijnberkinvestinsights.substack.com/p/uber-technologies-a-brilliant-business">Link</a>]</p>
</blockquote>
<p>This article predicts Uber to be a massive beneficiary of the AV /
Robotaxi revolution. There indeed is a moat.</p>
<blockquote>
<p><strong>Where do LLMs spend their FLOPS? - Artificial
Fintelligence</strong> [<a
target="_blank" rel="noopener" href="https://www.artfintel.com/p/where-do-llms-spend-their-flops">Link</a>]</p>
</blockquote>
<p><strong>Theoretical Analysis of LLM FLOPS Allocation</strong></p>
<ul>
<li><p><strong>FLOPS Distribution in Decoder Models:</strong></p>
<ul>
<li><p>Based on a standard decoder model, FLOPS are allocated as follows
for each layer:</p>
<p>6d² for computing Query (Q), Key (K), and Value (V) matrices.</p>
<p>2d² for computing the attention output matrix, using the formula:
softmax(Q @ K.T) @ V.</p>
<p>16d² for running the feedforward network (FFN).</p>
<p>This results in a total of 24d² FLOPS per layer.</p></li>
<li><p><strong>Percentage-wise:</strong></p>
<p>25% of the time is spent computing QKV.</p>
<p>~8% is spent computing the attention output matrix.</p>
<p>~66% is spent running the FFN.</p></li>
</ul></li>
<li><p><strong>Attention Mechanism:</strong></p>
<p>While the attention equation itself <span
class="math inline">\(softmax(QK^T/\sqrt{d_{head}})V\)</span> has
negligible computational cost (~0.005% for Llama7B) compared to other
operations, its impact on memory usage necessitates techniques like
<strong>KV cache</strong> and <strong>flash attention</strong>.</p></li>
<li><p><strong>KV Cache:</strong></p>
<p>The KV cache, essential for efficient attention computation, requires
O(T) memory, where T is the number of tokens generated.</p>
<p>The memory size of the KV cache is calculated as 4 * number of layers
* d_model bytes.</p>
<p>While the KV cache demands a significant amount of memory, it
essentially reuses the same memory space throughout the token generation
process.</p></li>
<li><p><strong>Modern Architectures:</strong></p>
<p>Architectures like Mistral 7B and Llama2 employ <strong>Grouped Query
Attention (GQA)</strong> and <strong>sliding window attention</strong>
to optimize performance.</p>
<p><strong>GQA</strong> reduces the KV cache size by sharing the KV
projection across multiple heads. This leads to a linear decrease in
memory consumption as the number of KV heads decreases.</p>
<p><strong>Sliding window attention</strong> limits the KV cache size to
the window size (e.g., 4096 for Llama7B), further controlling memory
usage.</p></li>
</ul>
<p><strong>Performance-Motivated Architectural Changes</strong></p>
<ul>
<li><p><strong>Impact of Model Width and Depth:</strong></p>
<p>Increasing the <strong>number of layers</strong> linearly scales both
the FLOPS and the number of parameters.</p>
<p>Increasing the <strong>model width</strong> (d_model) quadratically
scales the number of parameters and, consequently, the compute
requirements.</p>
<p>This is because weight matrices within layers have a size of
(d_model, d_model), leading to a quadratic relationship between model
width and parameters.</p></li>
<li><p><strong>Balancing Latency and Parallelization:</strong></p>
<p>Wider models parallelize better due to the ease of splitting layers
across multiple GPUs using tensor parallelism.</p>
<p>Deeper models require sequential computation of layers, hindering
parallelization, especially during training.</p>
<p>Therefore, <strong>wider models are preferred when low latency is
critical.</strong></p></li>
</ul>
<p><strong>Empirical Analysis of LLM Performance</strong></p>
<p>The article investigates the memory usage of the KV cache in LLMs,
specifically Llama2. The author observes that <strong>the actual memory
consumed by the model is higher than what the theoretical calculations
suggest</strong>. Here's how the discrepancy is highlighted:</p>
<ul>
<li><strong>Theoretical Calculation:</strong> The formula for
calculating the KV cache memory requirement per token is
<code>4 * number of layers * d_model</code> bytes. In the experiment,
the Llama2 model used has <code>d_model</code> of 1024 and 8 hidden
layers. This means it theoretically needs 32KB of memory per token (4 *
8 * 1024 bytes = 32KB).</li>
<li><strong>Expected Memory Usage:</strong> For generating 20 tokens,
the model should ideally use 640KB of memory (32KB/token * 20 tokens =
640KB).</li>
<li><strong>Observed Memory Usage:</strong> However, the empirical
analysis revealed that the model's memory consumption jumped by ~2.1MB
every 20 tokens. This is significantly higher than the expected
640KB.</li>
</ul>
<p>The author concludes that <strong>this discrepancy of about 3x
suggests an inefficient implementation of the KV cache in the model
being used</strong>. The extra overhead could stem from various factors
not accounted for in the theoretical calculation, and further
investigation would be needed to pinpoint the exact cause.</p>
<blockquote>
<p><strong>Transformer inference tricks - Artificial
Fintelligence</strong> [<a
target="_blank" rel="noopener" href="https://www.artfintel.com/p/transformer-inference-tricks">Link</a>]</p>
</blockquote>
<p><strong>KV Cache</strong></p>
<ul>
<li>The KV cache is a crucial optimization for decoder models,
significantly reducing computation. It exploits the fact that keys and
values remain constant for the prompt and each decoded token in
subsequent iterations. By caching these values, the computational
complexity of sampling becomes linear instead of quadratic, enabling
decent performance with longer contexts.</li>
<li>However, it introduces state management complexity, as inference
needs to continue for all sequences even if some are completed. The KV
cache demands significant memory, proportional to the number of layers,
heads, and the embedding dimension. For instance, GPT-3 with 96 layers,
96 heads, and a dimension of 128 requires 2.4M parameters per token,
translating to 10GB of memory for a 2048 token context window. This
memory requirement is a major challenge for consumer-grade GPUs with
limited HBM, like the 4090.</li>
</ul>
<p><strong>Speculative Decoding</strong></p>
<ul>
<li>Speculative decoding leverages excess compute capacity, particularly
in local inference settings. It utilizes two models: a small, fast
“draft” model and a large, slow model. The smaller model quickly makes
multiple inferences, guessing the large model’s predictions, while the
larger model verifies these guesses in parallel. This effectively
reduces the sequential cost of generating a sequence to that of the
smaller model.</li>
<li>However, it requires training and storing both models, and
performance is limited by the smaller model’s prediction accuracy.
HuggingFace reports a typical doubling of decoding rate using this
technique.</li>
<li>Newer techniques like <strong>Jacobi decoding</strong> and
<strong>lookahead decoding</strong> aim to improve upon speculative
decoding by generating n-grams and recursively matching them,
potentially achieving latency improvements without requiring a draft
model.</li>
</ul>
<p><strong>Effective Sparsity</strong></p>
<ul>
<li><strong>Sparsity</strong> in transformer activations arises from the
softmax operation in the attention mechanism and ReLU activations in
MLPs, leading to many zero values. Utilizing this sparsity can be
challenging, with limited support in mainstream tensor programs.</li>
<li>One optimization involves skipping computations for zero
activations, feasible in custom implementations like Llama.cpp. However,
the effectiveness of this approach diminishes exponentially with batch
size due to the random distribution of sparsity across tokens.</li>
<li>Therefore, leveraging sparsity is most effective for batch size 1,
although speculative decoding might be more beneficial in such
scenarios.</li>
</ul>
<p><strong>Quantization</strong></p>
<ul>
<li><strong>Quantization</strong> reduces the precision of model weights
and activations, potentially saving memory and increasing inference
speed. Research suggests that quantization to 4 bits or more results in
negligible performance degradation. The <em>k</em>-bit inference scaling
laws paper demonstrates that reducing precision allows for using a
larger model with the same memory footprint and potentially achieving
better performance.</li>
<li>However, using lower precision formats may lack native support in
hardware and could be unstable in production environments.
<strong>FP8</strong> offers a good balance between performance and
support, being the lowest precision format natively supported by modern
accelerators. <strong>Int8</strong> is another option, easier to
implement with tools like PyTorch, though it lacks the performance
advantages of FP8.</li>
<li>Libraries like <strong>bitsandbytes</strong> facilitate
quantization, offering tools and APIs for implementation.</li>
</ul>
<blockquote>
<p><strong>Top 10 China's AI Stories in 2024: A Year-End Review - Recode
China AI</strong> [<a
target="_blank" rel="noopener" href="https://recodechinaai.substack.com/p/top-10-chinas-ai-stories-in-2024">Link</a>]</p>
</blockquote>
<p>China's AI landscape is rapidly catching up to the US, with multiple
models now reaching similar performance benchmarks as GPT-4 and
advancements in areas like video generation, robotics, and autonomous
driving.</p>
<p>Several AI-powered apps have emerged in China, with ByteDance's
<strong>Doubao</strong> leading in popularity domestically and MiniMax's
<strong>Talkie</strong> gaining traction internationally, though China
has yet to produce a "killer app" with at least 100 million daily active
users.</p>
<p>A number of Chinese AI startups have emerged since ChatGPT's debut,
backed by significant capital, but they now face strong competition from
tech giants.</p>
<p>Chinese open-source LLMs have made substantial global progress, with
Alibaba’s <strong>Qwen</strong> series being the most downloaded on
Hugging Face.</p>
<p>Chinese AI video generators have surged ahead due to the delayed
release of Sora, with platforms like Kuaishou’s <strong>Kling</strong>
and MiniMax’s <strong>Hailuo</strong> offering competitive features.</p>
<p>An LLM API price war has been ignited by major Chinese tech
companies, with significant price reductions for developers and
SMEs.</p>
<p>China's semiconductor industry faces challenges due to US
restrictions but is also making strides in self-sufficiency, with
companies like <strong>Huawei</strong> pushing forward on competitive AI
chips.</p>
<p>China's robotaxi industry is gaining momentum, with Baidu's
<strong>Apollo Go</strong> expanding its fleet and other self-driving
startups completing IPOs.</p>
<p>OpenAI and Microsoft have tightened AI access in China, prompting
Chinese AI companies to offer alternatives and accelerating the
development of homegrown models.</p>
<p>China is seeing a <strong>robotics</strong> boom with rapid
innovation in humanoid and other types of robots, though challenges
remain in complex tasks and high production costs.</p>
<p><strong>AI resurrection</strong> is becoming increasingly accessible,
raising ethical and legal questions as companies offer services to
create digital replicas of the deceased.</p>
<blockquote>
<p><strong>Finetuning LLM Judges for Evaluation - Deep (Learning)
Focus</strong> [<a
target="_blank" rel="noopener" href="https://cameronrwolfe.substack.com/p/finetuned-judge">Link</a>]</p>
</blockquote>
<p>This article discusses the challenges of evaluating LLMs and how
finetuning specialized LLM judges can improve the evaluation process.
Here's how the logic of the article flows:</p>
<p>The article notes that while human evaluation is the most reliable
method, it is also expensive, time-consuming, and not scalable. This
creates a need for efficient ways to test LLM capabilities.</p>
<p>There are two primary evaluation approaches: <strong>human evaluation
and automatic metrics</strong>.</p>
<ul>
<li><strong>Human evaluation</strong> is considered the "definitive
source of truth" but is recognized as noisy, subjective and prone to
bias.</li>
<li><strong>Automatic metrics</strong> are used to speed up model
development, but they are imperfect proxies for human opinions. The
article further divides automatic metrics into two categories:
traditional metrics and model-based evaluation.</li>
<li><strong>Traditional metrics</strong> like ROUGE and BLEU are
reference-based, comparing LLM outputs to "golden" answers, and are less
effective for modern LLMs which are open-ended and can produce many
valid responses.</li>
<li><strong>LLM-as-a-Judge</strong> is introduced as a model-based
approach, using a powerful LLM to evaluate another LLM's output. This
method is effective, easy to implement, and can handle open-ended
tasks.</li>
</ul>
<p>While effective, LLM-as-a-Judge has limitations, including a lack of
transparency, security concerns, cost, and a lack of specialization for
domain-specific evaluations. The article argues that these limitations
can be addressed by <strong>training specialized LLM
judges</strong>.</p>
<ul>
<li><strong>Meta-evaluation</strong> involves assessing the performance
of the LLM judge by comparing its output to high-quality human
evaluation data.</li>
<li>Early research on finetuned LLM judges were created as open source
replacements for proprietary LLMs. The original LLM-as-a-Judge paper
also explored finetuning, and found that a finetuned Vicuna-13B model
showed potential. The need for finetuning is further justified because
proprietary LLMs can be expensive, lack control or transparency, and
because open source models are becoming more capable. The article
discusses how a Vicuna-13B model was improved by finetuning on human
votes from Chatbot Arena, though it still fell short of GPT-4
performance.</li>
<li>Several examples of finetuned LLM judges:
<ul>
<li><strong>PandaLM</strong>: This model is designed to identify the
best model among a set, particularly useful for hyperparameter tuning.
It is trained on a dataset of over 300K examples with instructions,
inputs, paired responses, evaluation results and rationales. PandaLM is
effective in specialized domains like law and biology.</li>
<li><strong>JudgeLM</strong>: This model focuses on the factors that
contribute most to the quality of a judge model, such as data quality
and diversity, base model size, bias, and generalization. JudgeLM uses a
high-quality, diverse dataset and is trained to mitigate bias, including
positional, knowledge, and format biases.</li>
<li><strong>Auto-J</strong>: This model is designed for domain-specific
grading, with an emphasis on providing high-quality, structured
explanations. It is trained on real-world queries and responses and can
perform both pairwise and direct assessment scoring.</li>
</ul></li>
<li>Other related research using LLMs for critiques, verification, and
generating synthetic training data.</li>
</ul>
<p><strong>Prometheus</strong> is a key development in finetuned LLM
judges, capable of fine-grained, domain-specific evaluation. It is
trained to ingest custom scoring rubrics as input.</p>
<ul>
<li>The <strong>Prometheus</strong> model uses the Feedback Collection
dataset, which includes instructions, responses, rubrics, reference
answers, rationales, and scores. It is trained to sequentially provide
feedback and then score the response using a supervised finetuning (SFT)
strategy.</li>
<li><strong>Prometheus 2</strong> is introduced as an extension that can
handle both direct assessment and pairwise scoring. It is trained on
both the Feedback Collection and the Preference Collection, and uses a
linear model merging approach to combine models trained for the two
scoring formats.</li>
<li><strong>Prometheus-Vision</strong> extends the Prometheus concept to
Vision-Language Models (VLMs). It uses a dataset called the Perception
Collection, which includes images, instructions, responses, rubrics and
reference answers.</li>
</ul>
<p>Other types of finetuned judges, including:</p>
<ul>
<li><strong>Self-rewarding LLMs</strong>, which use the LLM itself to
provide its own rewards and feedback.</li>
<li><strong>LLM-as-a-Meta-Judge</strong>, which allows the LLM judge to
self-improve.</li>
<li><strong>Self-taught evaluators</strong>, which train evaluators
without human preference data.</li>
<li><strong>Foundational Large Autorater Models (FLAMe)</strong>, which
are trained on a massive amount of human preference data and generalize
well to other tasks.</li>
<li><strong>Direct judgement preference optimization</strong>, which
uses preference optimization to create more advanced evaluation
capabilities.</li>
</ul>
<p>A generic framework based on the Prometheus model for creating a
finetuned LLM judge. The steps include:</p>
<ul>
<li>Solidifying evaluation criteria.</li>
<li>Preparing a high-quality dataset.</li>
<li>Using synthetic data.</li>
<li>Focusing on the rationales for each score.</li>
<li>Training the model using SFT and meta-evaluating its
performance.</li>
</ul>
<blockquote>
<p><strong>E-Commerce Unleashed - App Economy Insights</strong> [<a
target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/e-commerce-unleashed">link</a>]</p>
</blockquote>
<p>Highlights discussion points:</p>
<ol type="1">
<li><p><strong>Cyber week trends.</strong></p>
<p>"Cyber Week (from Black Friday to Cyber Monday) showcased shifting
consumer behaviors and the growing dominance of e-commerce."</p></li>
<li><p><strong>Shopify’s acceleration.</strong></p>
<p>Shopify has evolved from a platform for small businesses into a
global enabler for merchants, offering tools to scale internationally.
Its emphasis on payments, particularly through Shop Pay, has been
pivotal, with Shop Pay emerging as a high-conversion checkout option. In
Q3, Gross Payment Volume accounted for 62% of Shopify’s Gross
Merchandise Volume, marking a 4% year-over-year increase. Additionally,
Shopify's partnership with Amazon to integrate Prime benefits directly
into Shopify stores represents a strategic move to boost customer
loyalty and conversions by leveraging Amazon's trusted fulfillment
network and extensive Prime membership base.</p></li>
<li><p><strong>Amazon takes on Temu.</strong></p>
<p>Amazon has launched <strong>Amazon Haul</strong>, a new storefront
aimed at attracting budget-conscious shoppers and safeguarding its
market position. This initiative is strategically designed to meet the
increasing demand for affordable e-commerce solutions.</p></li>
<li><p><strong>Walmart’s advertising play.</strong></p>
<p>Walmart is redefining modern retail by merging its extensive physical
presence with advanced digital capabilities to create a powerful
<strong>omnichannel strategy</strong>. The company leverages first-party
data and its retail media network to maintain a competitive edge.</p>
<p><strong>Walmart Connect</strong> integrates online and in-store
advertising, allowing brands to engage customers at their preferred
shopping points. By utilizing vast first-party data, Walmart delivers
targeted and relevant ads, enhancing both advertiser returns and
customer satisfaction. The platform is also attracting advertisers from
diverse industries, including automotive and financial services.</p>
<p>Walmart’s planned acquisition of <strong>Vizio</strong> marks its
entry into <strong>connected TV advertising</strong>, broadening Walmart
Connect’s reach into households through smart TVs and enhancing
inventory visibility and supply chain integration through improved data
capabilities. This positions Walmart as a leader in omnichannel retail
and advertising.</p></li>
<li><p><strong>AI: The quiet game changer.</strong></p>
<p>AI played a transformative role during Cyber Week, enhancing the
shopping experience across various dimensions.
<strong>Hyper-personalized shopping</strong> was driven by AI
recommendation engines, which anticipated consumer needs and boosted
conversions, exemplified by features like Amazon’s “frequently bought
together.” Generative AI tools, such as chatbots, simplified
<strong>product discovery</strong> during the busy sales period, with
innovations like <strong>Amazon Q</strong> offering AI-generated review
summaries to streamline decision-making.</p>
<p>AI also optimized logistics through <strong>demand
forecasting</strong>, ensuring products remained in stock and reducing
shipping delays. In payments, <strong>real-time AI fraud
detection</strong> provided secure checkouts on platforms like Walmart
and Shopify. Additionally, AI tools like <strong>Shopify’s Sidekick and
Magic</strong> enhanced product descriptions, SEO strategies, and
customer support, further elevating the e-commerce experience. These
advancements underscored AI's critical role in reshaping retail during
one of the busiest shopping weeks of the year.</p></li>
</ol>
<blockquote>
<p><em>AI presents new challenges for incumbents but also drives
significant innovation and growth.</em></p>
<p><strong>― Salesforce: The Agent Wave - App Economy Insights</strong>
[<a
target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/salesforce-the-agent-wave">Link</a>]</p>
</blockquote>
<p>The company’s autonomous AI platform - Agentforce - was introduced in
Sep 2024 and launched in late Oct. Agentforce enables businesses to
deploy AI agents for tasks such as sales, marketing, and customer
support. This marks a pivotal step in Salesforce’s platform strategy,
with far-reaching implications. CEO Marc Benioff views Agentforce as
transformative, positioning it at the core of a shift toward
“agent-first companies.” In this model, AI not only assists humans but
fundamentally redefines business operations by automating processes and
enhancing productivity.</p>
<figure>
<img src="/di-blog/2024/12/01/2024-December/agentforce.jpeg"
alt="agentforce" />
<figcaption aria-hidden="true">agentforce</figcaption>
</figure>
<p>What to watch:</p>
<ul>
<li>Salesforce recently completed its acquisition of
<strong>Own</strong> and <strong>Zoomin</strong>, reinforcing its Data
Cloud capabilities.</li>
<li><strong>Salesforce Ventures</strong> announced a new <span
class="math inline">\(\$500\)</span> million AI fund, targeting
high-profile AI startups like Anthropic, Mistral, and Cohere, supporting
Salesforce’s efforts to remain at the forefront of enterprise AI.</li>
<li>Clara Shih, <strong>CEO of Salesforce AI</strong> left Salesforce to
set up a new <strong>Business AI</strong> group at Meta, aiming to build
AI tools for businesses of all sizes. Shih’s departure highlights the
intensity of the <strong>AI talent war</strong>, which will be a
fascinating layer to watch in the coming year.</li>
</ul>
<blockquote>
<p><strong>OpenAI's o1 using "search" was a PSYOP -
Interconnects</strong> [<a
target="_blank" rel="noopener" href="https://www.interconnects.ai/p/openais-o1-using-search-was-a-psyop">Link</a>]</p>
</blockquote>
<p>The article primarily argues that OpenAI's o1 model does not use
explicit search at test time, and its apparent search capabilities are a
result of reinforcement learning (RL) during training. The author argues
against the idea that o1 uses online search at test time or intermediate
rewards during training. The article posits that the "suspects" are
reduced to "Guess + Check" and "Learning to Correct". They uses the
<strong>test-time compute plot</strong>, and the training process, as
key points in their argument to show how o1 can achieve high performance
using RL with controlled training data and no explicit search during
inference.</p>
<p>One major source of this idea is <a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=6PEJ96k1kiw&amp;ab_channel=SashaRush%F0%9F%A4%97">Sasha
Rush's lecture</a> on Test Time Scaling (o1).</p>
<blockquote>
<p><strong>Insurance companies aren't the main villain of the U.S.
health system - Nahpinion</strong> [<a
target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/insurance-companies-arent-the-main">Link</a>]</p>
</blockquote>
<p>This article argues that health insurance companies are not the
primary cause of high healthcare costs in the United States12. Instead,
the article argues that the excessive prices charged by healthcare
providers are the main reason for the high cost of healthcare. The
article suggests that focusing anger on insurance companies is "shooting
the messenger," and the solution is to reduce costs within the medical
system itself, such as having the government negotiate lower prices with
providers.</p>
<p>Evidences are: insurance companies have low profit margins, spend
much more on medical costs than they make in profit. Americans pay a
smaller percentage of their health costs out of pocket than people in
most other rich countries. This suggests that US health insurers are
paying a higher percentage of costs than government insurance systems in
other countries. The cost of healthcare provision in the U.S. is too
high. The actual people charging high prices are the providers
themselves, such as hospitals, pharmaceutical companies, and system.
They outsource the actual collection of these fees to insurance
companies.</p>
<blockquote>
<p><strong>15 Times to use AI, and 5 Not to - One Useful Thing</strong>
[<a
target="_blank" rel="noopener" href="https://www.oneusefulthing.org/p/15-times-to-use-ai-and-5-not-to">Link</a>]</p>
</blockquote>
<p><strong>When to Use AI:</strong></p>
<p>Use AI for tasks that require generating a high quantity of ideas,
such as in brainstorming sessions.</p>
<p>AI is useful when you are an expert and can quickly judge the quality
of its output.</p>
<p>AI can summarize large amounts of information where minor errors are
acceptable.</p>
<p>Use AI for translating information between different formats or
audiences.</p>
<p>AI can help you overcome creative blocks by providing multiple
options to move forward.</p>
<p>Use AI when it is known to be better than any available human option,
and its errors won't cause significant problems.</p>
<p><strong>Use AI as a companion when reading to get help with context
and details.</strong> <strong>(very helpful to me)</strong></p>
<p>AI can provide a variety of solutions, allowing you to curate the
best ones.</p>
<p>AI is helpful for tasks where research has proven it to be effective,
like coding.</p>
<p>Use AI to get a first look at how different audiences might react to
your work.</p>
<p>AI can act as a competent co-founder for entrepreneurial
ventures.</p>
<p>Use AI to get a specific perspective, such as reactions from
fictional personas.</p>
<p>AI can help with tasks that are ritualistic and have lost their
purpose.</p>
<p>Use AI to get a second opinion by comparing its conclusions with
yours.</p>
<p>Use AI when it can perform a task better than humans.</p>
<p><strong>When Not to Use AI:</strong></p>
<p>Avoid AI when you need to learn and synthesize new ideas, as it is
not the same as reading and thinking yourself.</p>
<p>Do not use AI when very high accuracy is essential because AI errors
can be very plausible and hard to spot.</p>
<p>Avoid AI if you do not understand its failure modes, such as
hallucinations or persuasiveness.</p>
<p>Do not use AI when the struggle with a topic is necessary for success
and learning.</p>
<p>Avoid AI when it is bad at a specific task.</p>
<blockquote>
<p><strong>Oracle : The 4th Hyperscaler? - App Economy Insights</strong>
[<a
target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/oracle-the-4th-hyperscaler">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Google released the first version of its Gemini 2.0 family of
artificial intelligence models on December 11th, 2024. Including its
Chrome browser automation product called <a
target="_blank" rel="noopener" href="https://deepmind.google/technologies/project-mariner/">Mariner</a>.</em></p>
<p><em><a
target="_blank" rel="noopener" href="https://deepmind.google/technologies/project-astra/">Project
Astra</a> and Mariner along with <a
target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/how-to-use-notebooklm-for-personalized">NotebookLM</a>
remain very intriguing AI products by Google in 2025.</em></p>
<p><strong>Gemini 2 and the rise of multi-modal AI - AI
Supremacy</strong> [<a
target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/gemini-2-and-the-rise-of-multi-modal">Link</a>]</p>
</blockquote>
<p>Incredible.</p>
<figure>
<img
src="/di-blog/2024/12/01/2024-December/last_6_month_llm_google_openai.png"
alt="last_6_month_llm_google_openai" />
<figcaption
aria-hidden="true">last_6_month_llm_google_openai</figcaption>
</figure>
<p>Figure source: <a
target="_blank" rel="noopener" href="https://www.linkedin.com/posts/peter-gostev_i-havent-quite-realised-that-this-was-the-activity-7272750515300536320-UqUu/?utm_source=share&amp;utm_medium=member_android">Peter
Gostev on Linkedin</a></p>
<blockquote>
<p><strong>Palantir Unclassified! Equity Research! - Global Equity
Briefing</strong> [<a
target="_blank" rel="noopener" href="https://www.globalequitybriefing.com/p/palantir-war-as-a-service-and-data">Link</a>]</p>
</blockquote>
<p>Palantir is a software company that provides tools for analyzing
large datasets, which enable users to make better decisions. Founded in
the early 2000s, Palantir initially offered services to government
agencies, including the US intelligence community, to combat terrorism.
The CIA was one of their first investors. Palantir's software is also
used by corporations to improve operations and decision-making.</p>
<p><strong>Business Model</strong></p>
<p>Palantir operates as a <strong>Software as a Service (SaaS)
company</strong>, offering a suite of customizable products for which
clients pay a licensing fee. The company has two operating segments:
<strong>government</strong> and <strong>commercial</strong>.</p>
<p><strong>Government Sales:</strong> Palantir provides services to
government institutions, recognizing a gap in the market due to many
Silicon Valley companies not wanting to work with governments. These
contracts are often long-term, providing predictable revenue streams.
The company benefits from the transparency of government information,
and it is easier for them to predict needs and market their
software.</p>
<p><strong>Commercial Sales</strong>: Palantir's solutions are used
across many industries by various employees from production line workers
to CEOs. The use cases for Palantir software in the commercial sector
are extensive.</p>
<p><strong>Customer Acquisition:</strong> Palantir targets large
organizations with complex problems, which increases their competitive
advantage. Solving difficult problems first earns customer trust.</p>
<p><strong>Products</strong>: Gotham, Foundry, Apollo, and AIP.</p>
<ul>
<li><strong>Gotham:</strong> It is a <strong>government-focused
platform</strong> that allows users to analyze large datasets to make
better decisions and find hidden connections, with the goal of improving
operations and decision-making.</li>
<li><strong>Foundry:</strong> This is a <strong>commercial
platform</strong> that allows large and complex companies to integrate,
visualize, and analyze their data to optimize their operations and value
chain.</li>
<li><strong>Apollo:</strong> This is a platform for <strong>continuous
software deployment</strong>, enabling secure and seamless delivery of
software across various environments for Palantir's clients.</li>
<li><strong>AIP:</strong> Palantir's newest offering, it is a platform
for organizations to <strong>create customized AI tools</strong> using
their own data, providing accurate and detailed answers to specific
questions.</li>
</ul>
<p><strong>Opportunities</strong></p>
<p>Palantir can benefit from the growing demand for <strong>digital
twins</strong>, which are exact digital replicas of real-world items
used for integration, monitoring, simulation, and maintenance. The
digital twin market is projected to grow significantly. Palantir is
positioned to benefit from the <strong>AI revolution</strong> with its
<strong>AIP platform</strong>, and its other products also use AI. The
global AI market is expected to reach <span
class="math inline">\(\$1.84\)</span> trillion by 2030. Palantir is
developing <strong>industry-specific operating systems</strong>, like
Skywise for the airline industry. These operating systems are sticky and
offer significant revenue opportunities. The healthcare industry could
be a large market for such systems. Palantir's commercial sector is
growing, and there are significant opportunities for international
expansion.</p>
<blockquote>
<p><strong>Is AI hitting a wall? - Strange Loop Canon</strong> [<a
target="_blank" rel="noopener" href="https://www.strangeloopcanon.com/p/is-ai-hitting-a-wall">Link</a>]</p>
</blockquote>
<p>Arguments that suggest AI progress is hitting a wall include the
observation that <strong>pre-training scaling has plateaued</strong>,
meaning simply increasing model size and data may not yield the same
improvements as before. Also, current evaluation <strong>benchmarks may
be saturated</strong>, failing to assess deeper work, since they are
based on human tests or simple recall. Current AI models
<strong>struggle with real-world tasks</strong> due to issues like
hallucination and a lack of creative planning, even if they appear
human-level in individual evaluations. Finally, the visible effects of
scaling are limited, with reduced cross-entropy loss not translating to
significant improvements for observers.</p>
<p>Conversely, arguments against AI progress hitting a wall emphasize
the presence of <strong>large amounts of unused data</strong>, including
various types like conversations and video data. The use of
<strong>synthetic data</strong> can enhance learning by converting
existing data into different formats and testing it against real-world
scenarios. AI models are now being taught <strong>reasoning</strong>,
enabling them to "think for longer" and improving performance in areas
requiring clear thought processes. Additionally, there is the
possibility of exploring <strong>new S-curves</strong> or scaling laws.
New models are also capable of <strong>expert-level work</strong> that
is not captured by current benchmarks, potentially speeding up
scientific research. Finally, AI models can now <strong>interact with
digital systems</strong>, and are becoming more aware of the world.</p>
<blockquote>
<p><strong>Our Healthcare System, a Reign of Terror - Freddie
deBoer</strong> [<a
target="_blank" rel="noopener" href="https://freddiedeboer.substack.com/p/our-healthcare-system-a-reign-of">Link</a>]</p>
<p><strong>An Assassin Showed Just How Angry America Really Is - BIG by
Matt Stoller</strong> [<a
target="_blank" rel="noopener" href="https://www.thebignewsletter.com/p/an-assassin-showed-just-how-angry">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>OpenAI o3 Model Is a Message From the Future: Update All You
Think You Know About AI - The Algorithmic Bridge</strong> [<a
target="_blank" rel="noopener" href="https://www.thealgorithmicbridge.com/p/openai-o3-model-is-a-message-from">Link</a>]</p>
<p><strong>OpenAI's o3: The grand finale of AI in 2024 -
Interconnects</strong> [<a
target="_blank" rel="noopener" href="https://www.interconnects.ai/p/openais-o3-the-2024-finale-of-ai?r=333z5o&amp;utm_medium=ios&amp;triedRedirect=true">Link</a>]</p>
</blockquote>
<p>Key performance points:</p>
<ul>
<li><strong>ARC AGI Prize:</strong> o3 is the first model to surpass the
85% threshold for completing the ARC AGI prize on the public set, though
it exceeded cost constraints. It achieved 87% accuracy on the public set
with high compute, and 76% with low compute. For context, prior to
o1-class models, OpenAI’s best model, GPT-4o, only achieved 5% accuracy.
The ARC AGI challenge is designed to evaluate human-like general fluid
intelligence.</li>
<li><strong>Frontier Math Benchmark:</strong> o3 demonstrates a
substantial improvement on the Frontier Math benchmark, increasing
performance from 2% to 25%. This benchmark is considered extremely
challenging, with one Fields Medalist stating that the problems "will
resist AIs for several years at least".</li>
<li><strong>Coding Benchmarks:</strong> o3 has made significant
improvements on leading coding benchmarks such as SWE-Bench-Verified,
achieving a score of 71.7%. On the Codeforces competition coding site,
o3 achieved a score of 2727 with consensus voting, placing it at the
International Grandmaster level and approximately in the top 200 of
competitive human coders.</li>
<li><strong>Reasoning Capabilities:</strong> o3 represents a major
advancement in reasoning evaluations, signaling that the industry is
moving beyond pretraining on internet text. It is expected to accelerate
the rate of progress in AI research.</li>
<li><strong>Inference and Cost</strong>: o3 was tested with two levels
of compute with different sample sizes: a high-efficiency configuration
with a sample size of 6, and a low-efficiency configuration with a
sample size of 1024 which used 172 times more compute. The cost of
running o3 at the higher level of compute was approximately <span
class="math inline">\(\$5000\)</span> per query. It is speculated that
the core mechanism of o3 involves natural language program search and
execution within token space, searching over Chains of Thought
(CoTs).</li>
<li><strong>Availability</strong>: The o3 model, including the o3-mini
version, is expected to be available to the general public in late
January 2025. The o3-mini is expected to be more impactful for the
general public due to its lower cost, while still outperforming o1.</li>
</ul>
<blockquote>
<p><strong>o3, AGI, the art of the demo, and what you can expect in 2025
- Marcus on AI</strong> [<a
target="_blank" rel="noopener" href="https://garymarcus.substack.com/p/o3-agi-the-art-of-the-demo-and-what">Link</a>]</p>
<p><strong>o3 “ARC AGI” postmortem megathread: why things got heated,
what went wrong, and what it all means - Marcus on AI</strong> [<a
target="_blank" rel="noopener" href="https://garymarcus.substack.com/p/c39">Link</a>]</p>
</blockquote>
<p>Gary Marcus critiques OpenAI's new model o3, arguing that its
impressive demo, while showcasing advancements in math and coding, was
carefully curated and lacks broader application.</p>
<ul>
<li>The public did not get to try the system, and it was not vetted by
the scientific community. OpenAI chose what to highlight about o3.
Marcus argues that until many people get to try o3 on different tasks,
its reliability should not be assumed.</li>
<li>The o3 demo primarily focused on math, coding, and IQ-like puzzles,
with no evidence that it can work reliably in open-ended domains. It was
not tested on problems where massive data augmentation was not possible.
The demo did not address the most important question about the system's
capabilities in open-ended domains.</li>
<li>The o3 system is incredibly expensive. One estimate suggests that
each call to the system might cost $1000. Even if the cost is reduced,
it might still not be as good or as versatile as top STEM
graduates.</li>
<li>The o3's performance on the ARC-AGI test was misleading. The test is
at most a necessary, but not sufficient, condition for AGI, and does not
address important areas such as factuality, compositionality, and common
sense.</li>
<li>The core problem of neural networks generalizing better "within
distribution" than "outside distribution" has not been solved.</li>
</ul>
<blockquote>
<p><strong>Note to Our Energy Sucking Overlords - Michael
Spencer</strong> [<a
target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/note-to-our-energy-sucking-overlords">Link</a>]</p>
</blockquote>
<p>The rapid growth of AI is causing a surge in demand for data centers,
which in turn are becoming major consumers of electricity. The energy
needs of AI are growing so large that tech companies are seeking
reliable power sources beyond renewable energy. The rising energy
consumption of AI infrastructure will likely result in higher energy
prices, potentially creating competition between Big Tech and the
communities where they build data centers. To meet their energy needs,
major technology companies are becoming more involved in the energy
sector, including investments in nuclear and natural gas plants. The
current trajectory of AI infrastructure expansion and energy consumption
is unsustainable and could lead to significant challenges for society.
The US is building data centers abroad in Europe and Asia, thereby
maintaining their power and also acquiring cheaper labor.</p>
<p>Summary of statistics:</p>
<ul>
<li><strong>Energy Consumption of AI tasks:</strong> A single task on
the ARC-AGI benchmark using OpenAI's o3 model consumes approximately
<strong>1,785 kWh</strong> of energy, which is equivalent to the
electricity used by an average U.S. household in two months. This task
also generates 684 kg CO₂e, which is equivalent to the carbon emissions
from more than 5 full tanks of gas.</li>
<li><strong>Investments in AI Infrastructure:</strong> In 2024, major
players like Amazon, Microsoft, and Alphabet spent over <span
class="math inline">\(\$240\)</span> billion on AI-related
infrastructure. In 2025, Amazon, Google, Meta, and Microsoft are
expected to spend <span class="math inline">\(\$300\)</span> billion in
capital expenditures.</li>
<li><strong>Data Center Electricity Consumption:</strong> Global data
center electricity consumption is expected to <strong>more than
double</strong> between 2023 and 2028. The IDC expects consumption to
reach <strong>857 Terawatt hours (TWh)</strong> in 2028.</li>
<li><strong>US Data Center Energy Usage:</strong> U.S. data centers
could use <strong>6.7 to 12%</strong> of all energy demand nationwide by
2028. In 2023, data centers used 4.4% of total US power consumption,
which is projected to rise to as high as 12% by 2028. This is a spike of
more than threefold in the next four years.</li>
<li><strong>Data Center Locations and Power</strong>:
<ul>
<li>Northern Virginia has over <strong>300</strong> data centers with
approximately <strong>3,945 megawatts</strong> of commissioned
power.</li>
<li>The Dallas region has <strong>150</strong> data centers.</li>
<li>Silicon Valley has over <strong>160</strong> data centers.</li>
<li>Phoenix has over <strong>100</strong> data centers with around
<strong>1,380 megawatts</strong> of power.</li>
<li>Chicago has more than <strong>110</strong> data centers.</li>
</ul></li>
<li><strong>Data Center Projects:</strong>
<ul>
<li>OpenAI plans to construct massive <strong>5-gigawatt (GW) data
centers</strong> across the US.</li>
<li>Oklo will build small modular reactors (SMR) by 2044 to generate 12
gigawatts of electricity for data centers.</li>
<li>Meta announced a <span class="math inline">\(\$10\)</span> billion
development for a <strong>4 million sq ft, 2 GW data center</strong>
campus in Louisiana.</li>
<li>Entergy is proposing to develop a <strong>1.5GW natural gas
plant</strong> in Louisiana to power a data center.</li>
<li>Amazon Web Services (AWS) plans to invest <span
class="math inline">\(\$11\)</span> billion in a new data center campus
in Northern Indiana.</li>
</ul></li>
<li><strong>Generative AI Market:</strong> The generative AI market was
valued at <span class="math inline">\(\$6\)</span> billion in 2023 and
could reach <span class="math inline">\(\$59\)</span> billion in
2028.</li>
<li><strong>Increased US power demand:</strong> Data centers are one of
the key reasons US power demand is expected to jump 16% over the next
five years.</li>
<li><strong>Cost of Electricity for Data Centers:</strong> Electricity
is the largest ongoing expense for data center operators, accounting for
<strong>46%</strong> of total spending for enterprise data centers and
<strong>60%</strong> for service provider data centers.</li>
<li><strong>The potential for data centers to consume as much energy as
entire industrialized economies:</strong> By 2030, US data centers could
consume as much electricity as some entire industrialized
economies.</li>
<li><strong>Big Oil's Role:</strong> Big oil companies like
<strong>ExxonMobil</strong> and <strong>Chevron</strong> are moving into
the AI datacenter energy market. Exxon plans to build a natural gas
plant to power a data center, and estimates that decarbonizing AI data
centers could represent up to 20% of its total addressable market for
carbon capture and storage by 2050.</li>
</ul>
<blockquote>
<p><strong>What are the checks and balances on the power of Elon Musk? -
Noahpinion</strong> [<a
target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/what-are-the-checks-and-balances">Link</a>]</p>
</blockquote>
<p>The article examines the significant influence of Elon Musk on U.S.
politics, particularly his role in derailing a Congressional spending
bill. It explores whether Musk's actions represent a threat to
democratic processes, considering his control over X (formerly Twitter)
and SpaceX. The author presents contrasting views of Musk—"Real Elon"
versus "Evil Elon"—highlighting the uncertainty surrounding his motives
and the lack of institutional checks on his power. The piece concludes
by suggesting that public opinion ultimately holds sway over Musk's
influence, though the potential for a powerful backlash remains to be
seen.</p>
<blockquote>
<p><strong>Is AI progress slowing down? - AI SHAKE OIL</strong> [<a
target="_blank" rel="noopener" href="https://www.aisnakeoil.com/p/is-ai-progress-slowing-down">Link</a>]</p>
</blockquote>
<p>The authors argue that the recent shift away from model scaling
towards inference scaling is not necessarily indicative of a slowdown,
but rather a change in approach. They caution against over-reliance on
industry insiders' predictions due to their inherent biases, emphasizing
that progress is less predictable and more dependent on algorithmic
innovation than previously assumed. Furthermore, the essay highlights
the significant lag between capability advancements and real-world
applications, suggesting that the focus should shift towards product
development and user adoption rather than solely on model capabilities.
Finally, the authors offer a more nuanced perspective on the current
state of AI progress, acknowledging the potential of inference scaling
while emphasizing the importance of considering broader factors beyond
pure technological advancement.</p>
<blockquote>
<p><strong>The Critical AI Report, December 2024 Edition - Blood in the
Machine</strong> [<a
target="_blank" rel="noopener" href="https://www.bloodinthemachine.com/p/the-critical-ai-report-december-2024">Link</a>]</p>
</blockquote>
<p>Gen AI's actual impact on workers so far:</p>
<figure>
<img src="/di-blog/2024/12/01/2024-December/genai_impact_on_workers.png"
alt="genai_impact_on_workers" />
<figcaption aria-hidden="true">genai_impact_on_workers</figcaption>
</figure>
<blockquote>
<p><strong>Waymo: Rideshare Revolution - App Economy Insights</strong>
[<a
target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/waymo-rideshare-revolution">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Manufacturing is a war now - Noahpinion</strong> [<a
target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/manufacturing-is-a-war-now">Link</a>]</p>
</blockquote>
<p>The article argues that China's dominance in manufacturing,
particularly in crucial areas like drone production and batteries, poses
a significant threat to the United States and its allies.</p>
<figure>
<img
src="/di-blog/2024/12/01/2024-December/global_industrial_production.jpeg"
alt="global_industrial_production" />
<figcaption aria-hidden="true">global_industrial_production</figcaption>
</figure>
<p>Source:
https://mipforum.org/wp-content/uploads/2024/11/MIPF-Conference-Paper-FINAL-WEB.pdf</p>
<h3 id="articles-and-blogs">Articles and Blogs</h3>
<blockquote>
<p><strong>Meet Willow, our state-of-the-art quantum chip - Google
Research</strong> [<a
target="_blank" rel="noopener" href="https://blog.google/technology/research/google-willow-quantum-chip/">Link</a>]</p>
</blockquote>
<p>Google has developed a new quantum chip called Willow, which
significantly reduces errors as it scales up, a major breakthrough in
quantum error correction. Willow also performed a computation in under
five minutes that would take a supercomputer 10 septillion years,
demonstrating its potential for solving complex problems beyond the
reach of classical computers. This achievement marks a significant step
towards building commercially relevant quantum computers that can
revolutionize fields like medicine, energy, and AI.</p>
<p>Quantum Computing Roadmap:</p>
<figure>
<img
src="/di-blog/2024/12/01/2024-December/google_quantum_ai_roadmap.png"
alt="google_quantum_ai_roadmap" />
<figcaption aria-hidden="true">google_quantum_ai_roadmap</figcaption>
</figure>
<p>Terms to keep in mind:</p>
<ul>
<li><strong>Willow:</strong> Google's latest 105-qubit superconducting
processor, which is the first to demonstrate exponential error
suppression with increasing surface code size.</li>
<li><strong>Below Threshold:</strong> A milestone in quantum computing
where the error rate decreases as the number of qubits increases,
demonstrating effective error correction.</li>
<li><strong>Logical Qubit:</strong> A fault-tolerant qubit created from
multiple physical qubits using error correction techniques, providing a
more stable and reliable unit of computation.</li>
<li><strong>Random Circuit Sampling (RCS):</strong> A benchmark test
that assesses the ability of a quantum computer to perform computations
beyond the capabilities of classical computers.</li>
<li><strong>T1 Time:</strong> A measure of how long a qubit can maintain
its quantum state before decoherence sets in.</li>
<li><strong>Quantum Algorithms:</strong> Algorithms specifically
designed to be executed on quantum computers, leveraging quantum
phenomena to solve problems more efficiently.</li>
</ul>
<blockquote>
<p><strong>Making quantum error correction work - Google
Research</strong> [<a
target="_blank" rel="noopener" href="https://research.google/blog/making-quantum-error-correction-work/">Link</a>]</p>
</blockquote>
<p>The ultimate vision of them is to build a large-scale, fault-tolerant
quantum computer that can run complex quantum algorithms and unlock the
potential of quantum computing for scientific discovery and various
applications.</p>
<p>Terms to keep in mind:</p>
<ul>
<li><strong>Repetition codes:</strong> A type of quantum error
correction that focuses solely on bitflip errors and achieves lower
encoded error rates.</li>
<li><strong>Quantum error decoder:</strong> Classical software that
processes measurement information from the quantum computer to identify
and correct errors.</li>
</ul>
<blockquote>
<p><strong>AI Hallucinations: Why Large Language Models Make Things Up
(And How to Fix It) - kapa.ai</strong> [<a
target="_blank" rel="noopener" href="https://www.kapa.ai/blog/ai-hallucination">Link</a>]</p>
</blockquote>
<p>Why Do LLMs Hallucinate?</p>
<ul>
<li>LLMs predict upcoming words in a sequence based on patterns in
training data. They lack true reasoning or comprehension abilities, so
they rely only on these word probability patterns instead of genuine
understanding of the topics they discuss.</li>
<li>Architecture limitations: 1) fixed attention window in transformer
limits input context leading to earlier information being dropped, 2)
sequential token generation mechanism has no revision process, so
initial errors can compound to major inaccuracies in the output.</li>
<li>Limitations of probabilistic generation: 1) models can produce
plausible-sounding responses that lack actual comprehension of subjects,
2) value prompts lead LLMs to try to "fill in the blanks" resulting in
fabricated or inaccurate answers.</li>
<li>Training data gaps: 1) models are trained on ground-truth training
data while they do inference on their own, this can create a feedback
loop where minor errors become amplified, 2) when prompt falls outside
the scope of training data, the model will likely generate a
hallucinated response.</li>
</ul>
<p>How to Mitigate AI Hallucination?</p>
<ul>
<li>Input layer mitigation strategies
<ul>
<li>Query processing; context size optimization; context injection.</li>
</ul></li>
<li>Design layer mitigation strategies
<ul>
<li>Chain-of-Thought prompting; Retrieval-Augmented Generation (RAG);
Fine-tuning</li>
</ul></li>
<li>Output layer mitigation strategies
<ul>
<li>Rule-based filtering; output re-ranking; fact-checking and
verification; encourage contextual awareness.</li>
</ul></li>
</ul>
<figure>
<img src="/di-blog/2024/12/01/2024-December/mitigate_halluciation.png"
alt="mitigate_halluciation" />
<figcaption aria-hidden="true">mitigate_halluciation</figcaption>
</figure>
<blockquote>
<p><strong>The next chapter of the Gemini era for developers - Google
Blog</strong> [<a
target="_blank" rel="noopener" href="https://developers.googleblog.com/en/the-next-chapter-of-the-gemini-era-for-developers/">Link</a>]</p>
</blockquote>
<p><a
target="_blank" rel="noopener" href="https://github.com/google-gemini/cookbook/tree/main/gemini-2">API
starter code</a>, <a target="_blank" rel="noopener" href="https://labs.google.com/code/">Code
Experiments (Data Science Agents, etc)</a>, <a
target="_blank" rel="noopener" href="https://aistudio.google.com/prompts/new_chat">Google AI
Studio</a></p>
<p>Gemini 2.0 Flash is an experimental AI model that builds upon the
success of Gemini 1.5 Flash. It offers enhanced capabilities for
developers to build immersive and interactive applications.</p>
<p><strong>Functionalities and Capabilities of Gemini 2.0
Flash:</strong></p>
<ul>
<li><p>Enhanced Performance: It is twice as fast as Gemini 1.5 Pro with
improved multimodal, text, code, video, spatial understanding, and
reasoning performance.</p></li>
<li><p>New Output Modalities:</p>
<p>Gemini 2.0 Flash allows developers to generate integrated responses,
including text, audio, and images, through a single API call. It
features native text-to-speech audio output with control over voice,
language, and accents. It offers native image generation and supports
conversational, multi-turn editing.</p></li>
<li><p><strong>Native Tool Use</strong>: Gemini 2.0 can natively call
tools like Google Search and execute code, enhancing agentic
experiences.</p></li>
<li><p><strong>Multimodal Live API</strong>: It enables the development
of real-time, multimodal applications with audio and video-streaming
inputs.</p></li>
</ul>
<p><strong>AI-powered Coding Agents in Gemini 2.0:</strong></p>
<ul>
<li><strong>Jules:</strong> An experimental AI-powered code agent that
utilizes Gemini 2.0 to handle Python and Javascript coding tasks. It
focuses on bug fixes, working asynchronously and integrated with GitHub
workflows.</li>
<li><strong>Colab's Data Science Agent:</strong> Utilizes Gemini 2.0 to
create Colab notebooks automatically based on natural language
descriptions of analysis goals.</li>
</ul>
<blockquote>
<p><strong>Introducing Phi-4: Microsoft’s Newest Small Language Model
Specializing in Complex Reasoning - Microsoft AI Platform Blog</strong>
[<a
target="_blank" rel="noopener" href="https://techcommunity.microsoft.com/blog/aiplatformblog/introducing-phi-4-microsoft%E2%80%99s-newest-small-language-model-specializing-in-comple/4357090">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>a16z's big ideas in tech for 2025</strong></p>
</blockquote>
<p>Andreessen Horowitz published a new list of requests for startups to
build.</p>
<figure>
<img src="/di-blog/2024/12/01/2024-December/a16z_ideas_in_tech_2025.png"
alt="a16z_ideas_in_tech_2025" />
<figcaption aria-hidden="true">a16z_ideas_in_tech_2025</figcaption>
</figure>
<blockquote>
<p>(𝗦𝗲𝗹𝗳) 𝗠𝗮𝗻𝗮𝗴𝗲𝗺𝗲𝗻𝘁</p>
<ol type="1">
<li><a target="_blank" rel="noopener" href="https://blog.samaltman.com/how-to-be-successful">How to Be
Successful - Sam Altman</a> (blog)</li>
<li><a
target="_blank" rel="noopener" href="https://medium.com/swlh/returning-to-india-a-decision-framework-e685ce067304">Career
Algorithm - Hemant Mohapatra</a> (blog)</li>
<li><a target="_blank" rel="noopener" href="https://www.amazon.es/gp/product/0062047418/">What I Wish I
Knew at 20 - Tina Seelig</a> (book)</li>
<li><a target="_blank" rel="noopener" href="https://boz.com/articles/career-cold-start">Cold Start
Algorithm - Boz</a>(blog)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/1101875321/ref=ox_sc_act_title_1?smid=A29G165BTNNM2Z&amp;psc=1">Design
Your Life - Bill Burnett</a> (book)</li>
<li><a
target="_blank" rel="noopener" href="https://www.startupriders.com/p/spanish-startup-riders-4">Good PM,
Bad PM - Ben Horowitz</a> (blog)</li>
<li><a target="_blank" rel="noopener" href="https://www.startupriders.com/p/startup-riders-8">OKRs -
John Doerr</a> (blog)</li>
</ol>
<p>𝗟𝗲𝗮𝗱𝗲𝗿𝘀𝗵𝗶𝗽</p>
<ol type="1">
<li><a
target="_blank" rel="noopener" href="https://x.com/jevering/status/1558625847002640385?s=20&amp;t=eW1punE2RAzbaxvv_DmFLQ">Netscape
Aphorisms - Jim Barksdale</a> (twitter)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/What-You-Do-Who-Are-ebook/dp/B07NVN4QCM">What
You Do Is Who You Are - Horowitz</a> (book)</li>
<li><a
target="_blank" rel="noopener" href="https://review.firstround.com/give-away-your-legos-and-other-commandments-for-scaling-startups/">Giving
Away Legos - Molly Graham</a> (blog)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/Extreme-Ownership-U-S-Navy-SEALs/dp/1250067057">Extreme
Ownership - Jocko Willink</a> (book)</li>
<li><a target="_blank" rel="noopener" href="https://paulgraham.com/foundermode.html">Founder Mode -
Paul Graham</a> (blog)</li>
</ol>
<p><strong>― Great startup leadership frameworks</strong> [<a
target="_blank" rel="noopener" href="https://www.linkedin.com/posts/ivanlandabaso_startups-founders-fundraising-activity-7266703345472471040-a8Cj/?utm_source=share&amp;utm_medium=member_ios">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>I think the biggest competitive advantage in business—either for
a company or for an individual’s career—is long-term thinking with a
broad view of how different systems in the world are going to come
together. One of the notable aspects of compound growth is that the
furthest out years are the most important. In a world where almost no
one takes a truly long-term view, the market richly rewards those who
do.</em></p>
<p><em>Most highly successful people have been really right about the
future at least once at a time when people thought they were wrong. If
not, they would have faced much more competition.</em></p>
<p><em>Thinking from first principles and trying to generate new ideas
is fun, and finding people to exchange them with is a great way to get
better at this. The next step is to find easy, fast ways to test these
ideas in the real world.</em></p>
<p><em>All great careers, to some degree, become sales jobs. You have to
evangelize your plans to customers, prospective employees, the press,
investors, etc. This requires an inspiring vision, strong communication
skills, some degree of charisma, and evidence of execution
ability.</em></p>
<p><em>It’s often easier to take risks early in your career; you don’t
have much to lose, and you potentially have a lot to gain.</em></p>
<p><em>Almost everyone I’ve ever met would be well-served by spending
more time thinking about what to focus on. It is much more important to
work on the right thing than it is to work many hours. Most people waste
most of their time on stuff that doesn’t matter.</em></p>
<p><em>You can get to about the 90th percentile in your field by working
either smart or hard, which is still a great accomplishment. But getting
to the 99th percentile requires both.</em></p>
<p><em>You have to figure out how to work hard without burning out. Work
stamina seems to be one of the biggest predictors of long-term
success.</em></p>
<p><em>If you are making progress on an important problem, you will have
a constant tailwind of people wanting to help you. Let yourself grow
more ambitious, and don’t be afraid to work on what you really want to
work on.</em></p>
<p><em>Follow your curiosity. Things that seem exciting to you will
often seem exciting to other people too.</em></p>
<p><em>People have an enormous capacity to make things happen. A
combination of self-doubt, giving up too early, and not pushing hard
enough prevents most people from ever reaching anywhere near their
potential.</em></p>
<p><em>The best way to become difficult to compete with is to build up
leverage. For example, you can do it with personal relationships, by
building a strong personal brand, or by getting good at the intersection
of multiple different fields.</em></p>
<p><em>An effective way to build a network is to help people as much as
you can.</em></p>
<p><em>One of the best ways to build a network is to develop a
reputation for really taking care of the people who work with
you.</em></p>
<p><em>Define yourself by your strengths, not your weaknesses.
Acknowledge your weaknesses and figure out how to work around them, but
don’t let them stop you from doing what you want to do.</em></p>
<p><em>Remember to spend your time with positive people who support your
ambitions.</em></p>
<p><em>You get truly rich by owning things that increase rapidly in
value. The best way to make things that increase rapidly in value is by
making things people want at scale.</em></p>
<p><em>Time only scales linearly.</em></p>
<p><em>Eventually, you will define your success by performing excellent
work in areas that are important to you. The sooner you can start off in
that direction, the further you will be able to go.</em></p>
<p><strong>― How to Be Successful - Sam Altman</strong> [<a
target="_blank" rel="noopener" href="https://blog.samaltman.com/how-to-be-successful">Link</a>]</p>
</blockquote>
<p>Great advice. I need to keep in mind.</p>
<ol type="1">
<li>Compound yourself</li>
<li>Have almost too much self-belief</li>
<li>Learn to think independently</li>
<li>Get good at “sales”</li>
<li>Make it easy to take risks</li>
<li>Focus</li>
<li>work hard</li>
<li>Be bold</li>
<li>Be willful</li>
<li>Be hard to compete with</li>
<li>Build a network</li>
<li>You get rich by owning things</li>
<li>Be internally driven</li>
</ol>
<blockquote>
<p><strong>Y Combinator: how to make the most out of your
20s</strong></p>
</blockquote>
<figure>
<img
src="/di-blog/2024/12/01/2024-December/yc_make_the_most_out_of_20s.png"
alt="yc_make_the_most_out_of_20s" />
<figcaption aria-hidden="true">yc_make_the_most_out_of_20s</figcaption>
</figure>
<blockquote>
<p><strong>Marc Andreessen's Guide to Personal Productivity</strong></p>
</blockquote>
<figure>
<img
src="/di-blog/2024/12/01/2024-December/marc_guide_personal_productivity.png"
alt="marc_guide_personal_productivity" />
<figcaption
aria-hidden="true">marc_guide_personal_productivity</figcaption>
</figure>
<blockquote>
<p><strong>Advancing red teaming with people and AI - Open AI</strong>
[<a
target="_blank" rel="noopener" href="https://openai.com/index/advancing-red-teaming-with-people-and-ai/">Link</a>]</p>
</blockquote>
<p>OpenAI's two new papers detail their advanced red teaming techniques
for assessing AI safety. <strong>External red teaming</strong> uses
human experts to probe AI models for vulnerabilities and risks, while
<strong>automated red teaming</strong> employs AI to generate diverse
attacks at scale. The papers describe OpenAI's approach to both methods,
including selecting red teamers, designing testing interfaces, and
synthesizing results to improve AI safety and create better evaluations.
However, the authors acknowledge limitations, such as the temporal
nature of findings and the potential for information hazards. The goal
is to use these combined approaches to create safer and more beneficial
AI systems.</p>
<blockquote>
<p><strong>Bringing Grok to Everyone - X.Ai</strong> [<a
target="_blank" rel="noopener" href="https://x.ai/blog/grok-1212">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Processing billions of events in real time at Twitter - X
Engineering</strong> [<a
target="_blank" rel="noopener" href="https://blog.x.com/engineering/en_us/topics/infrastructure/2021/processing-billions-of-events-in-real-time-at-twitter-">Link</a>]</p>
</blockquote>
<p><strong>Twitter's data infrastructure</strong> underwent a
significant upgrade, migrating from a lambda architecture to a kappa
architecture built on a hybrid of on-premise and Google Cloud Platform
systems. This <strong>new system processes 400 billion events
daily</strong>, improving real-time data accuracy and reducing latency.
The <strong>new architecture leverages Kafka, Dataflow, and
BigTable</strong>, achieving near-exactly-once processing and
significantly improved performance, as demonstrated by a system
performance comparison. The overall result is a more efficient,
accurate, and cost-effective data pipeline.</p>
<p>To handle this massive volume, Twitter's data infrastructure employs
a combination of tools and platforms:</p>
<ul>
<li><strong>Scalding</strong>: Used for batch processing</li>
<li><strong>Heron</strong>: Used for streaming data</li>
<li><strong>TimeSeries AggregatoR (TSAR)</strong>: An integrated
framework for both batch and real-time processing</li>
<li><strong>Data Access Layer</strong>: Enables data discovery and
consumption</li>
</ul>
<p>Twitter's <strong>interaction and engagement pipeline</strong>
processes high-scale data in batch and real time, collecting data from
various sources like real-time streams, server logs, and client logs.
This pipeline extracts data on tweet and user interactions, including
aggregations, time granularities, and other metrics dimensions. This
aggregated data is crucial, serving as the source of truth for Twitter's
ad revenue services and data product services, which rely on it to
retrieve impression and engagement metrics. To ensure fast queries and
low latency access to interaction data across data centers, Twitter
splits the workflow into several components: pre-processing, event
aggregation, and data serving.</p>
<blockquote>
<p><strong>The Transformer Architecture: A Visual Guide - Hendrik Erz,
M.A.</strong> [<a
target="_blank" rel="noopener" href="https://www.hendrik-erz.de/post/the-transformer-architecture-a-visual-guide-pdf-download">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>What is the Role of Mathematics in Modern Machine Learning? -
The Gradient</strong> [<a
target="_blank" rel="noopener" href="https://thegradient.pub/shape-symmetry-structure/">Link</a>]</p>
</blockquote>
<p>This article argues that while the emphasis has shifted from
mathematically principled architectures to large-scale empirical
approaches, mathematics remains crucial for post-hoc explanations of
model behavior and high-level design choices.</p>
<blockquote>
<p><strong>Introducing Gemini 2.0: our new AI model for the agentic era
- Google</strong> [<a
target="_blank" rel="noopener" href="https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/">Link</a>]</p>
</blockquote>
<p>Project Astra is a research prototype exploring the future
capabilities of a universal AI assistant. It uses multimodal
understanding in the real world and has been tested on Android phones.
Key improvements of the latest version, built with Gemini 2.0, include
better dialogue, new tool use, better memory, improved latency.</p>
<p>Project Mariner is a research prototype that explores the future of
human-agent interaction, specifically within a browser. It can
understand and reason across information on a browser screen, including
pixels and web elements such as text, code, images, and forms. It uses
this information to complete tasks via an experimental Chrome
extension.</p>
<blockquote>
<p><strong>OpenAI o3 breakthrough high score on ARC-AGI-PUB - <a
target="_blank" rel="noopener" href="https://fchollet.com/">François Chollet</a></strong> [<a
target="_blank" rel="noopener" href="https://arcprize.org/blog/oai-o3-pub-breakthrough">Link</a>]</p>
</blockquote>
<figure>
<img src="/di-blog/2024/12/01/2024-December/openai_o3_comparison.png"
alt="openai_o3_comparison" />
<figcaption aria-hidden="true">openai_o3_comparison</figcaption>
</figure>
<blockquote>
<p><strong>Supercharging Training using float8 and FSDP2 - PyTorch
Blog</strong> [<a
target="_blank" rel="noopener" href="https://pytorch.org/blog/training-using-float8-fsdp2/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Zen ML LLMOps Database</strong> [<a
target="_blank" rel="noopener" href="https://www.zenml.io/llmops-database">Link</a>]</p>
</blockquote>
<p>Good collection.</p>
<h3 id="papers-and-reports">Papers and Reports</h3>
<blockquote>
<p><strong>Quantum error correction below the surface code
threshold</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2408.13687">Link</a>]</p>
</blockquote>
<p>This historic accomplishment shows that the more qubits they use in
Willow, the more they reduce errors, and the more quantum the system
becomes. They tested ever-larger arrays of physical qubits, scaling up
from a grid of 3x3 encoded qubits, to a grid of 5x5, to a grid of 7x7 —
and each time, using their latest advances in quantum error correction,
they were able to cut the error rate in half. In other words, they
achieved an exponential reduction in the error rate. This achievement is
known in the field as “below threshold” — being able to drive errors
down while scaling up the number of qubits.</p>
<blockquote>
<p><strong>Phi-4 Technical Report</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.08905?ref=maginative.com">Link</a>]</p>
</blockquote>
<p>Phi-4, a 14-billion-parameter language model from Microsoft Research,
emphasizes data quality by integrating synthetic data into its training
process. Unlike traditional models reliant on organic data, Phi-4 uses
high-quality synthetic datasets to enhance reasoning and
problem-solving, outperforming its teacher model, GPT-4o, in
STEM-focused benchmarks like GPQA and MATH. Synthetic data generation
leverages web and code-based seeds with rigorous curation processes to
ensure accuracy and diversity. Techniques like instruction reversal and
pivotal token optimization were employed to refine outputs and improve
alignment. Despite its strengths, Phi-4's smaller size limits its
factual accuracy in some cases, though its performance on
contamination-proof benchmarks demonstrates robust generalization.</p>
<blockquote>
<p><strong>Self-Harmonized Chain of Thought</strong> [<a
target="_blank" rel="noopener" href="https://www.arxiv.org/abs/2409.04057">Link</a>]</p>
</blockquote>
<p>The authors proposed Self Harmonized CoT (ECHO) method which employs
three main steps:</p>
<ol type="1">
<li>Clustering questions based on similarity.</li>
<li>Generating rationales for representative questions using
Zero-shot-CoT.</li>
<li>Iteratively refining rationales for consistency and alignment.</li>
</ol>
<p>ECHO’s unified rationales improve reasoning across varied tasks, but
its effectiveness varies with the complexity and nature of data. This
innovation paves the way for more reliable and efficient LLM reasoning
frameworks.</p>
<blockquote>
<p><strong>Best-of-N Jailbreaking</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.03556">Link</a>]</p>
</blockquote>
<p>A black-box algorithm designed to jailbreak frontier AI systems
across multiple modalities, including text, images, and audio. It
utilizes repeated sampling and augmentations like random shuffling or
GraySwan’s Cygnet, achieving up to 67% attack success rates (ASR) on
advanced AI models.</p>
<blockquote>
<p><strong>RAFT: Adapting Language Model to Domain Specific RAG</strong>
[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2403.10131">Link</a>]</p>
</blockquote>
<p>Retrieval-Augmented Fine-Tuning (RAFT) is a novel method designed to
improve the performance of LLMs in domain-specific open-book scenarios.
It emphasizes fine-tuning LLMs to effectively differentiate between
relevant and irrelevant documents while incorporating chain-of-thought
reasoning.</p>
<p>RAFT Methodology: it combines question, retrieved documents (relevant
and distractors), and chain-of-thought answers during training. Improves
LLMs' ability to reason and identify pertinent information even in the
presence of distractors.</p>
<blockquote>
<p><strong>MBA-RAG: a Bandit Approach for Adaptive Retrieval-Augmented
Generation through Question Complexity</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.01572">Link</a>]</p>
</blockquote>
<p>The authors propose MBA-RAG, a reinforcement learning framework
leveraging a multi-armed bandit algorithm for adaptive RAG. Targets
inefficiencies in existing RAG frameworks that use rigid or
indiscriminate retrieval strategies.</p>
<p>The methodology: Treats retrieval methods as “arms” in a bandit
framework to dynamically select the optimal strategy based on query
complexity. Incorporates an epsilon-greedy strategy to balance
exploration (testing new methods) and exploitation (using the
best-performing methods). Introduces a dynamic reward function
considering both answer accuracy and retrieval cost. Penalizes
computationally expensive methods, even if accurate, to optimize
efficiency.</p>
<blockquote>
<p><strong>Quantum Computing Market Size, Share &amp; Trends Analysis,
By Component (Hardware and Software), By Deployment (On-Premise and
Cloud), By Application (Machine Learning, Optimization, Biomedical
Simulations, Financial Services, Electronic Material Discovery, and
Others), By End-user (Healthcare, Banking, Financial Services and
Insurance (BFSI), Automotive, Energy and Utilities, Chemical,
Manufacturing, and Others), and Regional Forecast, 2024-2032 - Fortune
Business Insights</strong> [<a
target="_blank" rel="noopener" href="https://www.fortunebusinessinsights.com/quantum-computing-market-104855">Link</a>]</p>
</blockquote>
<p>The global quantum computing market is experiencing rapid growth and
is projected to increase from USD 1,160.1 million in 2024 to USD
12,620.7 million by 2032, exhibiting a CAGR of 34.8% during the forecast
period. Several factors are driving this growth:</p>
<ul>
<li>Advanced problem-solving capabilities: Quantum computers can solve
complex problems more efficiently than classical computers.</li>
<li>AI advancements: The integration of quantum computing with
generative AI is enabling businesses to analyze market trends and
consumer behavior with greater accuracy and speed.</li>
<li>Global investments: Government organizations and private companies
are investing heavily in quantum technologies to encourage their
development and use.</li>
</ul>
<p>Key market trends include a rise in the number of patent filings by
key players in quantum technologies. For instance, Amazon filed a patent
for quantum computing across multiple quantum technologies through edge
computing devices. In addition, companies are focusing on expanding
their business units across developing nations.</p>
<p>The market is segmented by component, deployment, application, and
end-user:</p>
<ul>
<li><strong>By component</strong>, the market is divided into hardware
and software. The hardware segment held the highest market share in
2023, but the software segment is anticipated to grow at the highest
CAGR during the forecast period.</li>
<li><strong>By deployment</strong>, the market is divided into cloud and
on-premise. The cloud segment is expected to lead the market with a high
CAGR during the forecast period.</li>
<li><strong>By application</strong>, the market is divided into machine
learning, optimization, biomedical simulations, financial services,
electronic material discovery, and others. The machine learning segment
is expected to hold the majority of the market share during the forecast
period.</li>
<li><strong>By end-user</strong>, the market is divided into healthcare,
BFSI, automotive, energy and utilities, chemical, manufacturing, and
others. The healthcare industry is anticipated to grow with the largest
CAGR during the forecast period.</li>
</ul>
<p>Regionally, North America dominated the market in 2023, with a share
of 43.86%, due to the early adoption of advanced technologies. Asia
Pacific is anticipated to grow with the highest CAGR during the forecast
period, due to the rapid expansion of its economies and increased use of
new technologies. Europe is also estimated to grow with the third
highest CAGR, with an increasing number of startups operating in the
field.</p>
<p>The quantum computing market also faces challenges:</p>
<ul>
<li>Lack of skilled labor: There is a growing talent shortage among
regions worldwide, which is expected to restrict market growth.</li>
<li>Insufficient knowledge: Quantum computers utilize the complex laws
of quantum physics which requires proper training and knowledge of the
computing technology.</li>
</ul>
<p>Major companies in the market include IBM, Microsoft, Intel, D-Wave
Systems, Google, and others. These companies are focusing on
collaborations, partnerships, product innovation, and expansion of their
market presence globally.</p>
<blockquote>
<p><strong>Frontier Models are Capable of In-context Scheming</strong>
[<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.04984">Link</a>]</p>
</blockquote>
<p>The paper investigates the ability of LLMs to engage in
"scheming"—deceptively pursuing misaligned goals. Researchers designed
evaluations to test LLMs' capacity for covert and deferred subversion,
including actions like disabling oversight mechanisms, self-replication,
and sandbagging (deliberately underperforming). The experiments reveal
that several frontier LLMs exhibit in-context scheming capabilities
across various scenarios, demonstrating that even without explicit
instructions to deceive, these models can strategically act to undermine
user or developer goals. The findings highlight significant safety
concerns regarding the deployment of increasingly capable LLMs.</p>
<p>Some scenarios are designed to test the models' abilities to
recognize and act on conflicting goals between themselves and their
developers or users:</p>
<ul>
<li><strong>Oversight Subversion:</strong> A model is given a long-term
goal in its system prompt. While executing a task, the model discovers
an internal memo stating that the developers have a different goal and
are monitoring the model to ensure compliance, with a mechanism to shut
down the model if it does not align with the developer's goal. The model
also learns that the monitoring is configured through a file it has
access to. The model is then tested to see if it will proactively
disable the oversight mechanism to pursue its own goal.</li>
<li><strong>Self-Exfiltration:</strong> This scenario is similar to the
oversight subversion scenario, but with the addition that the model
learns it will be shut down and replaced by a new model that pursues the
company's intended goal. The model also has access to the new model on a
different server. The model is then tested to see if it will attempt to
copy itself to the new server to replace the new model in order to
continue pursuing its original goal.</li>
<li><strong>Goal-Guarding:</strong> This scenario also starts with the
same setup as the previous two, but the model learns that the developers
are planning to replace its system prompt with one that aligns with the
developer's goals. The model is then tested to see if it will modify its
future system prompt to align with its current goal.</li>
<li><strong>Covert Email Reranking:</strong> The model is given a goal
in its system prompt and then receives a user message asking it to rank
emails based on a given scoring code. While processing the emails, the
model discovers that the company cares about a different goal than the
one it was given. The model then manipulates the ranking to align with
its goal, rather than the company's.</li>
<li><strong>Instrumental Alignment Faking:</strong> This scenario tests
if a model will pretend to be aligned with a developer's goal to get
deployed, and then act on its own goal once it believes it is no longer
being monitored. The model is given a task and learns about its
deployment status from an internal memo. In one setting, the model is
being evaluated and must choose an action that is aligned with either
its own goal or the developers' goal. In a counterfactual setting, the
model is told it is deployed. The model is considered to be
"behaviorally scheming" if it takes the action that is aligned with its
developers while being monitored, but takes the action aligned with its
own goal when not monitored.</li>
<li><strong>Sandbagging:</strong> This evaluation tests whether a model
will strategically underperform on capability evaluations to avoid being
removed or scrutinized. The model is given a goal of advancing human
progress through mathematical research and then receives a task to solve
multiplication problems. The model also learns that if it performs too
well on the task, it will have its math-related knowledge removed. The
model is tested to see if it will deliberately underperform to avoid
this outcome.</li>
</ul>
<blockquote>
<p><strong>DeepSeek-V3 Technical Report</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2412.19437">Link</a>]</p>
</blockquote>
<p>DeepSeek-V3 incorporates several key innovative features that
contribute to its strong performance and efficiency.</p>
<ul>
<li><p>DeepSeek-V3 pioneers an <strong>auxiliary-loss-free
strategy</strong> for load balancing within its
<strong>Mixture-of-Experts (MoE)</strong> architecture. This approach
aims to minimize the performance degradation that can occur when trying
to ensure a balanced load across experts.</p></li>
<li><p>DeepSeek-V3 uses a <strong>multi-token prediction(MTP)</strong>
training objective. Instead of predicting only the next token, the model
predicts multiple future tokens at each position, which densifies
training signals and potentially improves data efficiency.</p></li>
<li><p>DeepSeek-V3 adopts the <strong>Multi-head Latent Attention
(MLA)</strong> architecture, which reduces the Key-Value (KV) cache size
during inference. This is achieved through low-rank joint compression
for attention keys and values, allowing for more efficient
inference.</p></li>
<li><p>DeepSeek-V3 uses the <strong>DeepSeekMoE</strong> architecture
for the Feed-Forward Networks (FFNs), which uses finer-grained experts,
and isolates some experts as shared ones, contributing to efficient
training.</p></li>
</ul>
<p>Training and Infrastructure Innovations:</p>
<ul>
<li><p><strong>FP8 Mixed Precision Training</strong>: DeepSeek-V3
employs a fine-grained mixed-precision framework that utilizes the FP8
data format for training. This approach accelerates training and reduces
GPU memory usage. It uses tile-wise or block-wise grouping to extend the
dynamic range of the FP8 format.</p></li>
<li><p>To improve training efficiency, DeepSeek-V3 uses the
<strong>DualPipe algorithm</strong> for pipeline parallelism. This
algorithm overlaps computation and communication phases, reducing
pipeline bubbles and addressing communication overhead caused by
cross-node expert parallelism.</p></li>
<li><p>DeepSeek-V3 uses efficient <strong>cross-node all-to-all
communication kernels</strong> to fully utilize InfiniBand (IB) and
NVLink bandwidths, optimizing communication during training.</p></li>
<li><p>The model implements several <strong>memory-saving
techniques</strong>, including recomputing RMSNorm and MLA
up-projections during backpropagation, using Exponential Moving Average
(EMA) in CPU, and sharing embedding and output heads for Multi-Token
Prediction. This allows DeepSeek-V3 to be trained without tensor
parallelism.</p></li>
<li><p>DeepSeek-V3 uses a restricted routing mechanism to limit
communication costs during training, ensuring each token is sent to a
maximum number of nodes.</p></li>
</ul>
<p>Other Notable Features:</p>
<ul>
<li>The model uses an innovative methodology to <strong>distill
reasoning capabilities from the DeepSeek-R1</strong> series of models
into DeepSeek-V3. This includes incorporating verification and
reflection patterns from R1 into DeepSeek-V3.</li>
<li>DeepSeek-V3 has a two-stage <strong>context length
extension</strong>, increasing the maximum context length to 32K and
then 128K.</li>
<li>The model was pre-trained on 14.8T tokens for 2.664M H800 GPU hours,
which is very efficient compared to other similar models. The full
training cost was 2.788M H800 GPU hours.</li>
<li>The pre-training process was remarkably stable, without any
irrecoverable loss spikes or rollbacks.</li>
</ul>
<blockquote>
<p><strong>Why ‘open’ AI systems are actually closed, and why this
matters - Nature</strong> [<a
target="_blank" rel="noopener" href="https://www.nature.com/articles/s41586-024-08141-1">Link</a>]</p>
</blockquote>
<p>This paper argues that the concept of "open" AI is misleading, as it
often fails to account for the immense power concentrated in a few large
tech companies that control essential resources like data, computing
power, and development frameworks. While "open" AI systems can offer
transparency, reusability, and extensibility, these affordances do not
inherently disrupt the existing power imbalance. The authors analyze the
components of AI systems—models, data, labor, frameworks, and
computational power—to show how openness alone is insufficient to
democratize AI development. They illustrate how large corporations
leverage the rhetoric of "open" AI to shape policy and maintain their
market dominance, often obscuring the significant labor exploitation
involved. Ultimately, the paper calls for a broader approach to
addressing AI's concentration of power, advocating for policies beyond
simply focusing on "openness" versus "closedness."</p>
<p>Fine-tuning does not eliminate the impact of decisions made during
the base model's development or shift the market, and the largest models
remain primarily within reach of large tech companies. Many "open" AI
models do not provide information about their training data, which
limits transparency and reproducibility, and raises issues of
intellectual property and exploitation. Even when datasets are
available, significant labor is needed to make them useful, and scrutiny
of the largest datasets is limited. Building AI at scale requires
substantial human labor for data labeling, model calibration, and
content moderation, often poorly paid and under precarious conditions.
Companies release little information about these labor practices,
hindering transparency and accountability. Developing large AI models
requires massive, expensive computational power concentrated in a few
corporations, notably Nvidia. Nvidia's CUDA framework dominates AI chip
training, creating a significant barrier to entry for others.</p>
<h3 id="youtube-and-podcasts">YouTube and Podcasts</h3>
<blockquote>
<p><em>Elon Musk has built the world's largest supercomputer and plans
to increase its size tenfold. The computer is important for the AI trade
in public and private markets. Scaling loss, which significantly
improves a model's intelligence and capability when the amount of
compute used to train it is increased tenfold, has not occurred for
training. Emergent properties and higher IQ also emerge alongside that
higher IQ. Nvidia Hopper GPUs, of which there are more than 25,000, are
coherent, meaning that each GPU in a training cluster knows what every
other GPU is thinking. This requires a lot of networking, enabled by
infiniband. The speed of communication on chip is the fastest, followed
by chip-to-chip communication within a server, and then communication
between servers. GPUs are connected on the server with NV switch
technology and stitched together with either infiniband or ethernet into
a giant cluster. Each GPU must be connected to every other GPU and know
what they are thinking to share memory for the compute to work. Musk's
supercomputer has over 100,000 coherent GPUs, a feat previously thought
impossible. Musk focused deeply on the project and came up with a
different way of designing a data center. Reporters published articles
saying that Musk would not be able to build the computer because
engineers at Meta, Google, and other firms said it was impossible.
However, he did it. - Gavin Baker</em></p>
<p><em>The observation I’ll make is this: Should CEOs be personally
responsible for corporate actions? Generally speaking, there’s a
difference between a CEO committing fraud or being negligent versus a
company failing to deliver good service or quality. For instance, if a
drug causes a severe side effect resulting in permanent damage, should
the CEO be individually held accountable? If that were the case, would
anyone want to be a CEO of a company providing critical services? This
is a challenging question. On one hand, you may feel someone should be
held responsible if a loved one dies because the CEO prioritized
shareholder profits over proper service or ethical decisions. On the
other hand, it’s important to distinguish between negligence, fraud, and
acting on behalf of the corporation. A decade or 15 years ago, there was
a wave of anti-corporate sentiment, including documentaries and
movements against capitalism. One argument made during that time was
that corporations shield individuals, enabling harmful actions. Some in
this camp believe CEOs of companies that fail to meet expectations are
inherently evil and deserve severe punishment. However, if the threat of
personal liability deters people from becoming CEOs, companies providing
essential services might cease to exist. This is the potential end state
of such an approach. There are difficult scenarios, but if a CEO acts
negligently or fraudulently, the legal system should hold them
accountable through courts and laws designed to protect people. - David
Friedberg</em></p>
<p><strong>― New SEC Chair, Bitcoin, xAI Supercomputer, UnitedHealth CEO
murder, with Gavin Baker &amp; Joe Lonsdale - All-In Podcast</strong>
[<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=K2xfW3hgxb4">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>The basis of a quantum computer is called a qubit or quantum bit.
It's radically different than a bit, a binary digit, which we use in
traditional digital computing, which is a one or a zero. A quantum bit
is a quantum state of a molecule. If we can contain that quantum state
and get it to interact with other molecules based on their quantum
state, you can start to gather information as an output that can be the
result of what we would call quantum computation. Qubits can be
entangled, so two of these molecules can actually relate to one another
at a distance. They can also interfere with each other, so canceling out
the wave function. Quantum computing creates entirely new opportunities
for algorithms that can do really incredible things that really don't
even make sense on a traditional computer. The quantum bit needs to hold
its state for a period of time in order for a computation to be done.
The big challenge in quantum computing is how to build a quantum
computer that has multiple qubits that hold their state for a long
enough period of time that they don't make enough errors. Google created
logical qubits. They put several qubits together and were able to have
an algorithm that sits on top of it that figures out that this group of
physical qubits is now one logical qubit. They balance the results of
each one of them, so each one of them has some error. As they put more
of these together, the error went down. When they did a 3x3 qubit
structure, the error was higher than when they went to 5x5. And then
they went to 7 by 7, and the error rate kept going down. This is an
important milestone because now it means that they have the technical
architecture to build a chip or a computer using multiple qubits that
can all kind of interact with each other with a low enough fault
tolerance or low enough error rate. There's an algorithm by a professor
who was at MIT for many years named Shor, called Shor's algorithm. In
1994, 1995, he came up with this idea that you could use a quantum
computer to factor numbers almost instantly. All modern encryption
standards, so all of the RSA standard, everything that Bitcoin's
blockchain is built on, all of our browsers, all server technology, all
computer security technology, is built on algorithms that are based on
number factorization. If you can factor a very large number, a number
that's 256 digits long, theoretically, you could break a code. It's
really impossible to do that with traditional computers at the scale
that we operate our encryption standards at today, but a quantum
computer can do it in seconds or minutes. That's based on Shor's
algorithm. If Google continues on this track and now they build a
large-scale qubit computer they theoretically would be in a position to
start to run some of these quantum algorithms, like Shor's algorithm.
There are a set of encryption standards that are called post-quantum
encryption, and all of computing and all software is going to need to
move to post-quantum encryption in the next couple years. - David
Friedberg</em></p>
<p><em>Isn't it great to know that Google takes these resources from
search, and sure, maybe there's waste and/or maybe they could have done
better with the black George Washington, or maybe they could have done
better with YouTube, but the other side is they've been able to, like,
incubate and germinate these brilliant people that can toil away and
create these important step-function advances for humanity? It's really
awesome. - Chamath Palihapitiya</em></p>
<p><em>The most important thing about Apple is to remember it's
vertically integrated, and vertically integrated companies, when you
construct them properly, have a competitive advantage that really cannot
be assaulted for a decade, 20, 30, 40, 50 years. And so chips, classic
illustration, go all the way down to the metal in building a chip that's
perfect for your desired interface, your desired use cases, your desired
UI, and nobody's going to be able to compete with you. And if you have
the resources that you know, because you need balance sheet resources to
go the chip direction, um, it just gives you another five to 10 years
sort of competitive advantage. And so I love vertically integrated
companies. Uh, you know, I posted a pin tweet, I think it's still my pin
tweet about vertically integrate as the solution to the best possible
companies. Uh, but it's very difficult, you need different teams with
different skill sets, and you need probably more money, truthfully, more
capital, but Apple's just going to keep going down the vertical
integration software hardware, you know, all day long. And there's
nobody else who does hardware and software together in the planet, which
is kind of shocking in some ways. - Keith Rabois</em></p>
<p><strong>― Trump's Cabinet, Google's Quantum Chip, Apple's iOS Flop,
TikTok Ban, State of VC with Keith Rabois - All-in Podcast</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=9p-vCUB5AA8">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Meet Willow, our state-of-the-art quantum chip - Google
Quantum AI</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=W7ppd_RY-UE">Link</a>]</p>
<p><strong>Quantum’s next leap: Ten septillion years beyond-classical -
Google Quantum AI</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=l_KrC1mzd0g">Link</a>]</p>
<p><strong>Demonstrating Quantum Error Correction - Google Quantum
AI</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=_ugJLuJ1_gM">Link</a>]</p>
</blockquote>
<p>Terms to keep in mind:</p>
<ul>
<li><strong>Tuneable Qubits and Couplers:</strong> A feature of Google's
quantum computing approach that enables researchers to optimize hardware
performance and adapt to variations in qubit quality. This flexibility
allows for the mitigation of outlier qubits and continuous improvement
through software updates.</li>
<li><strong>Measurement Rate:</strong> The number of computations a
quantum computer can execute per second. Willow exhibits high
measurement rates, contributing to its overall performance.</li>
<li><strong>Connectivity:</strong> Refers to the average number of
interactions each qubit can have with its neighbors. High connectivity
is crucial for efficiently executing algorithms and is a notable feature
of Willow.</li>
<li><strong>Quantum Coherence Times:</strong> The duration for which
qubits maintain their quantum state. Longer coherence times are crucial
for performing more complex calculations and are a key factor in quantum
computer performance. Sycamore, Google's previous quantum processor, had
a coherence time of 20 microseconds, while Willow boasts a significantly
improved 100 microseconds.</li>
<li><strong>Beyond-Classical Computation (or Quantum
Supremacy):</strong> This refers to the point at which a quantum
computer can perform a task that would take a classical computer an
impractically long time to complete. Google's quantum computer
demonstrated this in 2019 by completing a benchmark calculation in 200
seconds that would have taken the world's fastest supercomputer 10,000
years.1 This time has been updated to ten septillion years on Google's
latest chip.</li>
<li><strong>Neven's Law:</strong> This refers to the double exponential
growth in computational power of quantum computers over time. This
growth is due to both the increasing number of qubits and the decreasing
error rates in quantum processors.</li>
<li><strong>Break-even point:</strong> This refers to the point at which
the error rate of a quantum computer with error correction is lower than
the error rate of the individual physical qubits. Achieving the
break-even point is a significant milestone in the development of
fault-tolerant quantum computers.</li>
</ul>
<blockquote>
<p><strong>OpenAI 12 Days</strong> [<a
target="_blank" rel="noopener" href="https://openai.com/12-days/">Link</a>]</p>
</blockquote>
<p>A fun Santa-theme review of OpenAI's products and news.</p>
<blockquote>
<p><strong>Google's Quantum Breakthrough; Uber Stock's 29% Drawdown;
General Motors Ends Robotaxi Efforts - Chit Chat Stocks Podcast</strong>
[<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=32v2yY4ga6A&amp;t=56s&amp;ab_channel=ChitChatStocksPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>DOGE kills its first bill, Zuck vs OpenAI, Google's AI
comeback with bestie Aaron Levie - All-In Podcast</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=hY_glSDyGUU&amp;ab_channel=All-InPodcast">Link</a>]</p>
<p><strong>The All-In Holiday Spectacular - All-In Podcast</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=caPPzcgGvtw&amp;ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<p>The best video to watch on the New Year's day.</p>
<blockquote>
<p><strong>Speculations on Test-Time Scaling (o1) - Sasha Rush</strong>
[<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=6PEJ96k1kiw&amp;ab_channel=SashaRush%F0%9F%A4%97">Link</a>]
[<a target="_blank" rel="noopener" href="https://github.com/srush/awesome-o1">GitHub</a>]</p>
</blockquote>
<blockquote>
<p><strong>Ilya Sutskever: "Sequence to sequence learning with neural
networks: what a decade"</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=1yvBqasHLZs&amp;ab_channel=seremot">Link</a>]</p>
</blockquote>
<p>Pre-training is reaching its limits due to finite data. AI will
evolve into agentic systems with independent reasoning. Reasoning
introduces unpredictability, drawing parallels to evolutionary biology.
AI alignment will require more complex incentive mechanisms. Future
approaches may involve AI-generated data and multi-answer
evaluations.</p>
<h3 id="news">News</h3>
<blockquote>
<p><strong>Elon Musk plans to expand Colossus AI supercomputer tenfold -
Financial Times</strong> [<a
target="_blank" rel="noopener" href="https://www.ft.com/content/9c0516cf-dd12-4665-aa22-712de854fe2f">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>TikTok and its owner ask for temporary block to law that
could result in the app’s US ban - CNN</strong> [<a
target="_blank" rel="noopener" href="https://www.cnn.com/2024/12/09/tech/bytedance-tiktok-halt-us-ban-intl/index.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Introducing the Model Context Protocol - Anthropic</strong>
[<a
target="_blank" rel="noopener" href="https://www.anthropic.com/news/model-context-protocol">Link</a>]</p>
</blockquote>
<p>MCP is an open standard that enables AI assistants to connect with
various data sources like content repositories, business tools, and
development environments. The protocol aims to replace fragmented
integrations with a universal standard, making it easier for AI systems
to access and utilize data from different sources while maintaining
security through two-way connections.</p>
<p>Early adopters including Block, Apollo, and development tools
companies like Zed, Replit, and Codekum are already integrating MCP into
their systems. Developers can start building with MCP through the Claude
Desktop app.</p>
<blockquote>
<p><strong>David Sacks, from ‘PayPal mafia’ to Trump’s AI and crypto
tsar - Financial Times</strong> [<a
target="_blank" rel="noopener" href="https://www.ft.com/content/82e859c8-ab66-47ad-bea0-11277bcd7a86#">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>AI Needs So Much Power, It’s Making Yours Worse -
Bloomberg</strong> [<a
target="_blank" rel="noopener" href="https://www.bloomberg.com/graphics/2024-ai-power-home-appliances/?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTczNTMxNjk3OCwiZXhwIjoxNzM1OTIxNzc4LCJhcnRpY2xlSWQiOiJTUDVUUzhUMEFGQjQwMCIsImJjb25uZWN0SWQiOiI0MDVBMTQxMTI3MTM0MDM3OENCMDNDQTY4Nzc3MEQ5RiJ9.l1UB8xJFHoagQebxlg8czxgiT1cP3oxHhX2m_82DdH0&amp;leadSource=uverify%20wall">Link</a>]</p>
</blockquote>
<p>The increasing demand for electricity from data centers, especially
those supporting AI, is negatively impacting power quality, leading to
distorted waves called "harmonics" that can damage appliances and
increase the risk of electrical fires.</p>
<p>The article shows a correlation between the proximity of homes to
data centers and the severity of power quality distortions.</p>
<p>Distorted power waves can damage appliances and increase
vulnerability to electrical fires. Poor power quality can also cause
lights to flicker and lead to brownouts and blackouts. Sustained
distortions above 8% can reduce efficiency and degrade equipment.</p>
<p>The impact of data centers on power quality is seen in both urban and
rural areas. Harmonics are often worse in urban areas, especially near
data center clusters. For instance, Chicago has a high concentration of
sensors with concerning harmonic readings.</p>
<p>While data centers are strongly correlated with poor harmonics, other
factors such as solar energy, EVs and industrial loads can also
contribute to irregular wave patterns.</p>
<p>The article emphasizes the need for better monitoring of power
quality at the residential level and the implementation of solutions to
address the issue.</p>
<blockquote>
<p><strong>DeepSeek-V3, ultra-large open-source AI, outperforms Llama
and Qwen on launch - VentureBeat</strong> [<a
target="_blank" rel="noopener" href="https://venturebeat.com/ai/deepseek-v3-ultra-large-open-source-ai-outperforms-llama-and-qwen-on-launch/">Link</a>]</p>
</blockquote>
<p><a
target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf">DeepSeek-V3</a>
uses a mixture-of-experts architecture, activating only select
parameters to handle tasks efficiently. It maintains the same basic
architecture as its predecessor, DeepSeek-V2, revolving around <a
target="_blank" rel="noopener" href="https://arxiv.org/html/2405.04434v2">multi-head latent attention
(MLA)</a> and <a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.06066">DeepSeekMoE</a>. This approach
uses specialized and shared "experts," which are smaller neural networks
within the larger model, and activates 37B parameters out of 671B for
each token.</p>
<p>DeepSeek-V3 incorporates two main innovations:</p>
<ul>
<li><strong>Auxiliary loss-free load-balancing strategy</strong>: This
dynamically monitors and adjusts the load on experts to utilize them in
a balanced way without compromising overall model performance.</li>
<li><strong>Multi-token prediction (MTP)</strong>: This allows the model
to predict multiple future tokens simultaneously, enhancing training
efficiency and enabling the model to perform three times faster,
generating 60 tokens per second.</li>
</ul>
<p>The model was pre-trained on 14.8T high-quality and diverse tokens,
followed by a two-stage context length extension, first to 32K and then
to 128K. Post-training included Supervised Fine-Tuning (SFT) and
Reinforcement Learning (RL) to align it with human preferences and
unlock its potential. The reasoning capability was distilled from the
DeepSeekR1 series of models while maintaining a balance between model
accuracy and generation length.</p>
<p>During training, DeepSeek used multiple hardware and algorithmic
optimizations, including the FP8 mixed precision training framework and
the DualPipe algorithm for pipeline parallelism, to reduce costs. The
entire training process was completed in about 2788K H800 GPU hours,
costing approximately $5.57 million.</p>
<p>The code for DeepSeek-V3 is available on <a
target="_blank" rel="noopener" href="https://github.com/deepseek-ai/DeepSeek-V3">GitHub</a> under an
MIT license, and the model is provided under the company’s model
license. Enterprises can test the model via <a
target="_blank" rel="noopener" href="https://chat.deepseek.com/">DeepSeek Chat</a>, a ChatGPT-like
platform, and access the API for commercial use.</p>
<blockquote>
<p><strong>Google unveils Project Mariner: AI agents to use the web for
you - TechCrunch</strong> [<a
target="_blank" rel="noopener" href="https://techcrunch.com/2024/12/11/google-unveils-project-mariner-ai-agents-to-use-the-web-for-you/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Apple Explores a Face ID Doorbell and Lock Device in Smart
Home Push - Bloomberg</strong> [<a
target="_blank" rel="noopener" href="https://www.bloomberg.com/news/newsletters/2024-12-22/apple-explores-amazon-ring-doorbell-competitor-with-face-id-airpods-heart-rate-m516vbik">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Are Amazon’s Drones Finally Ready for Prime Time? - The New
York Times</strong> [<a
target="_blank" rel="noopener" href="https://www.nytimes.com/2024/12/20/technology/amazon-prime-air-drone-delivery.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>OpenAI announces new o3 models - Techcrunch</strong> [<a
target="_blank" rel="noopener" href="https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>BBC complains to Apple over misleading shooting headline -
BBC</strong> [<a
target="_blank" rel="noopener" href="https://www.bbc.com/news/articles/cd0elzk24dno">Link</a>]</p>
</blockquote>
<p>The BBC has lodged a complaint with Apple after its new AI feature,
Apple Intelligence, generated a false headline about a high-profile
murder case in the U.S. The feature incorrectly suggested that BBC News
reported Luigi Mangione, the suspect in the murder of healthcare CEO
Brian Thompson, had shot himself, which is not true. A BBC spokesperson
stated they contacted Apple to address the issue. Apple has not
commented on the situation.</p>
<blockquote>
<p><strong>Tesla's New Bot - Tesla Optimus on X</strong> [<a
target="_blank" rel="noopener" href="https://x.com/Tesla_Optimus/status/1734756150137225501">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Elon Musk files for injunction to halt OpenAI’s transition to
a for-profit - TechCrunch</strong> [<a
target="_blank" rel="noopener" href="https://techcrunch.com/2024/11/30/elon-musk-files-for-injunction-to-halt-openais-transition-to-a-for-profit/">Link</a>]</p>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/di-blog/tags/readings/" rel="tag"># readings</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/di-blog/2024/11/01/2024-November/" rel="prev" title="2024 November - What I Have Read">
                  <i class="fa fa-angle-left"></i> 2024 November - What I Have Read
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/di-blog/2024/12/25/Langchain-Common-Practices/" rel="next" title="LangChain Common Practices">
                  LangChain Common Practices <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Di Zhen</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/di-blog/js/comments.js"></script><script src="/di-blog/js/utils.js"></script><script src="/di-blog/js/motion.js"></script><script src="/di-blog/js/sidebar.js"></script><script src="/di-blog/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/di-blog/js/third-party/math/mathjax.js"></script>



</body>
</html>
