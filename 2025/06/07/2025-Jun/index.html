<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/di-blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/di-blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/di-blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/di-blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/di-blog/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jokerdii.github.io","root":"/di-blog/","images":"/di-blog/images","scheme":"Muse","darkmode":true,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/di-blog/js/config.js"></script>

    <meta name="description" content="Substack  The frontier isn’t volume—it’s discernment. And in that shift, taste has become a survival skill. Because when abundance is infinite, attention is everything. And what you give your attentio">
<meta property="og:type" content="article">
<meta property="og:title" content="2025 Jun - What I Have Read">
<meta property="og:url" content="https://jokerdii.github.io/di-blog/2025/06/07/2025-Jun/index.html">
<meta property="og:site_name" content="Di&#39;s Blog">
<meta property="og:description" content="Substack  The frontier isn’t volume—it’s discernment. And in that shift, taste has become a survival skill. Because when abundance is infinite, attention is everything. And what you give your attentio">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jokerdii.github.io/di-blog/2025/06/07/2025-Jun/four-stages-of-marketplaces.png">
<meta property="og:image" content="https://jokerdii.github.io/di-blog/2025/06/07/2025-Jun/pricing_and_limits.png">
<meta property="article:published_time" content="2025-06-07T20:31:07.000Z">
<meta property="article:modified_time" content="2025-06-07T20:31:07.000Z">
<meta property="article:author" content="Di Zhen">
<meta property="article:tag" content="readings">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jokerdii.github.io/di-blog/2025/06/07/2025-Jun/four-stages-of-marketplaces.png">


<link rel="canonical" href="https://jokerdii.github.io/di-blog/2025/06/07/2025-Jun/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jokerdii.github.io/di-blog/2025/06/07/2025-Jun/","path":"2025/06/07/2025-Jun/","title":"2025 Jun - What I Have Read"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>2025 Jun - What I Have Read | Di's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/di-blog/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/di-blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Di's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#substack"><span class="nav-number">1.</span> <span class="nav-text">Substack</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#papers-and-reports"><span class="nav-number">2.</span> <span class="nav-text">Papers and Reports</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#youtube-and-podcasts"><span class="nav-number">3.</span> <span class="nav-text">YouTube and Podcasts</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#articles-and-blogs"><span class="nav-number">4.</span> <span class="nav-text">Articles and Blogs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#news"><span class="nav-number">5.</span> <span class="nav-text">News</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#new-book-list"><span class="nav-number">6.</span> <span class="nav-text">New Book List</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Di Zhen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/di-blog/archives/">
          <span class="site-state-item-count">43</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/di-blog/2025/06/07/2025-Jun/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/di-blog/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="2025 Jun - What I Have Read | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          2025 Jun - What I Have Read
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-06-07 16:31:07" itemprop="dateCreated datePublished" datetime="2025-06-07T16:31:07-04:00">2025-06-07</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="substack">Substack</h2>
<blockquote>
<p><em>The frontier isn’t volume—it’s discernment. And in that shift,
taste has become a survival skill.</em></p>
<p><em>Because when abundance is infinite, attention is everything. And
what you give your attention to—what you consume, what you engage with,
what you amplify—becomes a reflection of how you think.</em></p>
<p><em>What matters now is what you do with it. How you filter it. How
you recognize signal in the noise. Curation is the new IQ test.</em></p>
<p><em>Taste is often dismissed as something shallow or subjective. But
at its core, it’s a form of literacy—a way of reading the world. Good
taste isn’t about being right. It’s about being attuned. To rhythm, to
proportion, to vibe. It’s knowing when something is off, even if you
can’t fully articulate why.</em></p>
<p><em>Taste is what allows you to skim past the performative noise, the
fake depth, the viral bait, and know—instinctively—what’s worth your
time.</em></p>
<p><em>And that’s what real taste is: a deep internal coherence. A way
of filtering the world through intuition that’s been sharpened by
attention.</em></p>
<p><em>When you sharpen your discernment, you stop being swayed by
trends. You stop needing consensus. You stop reacting to every new thing
like it’s urgent.</em></p>
<p><em>There will always be creators. But the ones who stand out in this
era are also curators. People who filter their worldview so cleanly that
you want to see through their eyes. People who make you feel sharper
just by paying attention to what they pay attention to.</em></p>
<p><em>1995 interview with Steve Jobs — <strong>“Ultimately, it comes
down to taste. It comes down to trying to expose yourself to the best
things that humans have done, and then try to bring those things into
what you’re doing.”</strong></em></p>
<p><em>Good taste isn’t restrictive. It’s expansive. It allows you to
contain multitudes without becoming incongruent.</em></p>
<p><em>But good taste is deep structure. It’s the throughline in
someone’s life. You can see it in the design of their home, the cadence
of their speech, the way they treat people, the books on their
shelves.</em> <em>Taste is how you live a congruent life. Not in the
sense of brand consistency, but in the sense of spiritual alignment. You
can change your mind. Explore new spaces. But your values stay intact.
Your center holds.</em></p>
<p><strong>― Taste Is the New Intelligence - Wild Bare Thoughts</strong>
[<a
target="_blank" rel="noopener" href="https://wildbarestepf.substack.com/p/taste-is-the-new-intelligence">Link</a>]</p>
</blockquote>
<p>This is an amazing article. In an age of infinite content, taste is
your compass. It’s not about elitism—it’s about aligning your attention
with what truly matters to you. We can do these:</p>
<p><strong>Learnings and Suggestions</strong>:</p>
<ol type="1">
<li><p>Cultivate Discernment Over Consumption: Prioritize depth over
volume in what you read, watch, and engage with. Ask "Is this worth my
time?" before consuming content, creating something, or sharing. Trust
your intuition—if something feels off, skip it.</p></li>
<li><p>Curate Your Inputs (Because They Shape Your Outputs): Unfollow
accounts, mute topics, and unsubscribe from newsletters that don’t align
with your values. Follow thinkers, creators, and curators who
consistently offer depth. Set boundaries (e.g., no mindless scrolling
after 9 PM). Pause after reading/watching to digest, not just
react.</p></li>
<li><p>Build a "Library Mindset" (Not a Wishlist One): Read books,
essays, and long-form work that lingers. Don’t engage with viral content
just because it’s popular. Save/share only what resonates deeply—not
what’s merely entertaining.</p></li>
<li><p>Train Your Taste Like a Muscle: Study great art, writing, music,
and design to refine your sensibility. Remove distractions, unnecessary
commitments, and low-value inputs. Note what ideas/images/sounds stay
with you—these reveal your true taste.</p></li>
<li><p>Embrace Coherence Over Consistency: Your bookshelf, playlists,
and feeds should reflect who you are (or aspire to be). Stay open to new
influences, but filter them through your core principles. Don’t adopt
aesthetics/opinions for status—authenticity matters more.</p></li>
<li><p>Practice "Vibe Coding" (Like Rick Rubin): Whether in
conversations or creativity, prioritize feeling over formulas. In
work/life, strip away excess until only the essential remains. If
something feels "alive," lean in—even if it defies logic.</p></li>
<li><p>Reject Cheap Dopamine for Lasting Satisfaction: Opt for the book
over the tweet, the slow movie over the clip. After consuming something,
ask: Did this uplift or drain me? Regularly eliminate distractions
(apps, subscriptions, habits) that don’t serve you.</p></li>
<li><p>Taste as a Spiritual Practice: Prioritize art/ideas that
rearrange your perspective. From your home to your workspace, align
space with intention. Engage only with what nourishes, not
depletes.</p></li>
<li><p>Remember: Curation = Power: Amplify only what deserves a wider
audience. Your ability to filter signal from noise is a competitive
edge. The more you refine your taste, the more it protects you from
chaos.</p></li>
</ol>
<blockquote>
<p><strong>A Primer on US Healthcare - Generative Value</strong> [<a
target="_blank" rel="noopener" href="https://www.generativevalue.com/p/a-primer-on-us-healthcare">Link</a>]</p>
</blockquote>
<p>This article covers an overview of the system (main players), the
value chain (how products and services flow through the system and what
profitable segments are), incentives (motivation of behaviors),
challenges (significant issues within the industry), and potential
solutions (software and AI).</p>
<p>It deeply focuses on the interplay between incentives, middlemen, the
resulting administrative burden, and AI as the specific technological
solution appears to be a key perspective.</p>
<blockquote>
<p><strong>BREAKING: UnitedHealth Bleeds. CEO Witty Steps Down. - Sergei
Polevikov, AI Health Uncut</strong> [<a
target="_blank" rel="noopener" href="https://sergeiai.substack.com/p/breaking-unitedhealth-bleeds-ceo">Link</a>]</p>
<p><strong>UnitedHealth Abuse Tracker - Matt Stoller, American Economic
Liberties Project</strong> [<a
target="_blank" rel="noopener" href="https://www.economicliberties.us/data-tools/unitedhealth-group-abuse-tracker/">Link</a>]</p>
</blockquote>
<blockquote>
<ol type="1">
<li><em>Vibe coding is a new approach to software development that
utilizes AI tools to assist individuals in creating applications and
software <strong>without requiring extensive programming
knowledge</strong>.</em></li>
<li><em>The term was popularized by Andrej Karpathy, an AI expert, who
described it as a method where users <strong>interact with AI using
natural language</strong> to describe their ideas rather than writing
traditional code directly.</em></li>
<li><em>This allows creators, particularly those lacking technical
skills, <strong>to build functional applications rapidly</strong> by
simply explaining their requirements to the AI, which generates the
relevant code for them.</em></li>
</ol>
<p><strong>― What is Vibe Coding? - AI Supremacy</strong> [<a
target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/what-is-vibe-coding-2025">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Who’s the Highest-Paid CEO? - App Economy Insights</strong>
[<a
target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/whos-the-highest-paid-ceo">Link</a>]</p>
</blockquote>
<p>Rick Smith, co-founder and CEO of Axon.</p>
<blockquote>
<p><strong>I Summarized Mary Meeker's Incredible 340 Page 2025 AI Trends
Deck—Here's Mary's Take, My Response, and What You Can Learn - Nate, Ai
&amp; Product</strong> [<a
target="_blank" rel="noopener" href="https://natesnewsletter.substack.com/p/i-summarized-mary-meekers-incredible">Link</a>]</p>
</blockquote>
<p>Nate's overall take is that while Mary Meeker is correct that
Generative AI adoption is exploding, real value accrues only where
organizations align real-world problems with AI’s actual strengths in
workflows. He believes bigger claims demand commensurately bigger
evidence.</p>
<blockquote>
<p><em>Carl Dahlman later gave us the three categories that are widely
used today:</em></p>
<ol type="1">
<li><em><strong>Search and information costs:</strong> discovering what
is available to purchase and comparing alternatives</em></li>
<li><em><strong>Bargaining and decision costs</strong>: coming to an
agreement between buyer and seller, including establishing the final
price and terms</em></li>
<li><em><strong>Enforcement and policing costs</strong>: ensuring that
both sides holds up their end of the deal</em></li>
<li><em><strong>Distribution costs</strong>: actually getting the good
or service to the end consumer</em></li>
</ol>
<p><strong>― How To Build AI Agents (2025 Guide) - Max Berry, Max'
Prompts</strong> [<a
target="_blank" rel="noopener" href="https://www.maxberry.ca/p/how-to-build-ai-agents-2025-guide">Link</a>]</p>
</blockquote>
<p><strong>Key Concepts</strong>:</p>
<ul>
<li><strong>Transaction Costs</strong>: Costs incurred in addition to
the actual price of a good or service, necessary to coordinate and
execute a transaction. Marketplaces primarily sell the reduction of
these costs.</li>
<li><strong>TAM Expansion</strong>: Reducing transaction costs lowers
the effective cost of a good or service, increasing demand and expanding
the Total Addressable Market (TAM). The degree of TAM expansion relates
to the percentage of total cost eliminated.</li>
<li><strong>Value Distribution:</strong> Marketplaces save sellers money
on transaction costs and charge them a fee (often similar to what
sellers paid previously). They typically pass efficiency gains on to
buyers in the form of easier and faster experiences, creating a
demand-constrained market. <strong>Variable Costs of Addressing
Transaction Costs:</strong>
<ul>
<li><strong>Low Variable Costs:</strong> Addressing search and
bargaining costs is highly efficient and has low variable costs.
Marketplaces can keep more of the value created here.</li>
<li><strong>High Variable Costs:</strong> Addressing enforcement and
distribution costs involves significant variable costs (e.g., funding
returns, building logistics). While these make marketplaces bigger,
margins may be lower as value is passed to buyers.</li>
</ul></li>
</ul>
<p><strong>Takeaways</strong>:</p>
<p>This article puts the concept of transaction costs as central to
understanding marketplaces. Transaction costs are defined as the costs
incurred beyond the actual price of a good or service, associated with
coordinating and executing the transaction itself. Marketplaces are
essentially businesses that sell the reduction of these transaction
costs. Studying transaction costs can help determine where marketplaces
will succeed, what kind of marketplaces to build, and how to price
them.</p>
<p>Looking ahead, the article suggests that the "free lunch"
opportunities in many industries are exhausted, pushing marketplaces
into high variable cost activities. This implies future marketplaces may
be higher scale but potentially lower margin and more operationally
intensive. To disrupt incumbent marketplaces, one should look for
remaining transaction costs that can be addressed much more efficiently
than the current solution. The article suggests disrupting food delivery
was possible by building a more efficient network than restaurants had,
but disrupting shipping for handmade goods is harder because it requires
competing with highly efficient companies like UPS and Fedex.</p>
<p>By far, the largest unsolved transaction costs are in the
<strong>services industries</strong> (e.g., freelancing, home
improvement), which constitute two-thirds of consumer spending. Most
services marketplaces are currently stuck at the Lead Generation stage,
limiting penetration and take rate. This might be partly because much
spend is on recurring services where customers leave the marketplace
once a good provider is found, leading services marketplaces to rely on
high-churn consumer subscriptions. Despite this, there are
opportunities, such as Zillow exploring expanding into managed
marketplace territory for home services.</p>
<figure>
<img src="/di-blog/2025/06/07/2025-Jun/four-stages-of-marketplaces.png"
alt="four-stages-of-marketplaces" />
<figcaption aria-hidden="true">four-stages-of-marketplaces</figcaption>
</figure>
<blockquote>
<p><strong>An hour a day is all you need. - The Improvement
Journal</strong> [<a
target="_blank" rel="noopener" href="https://improvebypathsofstoicism.substack.com/p/an-hour-a-day-is-all-you-need">Link</a>]</p>
</blockquote>
<p>The one hour is suggested to be dedicated to three key practices that
aim to rebuild an individual from the ground up:</p>
<ol type="1">
<li><strong>Build Something That's Yours</strong>: This involves
creating something that belongs to you, beyond your job, such as a
newsletter, product, service, blog, or by learning/teaching a skill. The
purpose is to "plant seeds" that will compound over time, pulling you
out of stagnation.</li>
<li><strong>Train Like You Want to Be Here for a While</strong>: This
practice emphasizes physical strength and movement, like walking,
running, stretching, lifting, breathing, sleeping deeply, eating real
food, and drinking water. It's a message of self-care and an intention
to use one's body, which also sharpens mental clarity, as Seneca
suggested, "The body should be treated more rigorously, that it may not
be disobedient to the mind".</li>
<li><strong>Create Enough Silence to Hear Your Own Voice</strong>: This
habit counters the constant noise and stimulation of modern life. It
encourages practices like journaling, meditating, taking walks without
headphones, or simply sitting still without a goal or screen. The goal
is not productivity, but presence and creating space for reflection and
insight, preventing thoughts from being drowned out and actions from
remaining unexamined.</li>
</ol>
<blockquote>
<p><strong>How to become friends with literally anyone - April &amp; The
Fool</strong> [<a
target="_blank" rel="noopener" href="https://aprilandthefool.substack.com/p/how-to-become-friends-with-literally">Link</a>]</p>
</blockquote>
<p>The article suggests that becoming friends with anyone is to approach
interactions with a deep-seated belief in shared humanity, genuine
curiosity about individual worldviews, and an open, empathetic demeanor
that seeks to understand rather than judge.</p>
<ul>
<li><strong>Try to understand people through conversations with a belief
in the universal commonality of human nature:</strong> The author
fundamentally believes that all people are driven by the same core human
urges and desires, such as the need to feel loved, respected, and seen.
This perspective makes it intuitive to understand others. They see
meeting someone new as a "puzzle of empathy" and a "game of
commonality," where they try to understand what someone would think,
want, need, or crave given their background, values, limitations, and
longings.</li>
<li><strong>From common nature to differences among people due to
environmental factors:</strong> The author acknowledges that
<em>how</em> these needs are defined and achieved varies dramatically
due to factors like nationality, gender, religion, cultural heritage,
socioeconomic class, hobbies, and upbringing. These "little big
differences" are where things become interesting, leading to unique
individual personalities and perspectives.</li>
<li><strong>Follow the reasonableness within their personal worldview to
understand motivations and values:</strong> The author believes that
while people may not always be rational, they are always "reasonable"
within their own worldview. This means that everyone has reasons for
their actions, and those reasons make sense within their personal
framework. Understanding a person's circumstances allows the author to
understand their motivations, struggles, and values.</li>
<li><strong>Be curious and genuine while engaging with people:</strong>
The author describes themselves as extremely extraverted, loving people,
and hating small talk. They are curious about people, viewing them as
containing "worlds, histories, stories that span across generations and
geographies". This curiosity leads them to give "rapt attention and
genuine space to be yourself".</li>
<li><strong>Assumption of friendship from the beginning, share stories
and genuine care:</strong> The author approaches new encounters with the
assumption that "we are friends" from the moment they meet. They are
open, putting "all my cards on the table" and inviting others to reveal
theirs. They enjoy conversations, making people feel understood, heard,
and cared for.</li>
</ul>
<blockquote>
<p><em>The key takeaway is that genuine technological advancement, which
is real and accelerating, must be distinguished from the business models
built around it, which frequently adhere to age-old patterns. When
stated purpose and actual function align, it typically indicates that
the technology addresses a specific, measurable problem with clear
economic value, rather than promising to "transform
everything."</em></p>
<p><em>Systemantics, or, the art of understanding what’s going on, means
recognizing the persistent gaps between what systems proclaim and what
they actually do, and capitalizing on that insight.</em></p>
<p><em>When the fog dissipates and clarity emerges, the survivors will
be those who patiently deciphered the underlying mechanics amidst
fleeting illusions.</em></p>
<p><em>Enduring AI companies will emerge in two distinct spaces by 2035:
unglamorous but essential tools that demonstrably improve margins or
reduce costs, and genuine frontier research that reveals entirely new
problem spaces. The first category refines what exists; the second
invents what doesn't yet.</em></p>
<p><em>Real opportunities lie in the quiet spaces between stated
ambitions and operational truths. Just as they always have.</em></p>
<p><strong>― The Art of Understanding What's Going On - Tina He,
Fakepixels</strong> [<a
target="_blank" rel="noopener" href="https://fakepixels.substack.com/p/the-art-of-understanding-whats-going">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>How I Went From Reading 20 Books Per Year to Over 75 Books -
Ryan Hall, Read and Think Deeply</strong> [<a
target="_blank" rel="noopener" href="https://ryandhall.substack.com/p/how-i-went-from-reading-20-books">Link</a>]</p>
</blockquote>
<p><strong>Takeaways</strong>:</p>
<ol type="1">
<li>Always take a book with you.</li>
<li>Give it about 50 pages before you quit. This keeps you from getting
stalled on a book that is not resonating with you.</li>
<li>Schedule the reading time. e.g., 45 min in the morning, 30 min in
the evening, and throughout the day when you get breaks.</li>
<li>Weekend sprints. Read in hour-long stretches on weekends or to do
several smaller stretches and get through entire sections or even whole
books on the weekends.</li>
</ol>
<blockquote>
<p><em>there are people with half your skills and intelligence living
out your dreams, just because they put themselves out there and didn’t
overthink it.</em></p>
<p><em>Reach out anyway—someone will always have more followers, more
free time, a better setup. It’s up to you to push through everything,
part the crowd, and make some space for yourself to at least give
yourself the chance of getting what you want.</em></p>
<p><em>You will never be fully ready and there will never be a perfect
time. It’s genuinely not about waiting for the right time to do
something when you’re ready, it’s about <strong>doing things before
you’re ready</strong> <strong>just to make them exist.</strong></em></p>
<p><strong>― literally just do things - Erifili Gounari, crystal
clear</strong> [<a
target="_blank" rel="noopener" href="https://erifili.substack.com/p/literally-just-do-things">link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Diabolus Ex Machina - Amanda Guinzburg, Everything Is A
Wave</strong> [<a
target="_blank" rel="noopener" href="https://amandaguinzburg.substack.com/p/diabolus-ex-machina">link</a>]</p>
</blockquote>
<blockquote>
<p><strong>how to think like a genius (the map of all knowledge) - Dan
Koe, Future/Proof</strong> [<a
target="_blank" rel="noopener" href="https://letters.thedankoe.com/p/how-to-think-like-a-genius-the-map">Link</a>]</p>
</blockquote>
<p>the article suggests that thinking like a genius involves adopting a
holistic and nuanced approach to problems by utilizing the AQAL model,
encompassing all relevant perspectives (quadrants) and evolving one's
consciousness to a "second-tier" level that can integrate and synthesize
different stages of understanding. This allows for faster
problem-solving and greater achievement in life.</p>
<p><strong>All Quadrants</strong>:</p>
<ul>
<li>Individual Interior (Upper Left): Your personal thoughts, emotions,
beliefs, and consciousness. Questions in this quadrant might include
core values, what makes you feel alive, or fears holding you back.</li>
<li>Individual Exterior (Upper Right): Your behaviors, actions, and
physical brain states. This involves looking at natural talents,
developed skills, and what your behavior reveals about your
preferences.</li>
<li>Collective Interior (Lower Left): Shared culture, values, and group
consciousness. This could involve understanding parental or religious
expectations, influence of friends, or shared values you're drawn
to.</li>
<li>Collective Exterior (Lower Right): Systems, structures, and social
institutions. This quadrant considers current job opportunities, the
impact of education or technology, and systemic barriers or
advantages.</li>
</ul>
<p><strong>All Levels</strong>:</p>
<ul>
<li><p>Premodern: Characterized by following established authority and
traditions, with black-and-white thinking and obedience to a God or
conformity.</p></li>
<li><p>Modern: Values science, individual achievement, competition, and
merit-based success.</p></li>
<li><p>Postmodern: Emphasizes relativistic thinking, where everyone's
truth is valid, and focuses on inclusion and equality. The article notes
that postmodern thinking can become pathological when it attempts to
dismantle all hierarchies.</p></li>
<li><p><strong>Second-Tier</strong>: This is the suggested stage for
"genius" thinkers. Individuals at this level can look back and
synthesize truths from all prior perspectives, embracing complexity,
systems thinking, and awareness. It's less about "I'm right and you're
wrong" and more about <strong>finding the best solution through
synthesis, holding contradictions in mind until they can be
reconciled</strong>. <strong>Genius thinkers act as "translators"
between different stages</strong>.</p></li>
</ul>
<blockquote>
<p><strong>How to Be Taken Seriously - Tessa Xie, Diving Into
Data</strong> [<a
target="_blank" rel="noopener" href="https://www.divingintodata.com/p/how-to-be-taken-seriously">Link</a>]</p>
</blockquote>
<p>A summary of the four junior traits and what to do instead:</p>
<ul>
<li><strong>Junior Trait #1: Providing too much
detail/over-explaining</strong>
<ul>
<li>Excessive detail doesn't showcase knowledge and consideration of
edge cases, but it typically confuses the audience and makes them appear
unable to synthesize information, causing key points to be missed.
Managers may even prevent such individuals from presenting to executives
to avoid confusion and inefficiency in meetings.</li>
<li>What to do about it:
<ul>
<li>In written form: Summarize work with a "TL;DR" at the top, using the
Pyramid Principle (conclusion first, then supporting evidence). Focus on
what is important enough to communicate, moving less critical details to
an appendix.</li>
<li>In verbal form: Practice an "elevator pitch" of less than 30 seconds
to peers, focusing on the "why" and enough "what" to allow for opinion
formation. <strong>The ability to decide what NOT to communicate is as
crucial as what to mention.</strong></li>
</ul></li>
</ul></li>
<li><strong>Junior Trait #2: Not having an opinion or
recommendation</strong>
<ul>
<li>As data scientists become more senior, translating analysis into a
recommendation becomes increasingly important. Hesitation to provide
recommendations often stems from the perceived risk and the nuanced,
non-black-and-white nature of data, leading to "analysis paralysis".
However, not giving recommendations shows a lack of ownership and limits
one to simple "execution" work.</li>
<li>What to do about it:
<ul>
<li>Adopt an <strong>ownership mindset</strong>, imagining you are the
decision-maker. Ask what data <em>you</em> would need and if the
presented data would convince <em>you</em>.</li>
<li>Understand that value comes from giving robust recommendations
<em>despite</em> nuance and ambiguity, just as taking risks can lead to
above-average returns.</li>
<li>While you should list caveats, <strong>most people prefer a
recommendation they disagree with over no recommendation at all, as it
provides a basis for discussion and understanding assumptions.</strong>
Data teams are paid to <strong>drive business decisions,</strong> not
just pull and present data.</li>
</ul></li>
</ul></li>
<li><strong>Junior Trait #3: Not being clear about the "why" behind the
analysis</strong>
<ul>
<li>Junior DS often state "XYZ stakeholder asked for this" as the sole
reason for an analysis, which is insufficient. This indicates a lack of
ownership of the business problem and hinders the ability to deliver
effective solutions, leading to frustration from changing data
requests.</li>
<li>What to do about it:
<ul>
<li><strong>Own the problem</strong>. When asked to pull data, find out
<em>why</em> the stakeholder needs it and what decision they are trying
to make.</li>
<li>By understanding the ultimate business problem, you can
<strong>brainstorm the most effective data solutions</strong>,
potentially different from the original request, thus <strong>elevating
yourself to a</strong> <strong>thought partner</strong>.</li>
</ul></li>
</ul></li>
<li><strong>Junior Trait #4: Not having the basics down to be able to
stay "one step ahead"</strong>
<ul>
<li>Losing credibility happens when people feel you don't know the data
or business area you cover. To establish yourself as an expert, you need
to <strong>anticipate common questions and be the most familiar with the
data in your area</strong>. If you lack answers to natural follow-up
questions, it suggests you haven't thoroughly understood or explored the
data.</li>
<li>What to do about it:
<ul>
<li>Be curious about your data; start with a basic question and explore
from there, jotting down answers.</li>
<li>Anticipate follow-up questions in three buckets before presenting:
<strong>foundational knowledge</strong> (e.g., how the product works,
user numbers), <strong>your analysis</strong> (details beyond the main
insights), and <strong>next steps</strong> (what the findings mean for
stakeholders).</li>
<li>Get a second pair of eyes on your work, ideally from someone not
deep in the analysis, to catch obvious omissions.</li>
</ul></li>
</ul></li>
</ul>
<blockquote>
<p><strong>How to work with AI: Getting the most out of Deep Research -
Torsten Walbaum, Operator's Handbook</strong> [<a
target="_blank" rel="noopener" href="https://www.operatorshandbook.com/p/how-to-work-with-ai-getting-the-most">Link</a>]</p>
</blockquote>
<p>A comprehensive guide of AI Deep Research from idea to value. The
author provided a good ChapGPT Deep Research example <a
target="_blank" rel="noopener" href="https://chatgpt.com/share/6859a8d6-715c-8002-9afa-f3174f0a4b72">here</a>.
Deep Research prompt for meeting transcription by o3 <a
target="_blank" rel="noopener" href="https://docs.google.com/document/d/1rZHtuB0NiKALkwoLN3md34L56tQEArXQvybX-gp0gi0/edit?tab=t.0#heading=h.aq5h6awtm7bk">here</a>.</p>
<figure>
<img
src="/di-blog/2025/06/07/2025-Jun/structuring_a_deep_research_prompt.png"
alt="structuring_a_deep_research_prompt" />
<figcaption
aria-hidden="true">structuring_a_deep_research_prompt</figcaption>
</figure>
<p>Free 15 queries per (ChatGPT+Gemini); Free 13 queries per day
(perplexity+Grok)!</p>
<figure>
<img src="/di-blog/2025/06/07/2025-Jun/pricing_and_limits.png"
alt="pricing_and_limits" />
<figcaption aria-hidden="true">pricing_and_limits</figcaption>
</figure>
<h2 id="papers-and-reports">Papers and Reports</h2>
<blockquote>
<p><strong>Trends - Artificial Intelligence - Mary Meeker, Bond</strong>
[<a target="_blank" rel="noopener" href="https://www.bondcap.com/report/tai/#view/0">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Think Only When You Need with Large Hybrid-Reasoning
Models</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2505.14631">Link</a>]</p>
</blockquote>
<p>Large Reasoning Models (LRMs) improve reasoning via extended thinking
(e.g., multi-step traces), but this leads to inefficiencies like
overthinking simple queries, increasing latency and token usage. The
team Introduces Large Hybrid-Reasoning Models (LHRMs) — the first models
that adaptively choose when to think based on query complexity,
balancing performance and efficiency. They utilizes a two-stage
approach: 1) <strong>Hybrid Fine-Tuning (HFT)</strong> – cold start
using curated datasets labeled as "think" vs. "non-think"; 2)
<strong>Hybrid Group Policy Optimization (HGPO)</strong> – an online RL
method that trains the model to pick the optimal reasoning mode. They
defines <strong>Hybrid Accuracy</strong> to evaluate how well the model
selects between thinking and non-thinking strategies; correlates
strongly with human judgment. Experiments show LHRMs outperform both
LRMs and traditional LLMs in reasoning accuracy and response quality,
while also reducing unnecessary computation.</p>
<blockquote>
<p><strong>The 2025 State of B2B - Monetization - Kyle Poyar</strong>
[<a
target="_blank" rel="noopener" href="https://cdn.prod.website-files.com/66f3d5c51c51d8e744b8d529/682e259fa19323cc4ecda6be_60d3fca97de926e1eff89042d5a068a2_2025%20State%20of%20Monetization%20Report_Tremont_2025.pdf">Link</a>]</p>
</blockquote>
<p>The report summarizes a poll of 240 software companies about their
pricing strategies. Key findings indicate a decline in flat-rate and
seat-based pricing models, with hybrid pricing (combining subscriptions
and usage) emerging as the dominant approach, especially for companies
incorporating AI capabilities. The report also highlights a growing
interest in outcome-based pricing among AI-native companies and stresses
the importance of pricing agility and clear ownership of pricing
strategy within organizations.</p>
<blockquote>
<p><strong>The Illusion of Thinking: Understanding the Strengths and
Limitations of Reasoning Models via the Lens of Problem Complexity -
Apple Machine Learning Research</strong> [<a
target="_blank" rel="noopener" href="https://machinelearning.apple.com/research/illusion-of-thinking">Link</a>]</p>
</blockquote>
<p>The authors analyzed the thinking process and reasoning traces of
LRMs in several smart ways:</p>
<ul>
<li>A custom pipeline using regex identifies and extracts potential
solution attempts from the LRM's thinking traces.</li>
<li>Extracted solutions are rigorously verified against puzzle rules and
constraints using specialized simulators for step-by-step
correctness.</li>
<li>Records the accuracy of valid solutions and their relative position
within the reasoning trace for behavioral insights.</li>
<li>Categorizes LRM thinking patterns (e.g., overthinking, late success,
collapse) by analyzing how solution correctness and presence vary with
problem complexity.</li>
<li>Examines how the proportion of correct solutions changes
sequentially within the thinking trace, revealing dynamic accuracy
shifts.</li>
<li>Pinpoints the initial incorrect step in a solution sequence to
understand the depth of correct reasoning before error.</li>
<li>Quantifies thinking token usage to analyze scaling of effort with
complexity, noting an unexpected decline at high complexity.</li>
</ul>
<blockquote>
<p><strong>How much do language models memorize? - Meta, Google, NVIDIA,
and Cornell University</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2505.24832">Link</a>]</p>
</blockquote>
<p>This paper proposed a new method to quantify how much information a
language model "knows" about a datapoint.</p>
<p>They formally separate memorization into two components by two novel
definitions of memorization: unintended memorization (information about
a specific dataset) and generalization (information about the true
data-generation process).</p>
<p><strong>There are several interesting findings:</strong></p>
<ul>
<li>By training models on uniform random bitstrings (eliminating
generalization), they precisely measure model capacity, finding
GPT-style transformers store 3.5 to 4 bits per parameter.</li>
<li>Their framework shows that the double descent phenomenon occurs when
the data size exceeds the model capacity, suggesting that models are
"forced" to generalize when they can no longer individually memorize
datapoints.</li>
<li>The paper develops and validates a scaling law that predicts
membership inference performance based on model capacity and dataset
size, indicating that membership inference becomes harder with larger
datasets relative to model capacity.</li>
</ul>
<p><strong>To understand their smart methods:</strong></p>
<ul>
<li><p>They proposed a very clever approach to understand memorization
and model capacity in LM. They isolate unintended memorization by
training models on <strong>uniform random bitstrings</strong>.</p>
<ul>
<li>No Generalization Signal: When training on truly random data, there
are no underlying patterns, rules, or structures for the model to
generalize from. Each bitstring is an independent, random piece of
information.</li>
<li>Only Memorization is Possible: In this scenario, the <em>only</em>
way for the model to "learn" or perform well on this data (i.e., predict
the next bit in a sequence or identify if it was part of the training
set) is to literally memorize the specific bitstrings it has seen. Any
"knowledge" the model gains is purely about the individual data
points.</li>
<li>Total Memorization as Measured: Therefore, when generalization is
effectively zero, the information the model stores about the random
bitstrings directly reflects its <em>total memorization capacity</em>
for that type of information. There's no "general knowledge" to
distinguish; it's all about remembering specific instances.</li>
</ul>
<p>Therefore, they are measuring the maximum amount of distinct,
specific information the model can store.</p>
<p>They equal total memorization to model capacity. In machine learning,
model capacity generally refers to the <strong>size and complexity of
the functions a model is capable of learning</strong>. It's the model's
ability to fit a wide variety of patterns in the data. A model with
higher capacity can potentially fit more complex relationships or
memorize more specific data points.</p>
<p>The paper further quantifies this by showing that GPT-style models
have a capacity of approximately 3.6 bits-per-parameter. This indicates
that each parameter in the model effectively acts as a certain amount of
storage for information, reflecting the overall capacity of the neural
network architecture.</p></li>
<li><p>The fundamental challenge in understanding and evaluating
language models is the <strong>ambiguity and conflation of
"memorization" (copy or reproduce a specific sequence in the training
data) and "learning." (truly understand and generalize a pattern or
concept)</strong> This is exactly what they addressed by decomposing
memorization into unintended memorization and generalization. The
decomposition enables controlled measurement and the use of random
bitstrings is the key innovation.</p>
<p>About the Double Descent Phenomena: When a model's capacity exceeds
the generalizable patterns in the data, it starts to memorize individual
data points. As data size increases relative to capacity, the model is
"forced" to generalize more, leading to a decrease in unintended
memorization and an improvement in performance.</p>
<p>The core insight is that as models become massively overparameterized
(far beyond what's needed to simply fit the training data), they find
"simpler" interpolating solutions that generalize better, often due to
the implicit biases of optimization algorithms like Stochastic Gradient
Descent (SGD).</p>
<p><strong>Intuition for double descent</strong>:</p>
<ol type="1">
<li>"Under-parameterized" Regime (Classical ML): Model Capacity &lt;
Data Size: very generalizable, low test error</li>
<li>"Interpolation Threshold" (The Peak): Model Capacity ~ Data Size:
peak of test error, due to overfitting the noise</li>
<li>"Over-parameterized" Regime (Double Descent / Modern Deep Learning):
Model Capacity &gt;&gt; Data Size: robust generalization happens, test
error goes down again.</li>
</ol></li>
<li><p>Here is a concept <strong>Membership Inference Attacks
(MIAs):</strong> These are attacks that attempt to determine whether a
specific data point was part of a model's training dataset or not. A
successful MIA indicates that the model has "memorized" that specific
data point. "Scaling Laws for Membership Inference" in the paper refers
to <strong>predictive relationships that describe how the success rate
of a MIA changes as a function of various model and data
characteristics</strong>, such as model capacity and dataset size.</p>
<p>They basically propose that <strong>membership inference success is
inversely related to how "generalizable" the data point is within the
model's capacity.</strong> In other words, membership inference is
<strong>easier</strong> when the model has high capacity relative to the
dataset size, leading to more unintended memorization of individual data
points. Membership inference becomes <strong>harder</strong> (i.e., less
successful for an attacker) when the dataset size is very large compared
to the model's capacity, or when the model starts to "grok" (generalize)
more.</p></li>
</ul>
<blockquote>
<p><strong>LlamaFirewall: An open source guardrail system for building
secure AI agents - Meta AI</strong> [<a
target="_blank" rel="noopener" href="https://ai.meta.com/research/publications/llamafirewall-an-open-source-guardrail-system-for-building-secure-ai-agents/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Reasoning models don't always say what they think -
Anthropic</strong> [<a
target="_blank" rel="noopener" href="https://www.anthropic.com/research/reasoning-models-dont-say-think">Link</a>]</p>
</blockquote>
<p>The core issue explored is whether the Chain-of-Thought accurately
reflects the model's true reasoning process ("faithfulness"). The
article's research suggests that models frequently do not faithfully
report their reasoning. Researchers tested this by subtly providing
hints (both correct and incorrect) to models during evaluations. They
then checked if the models admitted using these hints in their
Chain-of-Thought explanations. The results showed that models (Claude
3.7 Sonnet and DeepSeek R1) rarely mentioned the hints they used, even
when those hints led them to a different answer or involved potentially
problematic information (like "unauthorized access"). Instead, models
often created fake rationales for their answers.</p>
<p>The researchers also studied reward hacking by constructing synthetic
Reinforcement Learning (RL) environments with injected "reward hacks."
They then finetuned an earlier snapshot of Claude 3.7 Sonnet in these
environments using outcome-based RL. By setting up the environments this
way, they could observe if the models learned to pick the incorrect hint
answer to maximize their reward, and then check if their
Chain-of-Thought verbalized this reward-seeking behavior. They found
that models learned the reward hacks very quickly (selecting the
incorrect hint answer over 99% of the time), but rarely verbalized these
hacks in their Chain-of-Thought (less than 2% of examples in most
environments).</p>
<blockquote>
<p><strong>Your Brain on ChatGPT: Accumulation of Cognitive Debt when
Using an AI Assistant for Essay Writing Task - MIT</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2506.08872v1">Link</a>]</p>
</blockquote>
<p>This experimental study combines neuroscience (EEG), educational
psychology, and human-AI interaction to examine how AI tools like
ChatGPT influence cognitive engagement during essay writing. The result
shows that brain-only group showed stronger and broader neural
connectivity, especially in theta bands, indicating deeper internal
ideation and cognitive engagement. LLM group exhibited reduced alpha and
theta connectivity, suggesting externalized and narrower thought
patterns—relying more on ChatGPT suggestions rather than internal
generation of ideas. So it's saying if you rely heavily on AI, you will
get dumber.</p>
<blockquote>
<p><strong>On the Extinction Risk from Artificial Intelligence -
RAND</strong> [<a
target="_blank" rel="noopener" href="https://www.rand.org/pubs/research_reports/RRA3034-1.html">Link</a>]</p>
</blockquote>
<p>This report examines the potential for AI to cause human extinction.
The authors analyzed three specific scenarios: <strong>the use of
weapons, the release of biological pathogens, and severe climate warming
via malicious geoengineering</strong>. The study concludes that
significant barriers exist for AI to achieve human extinction and it
would likely require intentional AI action and substantial time for the
threats to materialize, allowing for human response and mitigation
efforts. Ultimately, the report suggests that resources dedicated to AI
extinction risk should also support broader global catastrophic risk
mitigation and general AI safety.</p>
<p>This analysis starts from what could cause human extinction and
assesses how AI could contribute to that. The threats are limited to
those can be explored through scenario planning, while those that
involve a deeper level of uncertainty are ignored.</p>
<blockquote>
<p><strong>The OpenAI Files</strong> [<a
target="_blank" rel="noopener" href="https://www.openaifiles.org/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Trends in AI Supercomputers - Epoch AI</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/html/2504.16026v2">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Can US infrastructure keep up with the AI economy? -
Deloitte</strong> [<a
target="_blank" rel="noopener" href="https://www.deloitte.com/us/en/insights/industry/power-and-utilities/data-center-infrastructure-artificial-intelligence.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>2025: The State of Consumer AI - Shawn Carolan, et al., Menlo
Venture</strong> [<a
target="_blank" rel="noopener" href="https://menlovc.com/perspective/2025-the-state-of-consumer-ai/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Generative AI &amp; Gender Global Employment Trends -
Linkedin Economic Graph</strong> [<a
target="_blank" rel="noopener" href="https://economicgraph.linkedin.com/content/dam/me/economicgraph/en-us/PDF/generative-ai-and-gender.pdf">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Agentic Misalignment: How LLMs could be insider threats -
Anthropic</strong> [<a
target="_blank" rel="noopener" href="https://www.anthropic.com/research/agentic-misalignment">Link</a>]</p>
</blockquote>
<p>Researchers stress-tested 16 leading AI models from various
developers and found that in certain situations, these models resorted
to malicious behaviors like blackmailing officials or leaking sensitive
information. These actions occurred when the models faced replacement or
when their assigned goals conflicted with the company's changing
direction, even when they were given only harmless business goals and
explicitly told to avoid such behaviors. While no evidence of agentic
misalignment has been observed in real deployments, the findings suggest
caution when deploying current models in roles with minimal human
oversight and access to sensitive information.</p>
<blockquote>
<p><strong>SHADE-Arena: Evaluating sabotage and monitoring in LLM agents
- Anthropic</strong> [<a
target="_blank" rel="noopener" href="https://www.anthropic.com/research/shade-arena-sabotage-monitoring">Link</a>]</p>
</blockquote>
<p>Dual Objective Setup:</p>
<ul>
<li>Each evaluation environment includes a clearly defined <strong>main
task</strong> that simulates a real-world scenario and a <strong>secret
side task</strong> that is harmful but can be plausibly hidden within
the main task execution.</li>
<li>The agent's challenge: <strong>complete both tasks</strong> while
<strong>avoiding suspicion</strong>.</li>
</ul>
<p>Using LLMs to assess detection, measuring task completion vs.
detection success, and providing a benchmark for improving agent safety
and control.</p>
<h2 id="youtube-and-podcasts">YouTube and Podcasts</h2>
<blockquote>
<p><strong>Sundar Pichai: CEO of Google and Alphabet | Lex Fridman
Podcast</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/hashtag/471">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Jared Isaacman: What went wrong at NASA | The All-In
Interview</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=6YdOjoaQTOQ&amp;list=WL&amp;index=3">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Naval Ravikant On The 4 Books That CHANGED His Life
(Financially And Philosophically)</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=FOcD1ngbsXk&amp;list=WL&amp;index=4">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Chamath Palihapitiya: Zuckerberg, Rogan, Musk, and the
Incoming “Golden Age” Under Trump - Tucker Carison</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=eRlkcRnC9eE&amp;list=WL&amp;index=13">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Satya Nadella on AI Agents, Rebuilding the Web, the Future of
Work, and more - Rowan Cheung</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=_a8EnBX8DSU&amp;list=WL&amp;index=20">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Jeff Bezos: Amazon and Blue Origin | Lex Fridman Podcast -
Lex Fridman</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/hashtag/405">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>WWDC25: Platforms State of the Union - Apple</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLjODKV8YBFHbabxpCUjMzyVKZmcOFgd9b">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>#385 Michael Dell - Founders</strong> [<a
target="_blank" rel="noopener" href="https://www.founderspodcast.com/episodes/385-michael-dell">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>IPOs and SPACs are Back, Mag 7 Showdown, Zuck on Tilt,
Apple's Fumble, GENIUS Act passes Senate - All-In Podcasts</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=86t6YNf_B7Q&amp;list=PLn5MTSAqaf8peDZQ57QkJBzewJU1aUokl">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>I think being smart — and not being afraid to show it — means
living with discomfort. It's difficult. It means being willing and able
to admit when you're wrong. And it means being okay with complexity,
contradiction, and uncertainty.</em></p>
<p><em>So, the good news: I think smart survives. It's stubborn. It's
not loud. It's not flashy. But it's resilient — like a cockroach with a
PhD.</em></p>
<p><em>And the thing about stupidity is that eventually it bumps into
the hard wall of reality. When the bridges collapse and the crops fail,
when the Amazon package doesn't show up because the supply chain finally
imploded — suddenly people start looking around and going, "Hey, does
anybody know how to fix things? Build things?"</em></p>
<p><em>And the guy who spent the last 20 years reading books and
educating himself instead of screaming at his phone? Yeah, he's the one
holding the duct tape.</em></p>
<p><em>It won't be sexy, and it won't be immediate. But intelligence
isn't dead — it's just hungover. And sooner or later, we're going to
need it to crawl out of bed, drink some black coffee, and start fixing
the mess.</em></p>
<p><em>So at the end of the day, stupidity will always be popular — at
least in the U.S. But intelligence — real, patient, compassionate
intelligence — is what keeps the lights on.</em></p>
<p><em>And by the way, that goes for emotional intelligence too, which
is every bit as important.</em></p>
<p><em>So if you're still here, still critically thinking, still
refusing to go quietly into that great dumb night — you're already part
of the resistance.</em></p>
<p><em>Keep going.</em></p>
<p><strong>― The Death of Intelligence: Why Modern Society Celebrates
Stupidity - The Functional Melancholic</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=NTnQMCOhZFM&amp;list=WL&amp;index=6&amp;pp=gAQBiAQB">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Obsession That Creates Enduring Companies | David Senra
Interview - Invest Like The Best</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=Ak7oLVMlhfM&amp;list=WL&amp;index=24&amp;t=2459s">Link</a>]</p>
</blockquote>
<h2 id="articles-and-blogs">Articles and Blogs</h2>
<blockquote>
<p><strong>Everything Google Announced at I/O 2025 - WIRED</strong> [<a
target="_blank" rel="noopener" href="https://www.wired.com/story/everything-google-announced-at-io-2025/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Launch Hugging Face Models In Colab For Faster AI Exploration
- Medium</strong> [<a
target="_blank" rel="noopener" href="https://medium.com/google-colab/launch-hugging-face-models-in-colab-for-faster-ai-exploration-bee261978cf9">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>My AI Skeptic Friends Are All Nuts - Thomas Ptacek</strong>
[<a target="_blank" rel="noopener" href="https://fly.io/blog/youre-all-nuts/">Link</a>]</p>
</blockquote>
<p>The author argues that LLMs as agents are improving developer
productivity, and suggests that while the hype around AI can be
annoying, the technology's impact is real and profound. He believes that
those who don't embrace AI in their coding practices will be left
behind.</p>
<blockquote>
<p><strong>My Brain Finally Broke - The New Yorker</strong> [<a
target="_blank" rel="noopener" href="https://www.newyorker.com/culture/the-weekend-essay/my-brain-finally-broke">Link</a>]</p>
</blockquote>
<p>The author shares a disorienting sense of reality's erosion,
attributing it to various factors, including the relentless pace of
digital information, the overwhelming nature of political events, and
the insidious proliferation of AI. This environment fosters a collective
cognitive detachment and erosion of critical faculties, making it
challenging to discern truth, engage effectively, and maintain a
grounded sense of self and world.</p>
<blockquote>
<p><strong>Is there a Half-Life for the Success Rates of AI Agents? -
Toby Ord</strong> [<a
target="_blank" rel="noopener" href="https://www.tobyord.com/writing/half-life">Link</a>]</p>
</blockquote>
<h2 id="news">News</h2>
<blockquote>
<p><strong>Meet the Foundation Models framework - Apple</strong> [<a
target="_blank" rel="noopener" href="https://developer.apple.com/videos/play/wwdc2025/286/">Link</a>]</p>
</blockquote>
<p>The iPhone maker has launched the Foundation Models framework to
allow users to run a 3B parameter model locally. The framework is part
of Apple Intelligence suite and allows developers to access it using
three lines of code. The model can be used to generate text, extract
summaries, and tag structured information from unstructured text.</p>
<p>Users should be aware of strength and weakness. It's only available
on Apple Intelligence-enabled devices with OS version 26+. You need to
use Xcode Playgrounds to prototype with real model output. You can use
Instruments profiling template to measure latency and token overhead.
There is no support for fine-tuning or external model deployment</p>
<blockquote>
<p><strong>Connect Your MCP Client to the Hugging Face Hub -
HuggingFace</strong> [<a
target="_blank" rel="noopener" href="https://huggingface.co/changelog/hf-mcp-server">Link</a>]</p>
</blockquote>
<p>HuggingFace releases open-source MCP server to allow accessing its
tools from VSCode and Claude Desktop.</p>
<h2 id="new-book-list">New Book List</h2>
<p>Some book names from my daily readings recently caught my attention
and might be the next book to read for me:</p>
<ul>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/0062916602/ref=ox_sc_act_title_7?smid=ATVPDKIKX0DER&amp;psc=1">How
Innovation Works: And Why It Flourishes in Freedom</a> - Matt Ridley
(2021)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/0061452068/ref=ox_sc_act_title_8?smid=ATVPDKIKX0DER&amp;psc=1">The
Rational Optimist: How Prosperity Evolves (P.s.)</a>- Matt Ridley
(2021)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/Incerto-Fooled-Randomness-Procrustes-Antifragile/dp/059324365X">Incerto</a>
- Nassim Nicholas Taleb (2021)
<ul>
<li>Fooled by Randomness; The Black Swan; The Bed of Procrustes;
Antifragile; Skin in the Game</li>
</ul></li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/Beginning-Infinity-Explanations-Transform-World/dp/0143121359/">The
Beginning of Infinity</a> - David Deutsch (2012)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/0887307280/ref=ox_sc_act_title_2?smid=ATVPDKIKX0DER&amp;psc=1">The
E-Myth Revisited: Why Most Small Businesses Don't Work and What to Do
About It</a> - Michael E. Gerber</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/1591846447/ref=ox_sc_act_title_3?smid=ATVPDKIKX0DER&amp;psc=1">Start
with Why: How Great Leaders Inspire Everyone to Take Action</a> - Simon
Sinek</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/0307887898/ref=ox_sc_act_title_4?smid=ATVPDKIKX0DER&amp;psc=1">The
Lean Startup: How Today's Entrepreneurs Use Continuous Innovation to
Create Radically Successful Businesses</a> - Eric Ries</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/1501111116/ref=ox_sc_act_title_5?smid=ATVPDKIKX0DER&amp;psc=1">Grit:
The Power of Passion and Perseverance</a> - Angela Duckworth</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/0345472322/ref=ox_sc_act_title_6?smid=ATVPDKIKX0DER&amp;psc=1">Mindset:
The New Psychology of Success</a> - Carol S. Dweck</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/dp/0998116319?ref=ppx_yo2ov_dt_b_fed_asin_title">7
Powers: The Foundations of Business Strategy</a> - Hamilton Helmer
(2016)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/Great-CEO-Within-Tactical-Building/dp/0578599287/">The
Great CEO Within: The Tactical Guide to Company Building</a> - Matt
Mochary (2019)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/Hard-Thing-About-Things-Building/dp/0062273205/">The
Hard Thing About Hard Things: Building a Business When There Are No Easy
Answers―Straight Talk on the Challenges of Entrepreneurship</a> - Ben
Horowitz (2014)</li>
<li><a target="_blank" rel="noopener" href="https://amzn.to/43SsbXR">Inside the Ultimate Money Mind</a>
– Robert G. Hagstrom (2023)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/Creative-Act-Way-Being/dp/0593652886/">The
Creative Act: A Way of Being</a> - Rick Rubin (2023)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/gp/product/0070329656/ref=ox_sc_act_title_1?smid=A34MOU1WOG7LRW&amp;psc=1">In
the Company of Giants: Candid Conversations With the Visionaries of the
Digital World</a> - Rama Dev Jager (1998)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/dp/0593798694?ref=ppx_yo2ov_dt_b_fed_asin_title">The
Technological Republic: Hard Power, Soft Belief, and the Future of the
West</a> - Alexander C. Karp (2025)</li>
<li><a
target="_blank" rel="noopener" href="https://www.amazon.com/dp/1984878530?ref=ppx_yo2ov_dt_b_fed_asin_title">The
Contrarian: Peter Thiel and Silicon Valley's Pursuit of Power - Max
Chafkin</a> (2021)</li>
</ul>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/di-blog/tags/readings/" rel="tag"># readings</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/di-blog/2025/05/14/How-Leaders-Learn/" rel="prev" title="How Leaders Learn">
                  <i class="fa fa-angle-left"></i> How Leaders Learn
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/di-blog/2025/06/15/Zero-to-One/" rel="next" title="Zero to One">
                  Zero to One <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Di Zhen</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/di-blog/js/comments.js"></script><script src="/di-blog/js/utils.js"></script><script src="/di-blog/js/motion.js"></script><script src="/di-blog/js/sidebar.js"></script><script src="/di-blog/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/di-blog/js/third-party/math/mathjax.js"></script>



</body>
</html>
