<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/di-blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/di-blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/di-blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/di-blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/di-blog/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css" integrity="sha256-5eIC48iZUHmSlSUz9XtjRyK2mzQkHScZY1WdMaoz74E=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"jokerdii.github.io","root":"/di-blog/","images":"/di-blog/images","scheme":"Muse","darkmode":true,"version":"8.21.1","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/di-blog/js/config.js"></script>

    <meta name="description" content="Substack  How Meta Plans To Crank the Dopamine Machine With Infinite AI-Generated Content - The Algorithmic Bridge [Link]  This article discussed AI’s most dangerous potential - its ability to manipul">
<meta property="og:type" content="article">
<meta property="og:title" content="2025 January - What I Have Read">
<meta property="og:url" content="https://jokerdii.github.io/di-blog/2025/01/04/2025-January/index.html">
<meta property="og:site_name" content="Di&#39;s Blog">
<meta property="og:description" content="Substack  How Meta Plans To Crank the Dopamine Machine With Infinite AI-Generated Content - The Algorithmic Bridge [Link]  This article discussed AI’s most dangerous potential - its ability to manipul">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://jokerdii.github.io/di-blog/2025/01/04/2025-January/a16z_big_idea_2025.png">
<meta property="og:image" content="https://jokerdii.github.io/di-blog/2025/01/04/2025-January/deliberative_alignment.png">
<meta property="article:published_time" content="2025-01-04T05:05:36.000Z">
<meta property="article:modified_time" content="2025-01-04T05:05:36.000Z">
<meta property="article:author" content="Di Zhen">
<meta property="article:tag" content="readings">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://jokerdii.github.io/di-blog/2025/01/04/2025-January/a16z_big_idea_2025.png">


<link rel="canonical" href="https://jokerdii.github.io/di-blog/2025/01/04/2025-January/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://jokerdii.github.io/di-blog/2025/01/04/2025-January/","path":"2025/01/04/2025-January/","title":"2025 January - What I Have Read"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>2025 January - What I Have Read | Di's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/di-blog/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/di-blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Di's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#substack"><span class="nav-number">1.</span> <span class="nav-text">Substack</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#youtube-and-podcasts"><span class="nav-number">2.</span> <span class="nav-text">YouTube and Podcasts</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#articles-and-blogs"><span class="nav-number">3.</span> <span class="nav-text">Articles and Blogs</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#reports-and-papers"><span class="nav-number">4.</span> <span class="nav-text">Reports and Papers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#news"><span class="nav-number">5.</span> <span class="nav-text">News</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Di Zhen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/di-blog/archives/">
          <span class="site-state-item-count">44</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://jokerdii.github.io/di-blog/2025/01/04/2025-January/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/di-blog/images/avatar.gif">
      <meta itemprop="name" content="Di Zhen">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Di's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="2025 January - What I Have Read | Di's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          2025 January - What I Have Read
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-01-04 00:05:36" itemprop="dateCreated datePublished" datetime="2025-01-04T00:05:36-05:00">2025-01-04</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h2 id="substack">Substack</h2>
<blockquote>
<p><strong>How Meta Plans To Crank the Dopamine Machine With Infinite
AI-Generated Content - The Algorithmic Bridge</strong> [<a
target="_blank" rel="noopener" href="https://www.thealgorithmicbridge.com/p/how-meta-plans-to-crank-the-dopamine">Link</a>]</p>
</blockquote>
<p>This article discussed AI’s most dangerous potential - its ability to
manipulate and addict humans through hyper-targeted entertainment. This
trend, spearheaded by companies like Meta, risks reshaping human
cognition and agency, raising existential questions about freedom,
pleasure, and the future of society.</p>
<p>One good point is that the killer robots are brain-hacking
entertainment. A very plausible dystopia involves technology (e.g.,
AI-driven entertainment) manipulating human attention and cognition for
profit. Traditional TV was a prototype of mental manipulation but lacked
personalization. Current platforms such as Netflix and TikTok use
algorithms to cater to preferences but still feel limited. Future AI
will create hyper-personalized content tailored to individual
preferences in real-time, exploiting human psychology. Meta’s generative
AI plans are the next step toward addictive, manipulative entertainment.
Meta announced that AI content creators will be designed to enhance
engagement on platforms like Facebook and Instagram. Connor Hayes,
Meta’s VP for generative AI, explained how AI accounts will create and
share engaging content.</p>
<blockquote>
<p><strong>The Five Stages of AGI Grief - Marcus on AI</strong> [<a
target="_blank" rel="noopener" href="https://garymarcus.substack.com/p/the-five-stages-of-agi-grief">Link</a>]</p>
</blockquote>
<p>Marcus uses the framework of the Kübler-Ross model of grief to
describe the emotional responses people are having (or will likely have)
to the ongoing developments in Artificial General Intelligence (AGI). He
argues that many people are not yet facing the reality of AGI and are
likely to go through similar stages of grief as it gets closer.</p>
<ol type="1">
<li>Denial: Many people, including some experts, are still in denial
about the possibility and speed of AGI development. They dismiss the
progress, underestimate its potential, or claim it's decades away.</li>
<li>Anger: Once denial fades, anger emerges, often directed at those
perceived as enabling or hyping AGI. This can be targeted at AI
researchers, tech companies, or even the technology itself.</li>
<li>Bargaining: In this stage, people try to find ways to control or
mitigate AGI, often through unrealistic expectations or proposed
solutions.</li>
<li>Depression: As bargaining fails, a sense of profound unease and
hopelessness may set in. This is the realization that AGI could
fundamentally change society in ways that are difficult to predict or
control, leading to feelings of powerlessness.</li>
<li>Acceptance: This is the final stage, where people begin to accept
the reality of AGI and its potential impact. This isn't necessarily
cheerful, but it's characterized by a shift from denial and fear towards
a more realistic view.</li>
</ol>
<blockquote>
<p><strong>The Taiwan posts - Noahpinion</strong> [<a
target="_blank" rel="noopener" href="https://www.noahpinion.blog/p/the-taiwan-posts">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Disney Paid Off Trump for a Reason - BIG by Matt
Stoller</strong> [<a
target="_blank" rel="noopener" href="https://www.thebignewsletter.com/p/disney-paid-off-trump-for-a-reason">Link</a>]</p>
</blockquote>
<p>Fubo, a sports streaming service, had previously won a preliminary
injunction against a joint venture between Disney, Fox, and Warner Bros,
arguing that the venture was an illegal merger. However, Fubo's stock
wasn't performing well, leading Fubo CEO David Gandler to sell a
controlling stake in his company to Disney.</p>
<p>Here are the rationales behind this decision, according to the
sources:</p>
<ul>
<li>Fubo's CEO, David Gandler, profited from winning an antitrust suit
and joined forces with a large corporation. Instead of being an underdog
fighting against major corporations, Fubo has now joined forces with one
of them. Fubo will now have Disney's resources, while its leaders
imagine that it will operate somewhat independently.</li>
<li>Disney made a $16 million payment for defamation against Trump,
which is considered questionable by legal analysts, in order to gain
credibility with Trump. The aim of this was to ensure that government
enforcers would not interfere with the deal.</li>
<li>Fubo's leaders may be ignoring the risks involved in the merger.
They are potentially exhibiting a kind of "malevolent naivete" and
airbrushing away their own violation of the law.</li>
</ul>
<p>The sources suggest that Fubo's leadership may not be considering
some of the risks associated with mergers. Mergers carry significant
risk, and they can fall apart for a variety of reasons. During the 18-24
months that it takes to clear financing and regulatory hurdles, a
company under contract to be sold cannot make significant strategic
decisions or investments, while the purchaser can do whatever they want.
If the deal falls apart, the company that was to be sold could be in a
significantly worse position.</p>
<p>The sources point out that there is a possibility that another
private litigant could take Fubo's place and sue, using the legal
precedent set by Fubo. This is evidenced by a letter sent by EchoStar to
the court, in which the company states that it's considering suing along
the same lines as Fubo. This may not matter to Disney, since they now
control Fubo, but it should be a source of concern for Fubo's leadership
team who have essentially bet their company on a violation of the
law.</p>
<p>A private litigant, such as EchoStar, could take Fubo's place and sue
Disney, Fox, and Warner Bros, using the same legal arguments that Fubo
successfully used to win a preliminary injunction. This is a possibility
because the legal precedent set by Fubo remains, even though Fubo is now
under Disney's control.</p>
<p>Here's why this could be problematic for Fubo but not necessarily for
Disney:</p>
<ul>
<li>Fubo is in a vulnerable position due to the merger agreement. While
the deal is pending, Fubo is restricted in its strategic decision-making
and investments, effectively putting the company in "limbo". This means
Fubo cannot make significant moves to respond to a new lawsuit.</li>
<li>Disney, as the purchaser, is not similarly restricted. They can
continue to operate as they see fit. They have the resources to handle a
new legal challenge.</li>
<li>If the merger fails, Fubo will have wasted 18-24 months with the
potential for no significant strategic moves. It could end up in a
weakened state compared to competitors who were not in a merger process.
The company might even become "a limping and probably dead company".
Failed mergers can also lead to leadership changes, such as the CEO
getting fired.</li>
<li>Disney has already taken steps to ensure the deal's success,
including a payment to gain credibility with the current administration.
While another lawsuit could present a challenge, Disney has the
resources and political connections to navigate it, which Fubo does
not.</li>
<li>The incentive to complete the deal is different for Disney and Fubo.
Disney will remain a major player regardless of the deal's outcome.
However, Fubo's future is heavily dependent on the merger. This makes
Fubo more vulnerable if the deal is challenged.</li>
</ul>
<blockquote>
<p><strong>The rise and fall of "fact-checking" - Silver
Bulletin</strong> [<a
target="_blank" rel="noopener" href="https://www.natesilver.net/p/the-rise-and-fall-of-fact-checking">Link</a>]</p>
</blockquote>
<p>The main opinion of this article is that Meta's decision to replace
fact-checkers with a community notes system is justifiable because
fact-checkers have been politically biased and have not effectively
addressed the issue of misinformation.</p>
<p>While the author agrees with Zuckerberg's decision, they also
acknowledge that Zuckerberg's motivations may not be high-minded, but
rather driven by political pressure and business incentives. Despite
that, the author thinks the move is "pointing in the right direction,"
and agrees with Zuckerberg's claim that fact-checkers have been too
politically biased. The author also admits their own biases and that
Community Notes is a new program that might also have problems.</p>
<blockquote>
<p><strong>US Banks: Profits Surge - App Economy Insights</strong> [<a
target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/us-banks-profits-surge">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>CES 2025: AI Takes Over - App Economy Insights</strong> [<a
target="_blank" rel="noopener" href="https://www.appeconomyinsights.com/p/ces-2025-ai-takes-over">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>a16z's big ideas in tech for 2025 - ben lang's notes</strong>
[<a
target="_blank" rel="noopener" href="https://benlangsnotes.substack.com/p/a16zs-big-ideas-in-tech-for-2025">Link</a>]</p>
</blockquote>
<p>Andreessen Horowitz’s list of big ideas in tech for 2025:</p>
<figure>
<img src="/di-blog/2025/01/04/2025-January/a16z_big_idea_2025.png"
alt="a16z_big_idea_2025" />
<figcaption aria-hidden="true">a16z_big_idea_2025</figcaption>
</figure>
<blockquote>
<p><strong>How AI-assisted coding will change software engineering: hard
truths - The Pragmatic Engineer</strong> [<a
target="_blank" rel="noopener" href="https://newsletter.pragmaticengineer.com/p/how-ai-will-change-software-engineering">Link</a>]</p>
</blockquote>
<p>Great article!</p>
<blockquote>
<p><em>This "70% problem" suggests that current AI coding tools are best
viewed as:</em></p>
<ul>
<li><em>Prototyping accelerators for experienced developers</em></li>
<li><em>Learning aids for those committed to understanding
development</em></li>
<li><em>MVP generators for validating ideas quickly</em></li>
</ul>
<p><em>Current tools mostly wait for our commands. But look at newer
features like Anthropic's computer use in Claude, or Cline's ability to
automatically launch browsers and run tests. These aren't just glorified
autocomplete - they're actually understanding tasks and taking
initiative to solve problems.</em></p>
<p><em>Think about debugging: Instead of just suggesting fixes, these
agents can:</em></p>
<ul>
<li><em>Proactively identify potential issues</em></li>
<li><em>Launch and run test suites</em></li>
<li><em>Inspect UI elements and capture screenshots</em></li>
<li><em>Propose and implement fixes</em></li>
<li><em>Validate the solutions work (this could be a big deal)</em></li>
</ul>
<p><strong>― The 70% problem: Hard truths about AI-assisted coding -
Elevate</strong> [<a
target="_blank" rel="noopener" href="https://addyo.substack.com/p/the-70-problem-hard-truths-about">Link</a>]</p>
</blockquote>
<p>Great pragmatic article! And it's well-said in the end:
"<strong><em>Software quality was (perhaps) never primarily limited by
coding speed...The goal isn't to write more code faster. It's to build
better software.</em></strong> "</p>
<p>AI tools help experienced developers more than beginners. This is
similar to the fact that AI helps top biologists to be successful more
than normal biologists. The results and efficiency of AI usage differ
based on users' domain expertise. This is called 'knowledge paradox'. AI
can help to get the first 70% job done quickly, but the efforts on the
final 30% have diminishing returns. This is called 'AI learning curve
paradox'.</p>
<blockquote>
<p><strong>o1 isn’t a chat model (and that’s the point) - Latent
Space</strong> [<a
target="_blank" rel="noopener" href="https://www.latent.space/p/o1-skill-issue?utm_source=%2Finbox%2Fsaved&amp;utm_medium=reader2">Link</a>]</p>
</blockquote>
<ul>
<li><p>Provide Extensive Context: Give 10x more context than you think
is necessary. This includes details about previous attempts, database
schemas, and company-specific information. Think of o1 like a new hire
that needs all the relevant information to understand the task. Put the
context at the end of your prompt.</p>
<p>Use tools like voice memos to capture context and paste transcripts.
You can also save reusable segments of context for future use. AI
assistants within other products can help extract context.</p></li>
<li><p>Focus on the Desired Output: Instead of telling o1 <em>how</em>
to answer, clearly describe <em>what</em> you want the output to be. Let
o1 plan and resolve its own steps, leveraging its autonomous
reasoning.</p></li>
<li><p>Define Clear Evaluation Criteria: Develop specific criteria for
what constitutes a "good" output so that o1 can evaluate its own output
and improve. This moves the LLM-as-Judge into the prompt itself. Ask for
one specific output per prompt.</p></li>
<li><p>Be Explicit About Output Format: o1 often defaults to a
report-style output with numbered headings. Be clear if you need
complete files or other specific formats.</p></li>
<li><p>Manage Context and Expect Latency: Since o1 is not a chat model,
it will not respond in real time, like email. Make sure you can manage
and see the context you are providing to the model. o1 is better suited
to high-latency, long-running tasks.</p></li>
</ul>
<blockquote>
<p><strong>The Deep Roots of DeepSeek: How It All Began - Recode China
AI</strong> [<a
target="_blank" rel="noopener" href="https://recodechinaai.substack.com/p/the-deep-roots-of-deepseek-how-it">Link</a>]</p>
</blockquote>
<p>Liang's Visions from his first public interview in May 2023:</p>
<p><strong>AI Development:</strong></p>
<ul>
<li>Liang aims to build AGI, not just improve existing models like
ChatGPT.</li>
<li>He prioritizes deep research over quick applications, requiring more
resources.</li>
<li>He sees AI as a way to test ideas about human intelligence, like
whether language is key to thought.</li>
<li>He plans to share DeepSeek’s results publicly to keep AI accessible
and affordable.</li>
</ul>
<p><strong>Company Culture &amp; Innovation:</strong></p>
<ul>
<li>He hires based on ability, creativity, and passion, preferring fresh
graduates for key roles.</li>
<li>Employees should have freedom to explore and learn from
mistakes.</li>
<li>It can't be forced or taught.</li>
<li>A shared pace and curiosity drive the team, not strict rules or
KPIs.</li>
</ul>
<p><strong>Competition:</strong></p>
<ul>
<li>Startups can still challenge big companies since AI tech is
evolving.</li>
<li>No one has a clear lead in AI yet.</li>
<li>LLM applications will become easier, creating startup opportunities
for decades.</li>
<li>AI believers stay in for the long run.</li>
<li>Unconventional approaches can be a game-changer.</li>
</ul>
<p><strong>Resources &amp; Funding:</strong></p>
<ul>
<li>Securing GPUs and a strong engineering team is crucial.</li>
<li>Traditional VC funding may not fit DeepSeek’s research-heavy
approach.</li>
<li>Innovation is costly, and some waste is inevitable.</li>
<li>GPUs are a solid investment as they hold value.</li>
</ul>
<blockquote>
<p><strong>Is DeepSeek the new DeepMind? - AI Supremacy</strong> [<a
target="_blank" rel="noopener" href="https://www.ai-supremacy.com/p/deepseek-the-new-google-deepmind">Link</a>]</p>
</blockquote>
<p><strong>Implications for the AI Industry:</strong></p>
<ul>
<li>DeepSeek's emergence challenges the dominance of Western AI firms
like Google DeepMind, Meta, and OpenAI. The success of DeepSeek suggests
that open-source models can outperform proprietary ones. It also calls
into question the massive spending on AI infrastructure by Big Tech
companies.</li>
<li>Its cost-effectiveness is causing enterprises to rethink their AI
strategies. The availability of high-performing, cheaper models could
disrupt the business model of companies that rely on expensive,
proprietary models.</li>
<li>Its achievements indicate that China is becoming a leader in AI,
particularly in inference-time compute and compute efficiency. This
development raises concerns about America's shrinking lead in artificial
intelligence.</li>
<li>Its open-source approach is seen as essential to keeping AI
inclusive and accessible. The ability to run powerful models on a laptop
could decentralize AI development and reduce reliance on Big Tech.</li>
</ul>
<p><strong>Arguments about US vs. China in AI:</strong></p>
<ul>
<li>The article suggests that the U.S. is losing its lead in AI
innovation due to its focus on "Tycoon capitalism" and protectionist
policies. The U.S. government's export controls on semiconductors, while
intended to slow China's progress, may be inadvertently fueling China's
self-reliance and innovation.</li>
<li>China has advantages in areas such as manufacturing, go-to-market
strategies, talent (STEM programs and ML researchers), and patents.
China's progress in various overlapping industries creates a "mutually
reinforcing feedback loop". The article implies that Chinese work
culture of empowering workers with autonomy and collaboration is a
strong contrast to the grueling work schedules, rigid hierarchies, and
internal competition that are common in Chinese tech firms.</li>
<li>The article criticizes the massive AI infrastructure projects in the
U.S. (dubbed "Project Oracle") as a scheme by the financial elite to
control the future of AI. The author argues that these projects
prioritize the interests of Big Tech and the financial elite over those
of regular citizens and that these AI infrastructure projects are
primarily intended to redistribute wealth globally to the elite.</li>
</ul>
<p><strong>Concerns about AI's Impact:</strong></p>
<ul>
<li>The author acknowledges concerns that AI could lead to wage
deflation, particularly in white-collar jobs where AI can automate
tasks.</li>
<li>It questions the assumption that AI will create more jobs than it
displaces, noting that AI coding tools could negatively impact software
engineers.</li>
<li>It also raises concerns about the potential for misuse of AI,
including the use of AI for "authoritarian" control and as a weapon in
trade wars. There are also concerns about the potential for backdoors,
Trojans, model inversion attacks, sensitive information inference, and
automated social engineering via the release of attractive but cheap AI
services.</li>
</ul>
<p><strong>Additional Info:</strong></p>
<ul>
<li>DeepSeek is an offshoot of a quantitative hedge fund, High-Flyer,
and is fully funded by them.</li>
<li>It is noted for being more transparent about its methods compared to
some Western AI firms.</li>
<li>Its mission is to "unravel the mystery of Artificial General
Intelligence (AGI) with curiosity". They focus on open-source
development, research-driven innovation, and making advanced AI
accessible to all.</li>
</ul>
<blockquote>
<p><strong>Monopoly Round-Up: China Embarrasses U.S. Big Tech - BIG by
Matt Stoller</strong> [<a
target="_blank" rel="noopener" href="https://www.thebignewsletter.com/p/monopoly-round-up-china-embarrasses">Link</a>]</p>
</blockquote>
<ul>
<li>DeepSeek, a Chinese AI firm, developed cost-effective AI models that
rival U.S. models and released them on an open-source basis. This is a
significant accomplishment, especially since the U.S. has placed export
controls that prevent China from accessing the best chips. DeepSeek's
approach focused on efficiency, rather than raw computing power, which
challenges the assumption that computing power is the primary
competitive barrier in AI. This development is considered
<strong>embarrassing and threatening to big tech and U.S.
security.</strong></li>
<li>The U.S. has heavily invested in AI, with tech giants spending
billions on data centers and infrastructure, betting that these
investments will provide a competitive advantage. However, DeepSeek’s
success suggests that this approach may be flawed. The sources suggest
that <strong>the U.S. strategy of denying top chips to China may also be
ineffective.</strong></li>
<li>The sources argue that betting on monopolistic national champions is
a disastrous national security strategy. It points out that history
shows that <strong>monopolies are slow to innovate. The U.S. needs to
prioritize competition over protecting monopolies.</strong> The sources
criticize large U.S. tech firms (Meta, Microsoft, Google, Amazon, Apple)
for becoming slothful bureaucracies that are not very good at developing
and deploying technology.</li>
<li>Chinese policy is noted to be more aggressive in forcing competition
in some sectors. China's electric vehicle industry is cited as an
example of this. The Chinese government's crackdown on its big tech
firms and financial sector is also mentioned as a move that has
seemingly benefited the economy by driving innovation. The success of
companies like ByteDance and DeepSeek is mentioned as evidence of
this.</li>
<li>The sources highlight that U.S. anti-monopoly laws take too long to
take effect. It uses the example of the Federal Trade Commission's case
against Facebook for its acquisition of Instagram and WhatsApp. This
case highlights how companies like Facebook acquire and bury innovative
competitors rather than compete. It argues that <strong>if Facebook had
been broken up, there would be tremendous innovation in social
networking.</strong></li>
<li>The sources express uncertainty about the future of AI, noting it
might not live up to expectations. It also notes that the
<strong>competitive advantages in AI are not as straightforward as
previously thought</strong>.</li>
</ul>
<blockquote>
<p><em>In a <a target="_blank" rel="noopener" href="https://archive.is/JnE4j">rare interview</a> for
AnYong Waves, a Chinese media outlet, DeepSeek CEO Liang Wenfeng
emphasized innovation as the cornerstone of his ambitious
vision:</em></p>
<p><em>. . . we believe the most important thing now is to participate
in the global innovation wave. For many years, Chinese companies are
used to others doing technological innovation, while we focused on
application monetization—but this isn’t inevitable. In this wave, our
starting point is not to take advantage of the opportunity to make a
quick profit, but rather to reach the technical frontier and drive the
development of the entire ecosystem.</em></p>
<p><strong>― 7 Implications of DeepSeek’s Victory Over American AI
Companies - The Algorithmic Bridge</strong> [<a
target="_blank" rel="noopener" href="https://www.thealgorithmicbridge.com/p/7-implications-of-deepseeks-victory">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>"Every job is a bundle of tasks.</em></p>
<p><em>Every new technology wave (including the ongoing rise of Gen AI)
attacks this bundle.</em></p>
<p><em>New technology may <strong>substitute</strong> a specific task
<strong>(Automation)</strong> or it may <strong>complement</strong> a
specific task <strong>(Augmentation)</strong>"</em></p>
<p><em>Extend this analogy far enough, and you get this:</em></p>
<p><em>Once technology has substituted all tasks in a job bundle, it can
effectively displace the job itself.</em></p>
<p><em>Of course, there are limits to this logic. This can only be true
for a small number of jobs, which involve task execution only.</em></p>
<p><em>But most jobs require a lot more than mere task
execution.</em></p>
<p><em>They require ‘getting things done’. They require achievement of
objectives, accomplishment of outcomes.</em></p>
<p><em>In other words, <strong>most jobs involve
goal-seeking.</strong></em></p>
<p><em>This is precisely why previous generations of technologies
haven’t fully substituted most jobs. They chip away at tasks in the job
bundle without really substituting the job entirely.</em></p>
<p><em>Because humans retain their right to play because of their
ability to plan and sequence tasks together to achieve goals.</em></p>
<p><em>In most previous instances, technology augments humans far more
than automating an entire job away.</em></p>
<p><strong><em>And that is because humans possess a unique advantage:
goal-seeking.</em></strong></p>
<p><strong>― Slow-burn AI: When augmentation, not automation, is the
real threat - Platforms, AI, and the Economics of BigTech</strong> [<a
target="_blank" rel="noopener" href="https://platforms.substack.com/p/slow-burn-ai-when-augmentation-not">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>AI agents are the first instance of technology directly attacking
and substituting goals within a role or a team.</em></p>
<p><em>In doing so, they directly impact power dynamics within an
organization, empowering some roles and weakening others, empowering
some teams and weakening others.</em></p>
<p><strong>― How AI agents rewire the organization - Platforms, AI, and
the Economics of BigTech</strong> [<a
target="_blank" rel="noopener" href="https://platforms.substack.com/p/ai-wont-eat-your-job-but-it-will-880">Link</a>]</p>
</blockquote>
<p>This is a brilliant article.</p>
<p>Goal-seeking, for the first time, can be performed by technology.</p>
<ol type="1">
<li>Scope of the role: Effectively, a goal-seeking AI agent can unbundle
a goal from the role. They reduce the scope of the role.</li>
<li>Scope of the team: They displace the role entirely in a team if the
team can now achieve the same goal using an AI agent.</li>
<li>Rebundling of roles: Role B is eliminated not because its tasks were
fully substituted by technology, nor because its goals were fully
substituted by technology, but because the scope of the role no longer
justified a separate role.</li>
<li>Reworking power structures: Teams have voting rights on the
relevance of Roles. The fewer teams speaking to a role’s contributions,
the lower the negotiating power for that role within the
organization.</li>
<li>Roles unbundle, teams rebundle: this cycle of unbundling and
rebundling across roles and teams is inherent to the organization of
work. AI isn’t fundamentally changing goal-seeking and resource
allocation. It is merely inserting itself into the organization and
re-organization of work.</li>
</ol>
<h2 id="youtube-and-podcasts">YouTube and Podcasts</h2>
<blockquote>
<p><strong>2025 Predictions with bestie Gavin Baker - All-In
Podcasts</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=HxNUAwBWX4I&amp;ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<p>Interesting discussions about new year predictions. Here is a summary
of the predictions:</p>
<p><strong>Chamath Palihapitiya:</strong></p>
<ul>
<li><strong>Biggest Political Winner:</strong> Fiscal conservatives. He
believes austerity will reveal waste and fraud in the US government and
that this will spill over to state elections.</li>
<li><strong>Biggest Political Loser:</strong> Progressivism. He predicts
a repudiation of class-based identity politics in multiple Western
countries.</li>
<li><strong>Biggest Business Winner:</strong> Dollar-denominated
stablecoins, which he believes will grow substantially and challenge the
dominance of Visa and Mastercard.</li>
<li><strong>Biggest Business Loser:</strong> The "MAG 7" companies will
see a drawdown in absolute dollars due to high concentration in the
indices. He suggests that these companies may not be able to maintain
their high valuations, though they are good businesses.</li>
<li><strong>Biggest Business Deal:</strong> The collapse of traditional
auto OEMs and a wave of auto mega-mergers, triggered by Tesla's strong
position.</li>
<li><strong>Most Contrarian Belief:</strong> A banking crisis in a major
mainline bank, triggered by the total indebtedness of Pax America and
the impact of higher interest rates.</li>
<li><strong>Best Performing Asset:</strong> Credit Default Swaps (CDS)
as an insurance policy against a potential default event.</li>
<li><strong>Worst Performing Asset:</strong> The software industrial
complex, or large, bloated enterprise software companies.</li>
<li><strong>Most Anticipated Trend:</strong> Small, arcane regulatory
changes related to the supplemental loss ratio that allow the US to kick
the debt can down the road.</li>
<li><strong>Most Anticipated Media:</strong> The enormity of files that
will be declassified and released by the Trump administration.</li>
<li><strong>Prediction Market:</strong> The MAG 7 representation in the
S&amp;P 500 shrinks below 30%.</li>
</ul>
<p><strong>David Friedberg:</strong></p>
<ul>
<li><strong>Biggest Political Winner</strong>: Young political
candidates, marking a trend of a shift towards younger leaders.</li>
<li><strong>Biggest Political Loser:</strong> Pro-war neoconservatives.
He believes they will lose out to figures like JD Vance and Elon
Musk.</li>
<li><strong>Biggest Business Winner:</strong> Autonomous hardware and
robotics, citing the rise of humanoid robots and their
applications.</li>
<li><strong>Biggest Business Loser</strong>: Old defense and aerospace
providers, like Boeing and Lockheed Martin. He predicts a shift towards
more tech-oriented and rationalized spending in defense. He also thinks
Vertical SaaS companies will struggle as AI replaces their
services.</li>
<li><strong>Biggest Business Deal:</strong> Massive funding deals for
hardware-based manufacturing buildout in the United States, potentially
involving government support.</li>
<li><strong>Most Contrarian Belief:</strong> A dramatic rise in
socialist movements in the United States, fueled by economic inequality
and disruption from AI.</li>
<li><strong>Best Performing Asset:</strong> Chinese tech stocks or ETFs,
based on potential deals between the US and China and the strong
fundamentals of Chinese tech companies.</li>
<li><strong>Worst Performing Asset:</strong> Vertical SaaS companies
again as AI replaces the practices. Also legacy car companies and real
estate because of overbuilding and high debt.</li>
<li><strong>Most Anticipated Trend:</strong> The announcement of
buildout of nuclear power in the United States.</li>
<li><strong>Most Anticipated Media:</strong> AI Video Games with dynamic
story lines</li>
<li><strong>Prediction Market</strong>: Microsoft, AWS, and Google Cloud
Revenue Growth.</li>
</ul>
<p><strong>Gavin Baker:</strong></p>
<ul>
<li><strong>Biggest Political Winner:</strong> Trump and centrism; also
Gen X and Elder Millennials.</li>
<li><strong>Biggest Political Loser:</strong> Putin, due to Europe
rearming, which shifts US resources to the Pacific, and Trump's likely
tougher stance.</li>
<li><strong>Biggest Business Winner:</strong> Big businesses that use AI
thoughtfully, and the robotics industry, as well as companies that make
high bandwidth memory.</li>
<li><strong>Biggest Business Loser:</strong> Government service
providers with over 35% of their revenue coming from the US government.
He also thinks Enterprise application software will be hurt by AI
agents</li>
<li><strong>Biggest Business Deal:</strong> A wave of M&amp;A after a
period of inactivity and something significant happening with Intel.
Also, he thinks independent AI labs will get acquired.</li>
<li><strong>Most Contrarian Belief:</strong> The US will experience at
least one year of greater than 5% real GDP growth due to AI and
deregulation. He also thinks frontier AI labs will stop releasing their
leading-edge models.</li>
<li><strong>Best Performing Asset:</strong> Companies that make high
bandwidth memory (HBM).</li>
<li><strong>Worst Performing Asset:</strong> Enterprise application
software.</li>
<li><strong>Most Anticipated Trend:</strong> AI will make more progress
per quarter in 2025 than it did per year in 2023 and 2024, due to
scaling performance through reasoning, pre-training, and test time
compute.</li>
<li><strong>Most Anticipated Media:</strong> Season 2 of 1923</li>
<li><strong>Prediction Market</strong>: US Treasury Market Report on
Federal Debt in December 2025 above or below $38 trillion</li>
<li><strong>UFOs:</strong> Believes there is a 25% chance the US
government is sitting on knowledge of extraterrestrial life.</li>
</ul>
<p><strong>Jason Calacanis:</strong></p>
<ul>
<li><strong>Biggest Business Winner:</strong> Tesla and Google for AI
and Robotics</li>
<li><strong>Biggest Business Loser:</strong> Open AI</li>
<li><strong>Biggest Business Deal:</strong> Partnerships between Amazon,
Uber, Tesla, and Waymo for autonomy, delivery, and e-commerce</li>
<li><strong>Most Contrarian Belief:</strong> Open AI will lose its lead
and its nonprofit-to-for-profit transition and become the number four
player in AI.</li>
<li><strong>Best Performing Asset:</strong> MAG 7 stocks</li>
<li><strong>Worst Performing Asset:</strong> Legacy car companies and
Real Estate.</li>
<li><strong>Most Anticipated Trend:</strong> Exits and DPI will shower
down, along with a surge in M&amp;A and IPOs</li>
<li><strong>Most Anticipated Media:</strong> Legacy media outlets owned
by billionaires attempting to steer towards the middle</li>
<li><strong>Prediction Market:</strong> Over or under 750,000
deportations by Trump in the first year of office</li>
</ul>
<blockquote>
<p><strong>Building Anthropic | A conversation with our co-founders -
Anthropic</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=om2lIWXLLN4&amp;ab_channel=Anthropic">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>WTF is Artificial Intelligence Really? | Yann LeCun x Nikhil
Kamath | People by WTF Ep #4 - Nikhil Kamath</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=JAgHUDhaTU0&amp;ab_channel=NikhilKamath">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The Next Frontier: Sam Altman on the Future of A.I. and
Society - New York Times Events</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=tn0XpTAD_8Q&amp;ab_channel=NewYorkTimesEvents">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>LA's Wildfire Disaster, Zuck Flips on Free Speech, Why Trump
Wants Greenland</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=is1QAZ7ShRU&amp;ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Text, camera, action! Frontiers in controllable video
generation - William (Bill) Peebles</strong> [<a
target="_blank" rel="noopener" href="https://icml.cc/virtual/2024/workshop/29968">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Best of 2024 in Agents (from #1 on SWE-Bench Full, Prof.
Graham Neubig of OpenHands/AllHands) - Latent Space</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=B6PKVZq2qqo&amp;ab_channel=LatentSpace">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>The State of AI Startups in 2024 [LS Live @ NeurIPS] - Latent
Space</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=HM1d7kMebEI&amp;ab_channel=LatentSpace">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Best of 2024 in Vision [LS Live @ NeurIPS] - Latent
Space</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=76EL7YVAwVo&amp;t=4s&amp;ab_channel=LatentSpace">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Red-pilled Billionaires, LA Fire Update, Newsom's Price Caps,
TikTok Ban, Jobless MBAs - All-In Podcast</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=WQ35G6XI8Uw&amp;ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>NVIDIA CEO Jensen Huang Keynote at CES 2025 - NVIDIA</strong>
[<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=k82RwXqZHY8&amp;ab_channel=NVIDIA">Link</a>]</p>
</blockquote>
<p>CES 2025 is the world's biggest tech expo. Each January, CES kicks
off the tech year by highlighting everything from groundbreaking gadgets
to the processors driving our digital world.</p>
<p>NVIDIA's CES announcements showcased its dominance in the AI chip
market while highlighting its bold expansion into emerging, high-growth
sectors. By emphasizing robotics, autonomous vehicles, and broader
accessibility to AI, NVIDIA demonstrated its commitment to staying
central to this wave of innovation.</p>
<p><strong>Highlights</strong>:</p>
<ol type="1">
<li><p><strong>GeForce RTX 50 Series GPUs</strong></p>
<p>NVIDIA unveiled its latest GeForce RTX 50 series GPUs, powered by the
advanced Blackwell architecture and set to launch in January. These GPUs
deliver significant improvements in gaming and AI performance, with the
flagship RTX 5090 priced at <span class="math inline">\(\$1,999\)</span>
and the RTX 5070 at <span class="math inline">\(\$549\)</span>,
surpassing the RTX 4090, which debuted at <span
class="math inline">\(\$1,599\)</span> in 2022.</p>
<p>The 50 series also introduces DLSS 4, a cutting-edge Deep Learning
Super Sampling technology that employs a transformer-based architecture
to generate three AI-rendered frames for every traditionally rendered
one, enhancing graphics quality and gaming experiences. NVIDIA partnered
with Micron to supply memory chips for these GPUs.</p>
<p>Although GeForce RTX GPUs contributed only 9% of NVIDIA’s revenue in
the October quarter, the company’s primary growth continues to come from
its Data Center segment, driven by AI demand.</p></li>
<li><p><strong>AI Advancements</strong></p>
<p>NVIDIA introduced Nemotron, a new family of AI models derived from
Meta’s Llama models, including Llama Nemotron Nano, Super, and Ultra,
aimed at advancing AI agent capabilities. CEO Jensen Huang projects that
the AI agent market could be worth trillions of dollars.</p>
<p>Additionally, NVIDIA confirmed that its Blackwell AI accelerators are
in full production and are being adopted by leading cloud providers and
PC manufacturers, further solidifying its position in AI
technology.</p></li>
<li><p><strong>Robotics and Autonomous Vehicles</strong></p>
<p>NVIDIA debuted Cosmos, the "world's first physical AI model,"
designed to advance robotics. Trained on 20 million hours of video,
Cosmos is open-licensed on GitHub and integrates seamlessly with
NVIDIA’s Omniverse platform to provide physics-based simulations for AI
model training in robotics and autonomous systems.</p>
<p>In partnership with Toyota, NVIDIA is collaborating on developing the
automaker's latest autonomous vehicles. Huang sees robotics and
autonomous technology as a <span class="math inline">\(\$1\)</span>
trillion market opportunity, expecting NVIDIA’s automotive revenue to
grow from <span class="math inline">\(\$4\)</span> billion in FY25 to
<span class="math inline">\(\$5\)</span> billion in FY26, spanning Data
Center and OEM segments.</p></li>
<li><p><strong>Project DIGITS</strong></p>
<p>NVIDIA announced Project DIGITS, a personal AI supercomputer aimed at
democratizing access to powerful AI tools. Starting at <span
class="math inline">\(\$3,000\)</span>, the system features the GB10
Grace Blackwell Superchip, 128GB of unified memory, and up to 4TB of
NVMe storage. Users can connect two systems for enhanced processing
capabilities.</p>
<p>Designed for AI researchers and data scientists, Project DIGITS
provides a cost-effective solution for building complex AI models
without relying on large-scale data center resources.</p></li>
</ol>
<p><strong>A not comprehensive summary of NVIDIA's efforts on AI, not a
summary of this YouTube video</strong>:</p>
<ol type="1">
<li><p><strong>AI Compute Hardware:</strong></p>
<p>This category includes the physical processing units that perform the
core calculations for AI models. These are primarily GPUs, but also
include specialized CPUs and other accelerators.</p>
<p><strong>Focus:</strong> High-performance, parallel processing, low
latency, memory bandwidth, energy efficiency for AI workloads.</p>
<p><strong>Examples</strong>:</p>
<p>NVIDIA A100 Tensor Core GPU NVIDIA A40 Tensor Core GPU NVIDIA A10
Tensor Core GPU NVIDIA H100 Tensor Core GPU NVIDIA L40 GPU NVIDIA L4 GPU
NVIDIA B100 "Blackwell" Data Center GPU NVIDIA Grace CPU Superchip
GeForce RTX 30 Series (Desktop) - Ampere (Relevance for model
development) GeForce RTX 50 Series (Desktop) - Blackwell (Relevance for
model development) Project DIGITS - Hardware system (personal AI
supercomputer).</p></li>
<li><p><strong>AI Platforms &amp; Systems:</strong></p>
<p>This category includes integrated hardware and software solutions
designed to simplify the development and deployment of AI applications.
It encompasses both edge and data center solutions.</p>
<p><strong>Focus:</strong> Ease of use, scalability, optimized
performance for specific AI tasks, deployment solutions.</p>
<p><strong>Examples</strong>:</p>
<p>NVIDIA DGX A100 System NVIDIA Jetson AGX Xavier NX NVIDIA Jetson Orin
NVIDIA Jetson Orin Nano NVIDIA Omniverse Platform</p></li>
<li><p><strong>AI Software &amp; Development Tools:</strong></p>
<p>This category includes the software libraries, frameworks, and tools
that allow developers to build, train, and deploy AI models. It covers
both open source and proprietary tools.</p>
<p><strong>Focus:</strong> Developer productivity, model performance,
framework support, customization.</p>
<p><strong>Examples</strong>:</p>
<p>NVIDIA Merlin (Software Library) NVIDIA NeMo Framework NVIDIA TAO
Toolkit</p></li>
<li><p><strong>AI Applications &amp; Solutions:</strong></p>
<p>This category focuses on specific, industry-focused AI applications
built on top of NVIDIA hardware and software.</p>
<p><strong>Focus:</strong> Pre-built solutions, vertical market
expertise, end-to-end solutions.</p>
<p><strong>Examples</strong>: Intelligent Video Analytics (IVA),
autonomous vehicle solutions, AI-driven healthcare, generative
AI.</p></li>
<li><p><strong>AI Research and Frameworks</strong></p>
<p>While related to AI Software and development tools, it deserves its
own category because of the open source nature of much of the research
based tools and APIs, allowing for community contributions and new
technology development.</p>
<p><strong>Focus:</strong> Next-generation tools, advanced research,
pushing the limits of AI, new technologies and algorythms.</p>
<p><strong>Examples</strong>: Nemotron NVIDIA FLARE (Federated Learning
Application Runtime Environment) NVIDIA Research Publications and
Open-Source Projects TensorFlow and PyTorch (With NVIDIA's
Extensions)</p></li>
</ol>
<blockquote>
<p><em>So, my takeaway was entirely different. It was not a commentary
on Masa, or Larry, or Sam. I think all of those three companies are,
frankly, very good. It was more a comment that you have to be very
careful to protect the president's legacy, if I were them, to make sure
that the things that get announced are actually further down the
technical spectrum and are actually going to be real. Because if they
achieve these things, but it costs you a billion dollars and you only
hire 50 people, there's going to be a little bit of egg on the face. And
so, that was sort of my own takeaway. I think that the things were
decoupled. It just seemed more like marketing and sizzle and kind of
hastily put together. I think it would be great if OpenAI builds another
incredible model, whatever comes after o3, o4, o5. But it's not clear
that you have to spend $500 billion to do it. - Chamath
Palihapitiya</em></p>
<p><strong>― Trump's First Week: Inauguration Recap, Executive Actions,
TikTok, Stargate + Sacks is Back! - All-In Podcast</strong> [<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=e1pTCSFrkbk&amp;ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>There's a thing called <a
target="_blank" rel="noopener" href="https://www.wikiwand.com/en/articles/Jevons_paradox">Jevons
Paradox</a>, which kind of speaks to this concept. SAA actually tweeted
about it. It's an economic concept where, as the cost of a particular
use goes down, the aggregate demand for all consumption of that thing
goes up. So, the basic idea is that as the price of AI gets cheaper and
cheaper, we're going to want to use more and more of it. You might
actually get more spending on it in the aggregate. That's right—because
more and more applications will become economically feasible. Exactly.
That is, I think, a powerful argument for why companies are going to
want to continue to innovate on frontier models. You guys are taking a
very strong point of view that open source is definitely going to win,
that the leading model companies are all going to get commoditized, and
therefore, there will be no return on capital—essentially forcing
continued innovation on the frontier. - David Sacks</em></p>
<p><em>But then there's this dark horse that nobody's talking about—it's
called electricity. It's called power. And all these vehicles are
electric vehicles. If you said, 'You know, I just did some quick
back-of-the-envelope calculations,' if all of the miles in California
went to EV ride-sharing, you would need to double the energy capacity of
California. Right? Let's not even talk about what it would take to
double the energy capacity of the grid and things like that in
California. Let's not even go there. Even getting 10% or 20% more
capacity is going to be a gargantuan, five-to-ten-year exercise. Look, I
live in LA—in a nice area in LA—and we have power outages all the
freaking time because the grid is messed up. They're sort of upgrading
it as things break. That's literally where we're at in LA, in one of the
most affluent neighborhoods. That’s just the reality. So, I think the
dark horse, kind of hot take, is combustion engine AVs. Because I don’t
know how you can scale AVs really, really massively with the electric
grid as it is. - Travis Kalanick</em></p>
<p><em>I just wanted to read a message from Brian Yutko, who's the CEO
of Wisk, which is building a lot of these autonomous systems. He said:
'First, automatic traffic collision avoidance systems do exist right
now. These aircraft will not take control from the pilot to save the
aircraft, even if the software and systems on the aircraft know that
it’s going to collide. That’s the big flip that needs to happen in
aviation—automation can actually kick in and take over, even in piloted
aircraft, to prevent a crash. That’s the minimum of where we need to go.
Some fighter jets have something called Automatic Ground Collision
Avoidance Systems that do exactly this when fighter pilots pass out.
It’s possible for commercial aviation as well.' And then, the second
thing he said is: 'We need to have better ATC (Air Traffic Control)
software and automation. Right now, we use VHF radio communications for
safety and critical instructions, and that’s kind of insane. We should
be using data links, etc. The whole ATC system runs on 1960s technology.
They deserve better software and automation in the control towers—it’s
totally ripe for change. The problem is that attempts at reform have
failed.' - Chamath Palihapitiya</em></p>
<p><strong>― DeepSeek Panic, US vs China, OpenAI $40B?, and Doge
Delivers with Travis Kalanick and David Sacks - All-In Podcast</strong>
[<a
target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=8RkgkOqWs0s&amp;ab_channel=All-InPodcast">Link</a>]</p>
</blockquote>
<h2 id="articles-and-blogs">Articles and Blogs</h2>
<blockquote>
<p><strong>The Art of Leading Teammates - Harvard Business
Review</strong> [<a
target="_blank" rel="noopener" href="https://hbr.org/2024/09/tom-brady-on-the-art-of-leading-teammates">Link</a>]</p>
</blockquote>
<p>A Team-Focused Philosophy</p>
<ul>
<li>Put the team first, always, even when facing personal
adversity.</li>
<li>Show appreciation for unsung colleagues.</li>
<li>Set the standard and create a culture of 100% effort.</li>
<li>Recognize teammates’ individual psychology and the best ways to
motivate them.</li>
<li>Understand and complement the style of the formal leader.</li>
<li>Recognize and counteract the external forces that can cause selfish
behavior.</li>
<li>Create opportunities to connect as people outside the office.</li>
</ul>
<p>What Helps—and What Gets in the Way</p>
<ul>
<li>The emotions and behaviors that define individuals are formed
early.</li>
<li>Leaders work within a system.</li>
<li>It can be hard for individual team leaders to influence change
across large organizations.</li>
<li>A leader’s style and influence will take time to evolve.</li>
</ul>
<blockquote>
<p><em>Early adopters of gen AI can eclipse rivals by using it to
identify entirely new product opportunities, automate routine decisions
and processes, deliver customized professional services, and communicate
with customers more quickly and cheaply than was possible with
human-driven processes.</em></p>
<p><em>Far from being a source of advantage, even in sectors where its
impact will be profound, gen AI will be more likely to erode a
competitive advantage than to confer one, because its very nature makes
new insights and data patterns almost immediately transparent to anyone
using gen AI tools.</em></p>
<p><em>If you already have a competitive advantage that rivals cannot
replicate using gen AI, the technology may amplify the value you derive
from that advantage.</em></p>
<p><em>Businesses that try to deny the power of gen AI will certainly
fail. Those that adopt it will stay in the fight. But at this stage it
looks likely that the only ones that will actually win with it will be
those that can apply it to amplify the advantages they already
have.</em></p>
<p><strong>― AI Won’t Give You a New Sustainable Advantage - Harvard
Business Review</strong> [<a
target="_blank" rel="noopener" href="https://hbr.org/2024/09/ai-wont-give-you-a-new-sustainable-advantage">Link</a>]</p>
</blockquote>
<blockquote>
<table style="width:100%;">
<colgroup>
<col style="width: 34%" />
<col style="width: 28%" />
<col style="width: 37%" />
</colgroup>
<thead>
<tr>
<th style="text-align: left;"><em>To prevent this problem:</em></th>
<th style="text-align: left;"><em>Ask about this:</em></th>
<th style="text-align: left;"><em>Sample questions:</em></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;"><em>Conflating Correlation And
Causation</em></td>
<td style="text-align: left;"><em>Approach to determining
causality</em></td>
<td style="text-align: left;"><em>Was this analysis based on an
experiment? If not, are there confounders (variables that affect the
independent and dependent variables)?To what extent were they addressed
in the analysis?</em></td>
</tr>
<tr>
<td style="text-align: left;"><em>Misjudging The Potential Magnitude Of
Effects</em></td>
<td style="text-align: left;"><em>Sample size and the precision of the
results</em></td>
<td style="text-align: left;"><em>What was the average effect of the
change? What was the sample size and the confidence interval (or range
of likely values the true effect would fall into, and the degree to
which one is certain it would fall into that range)? How would our
course of action change, depending on where the true effect might
lie?</em></td>
</tr>
<tr>
<td style="text-align: left;"><em>A Disconnect Between What Is Measured
And What Matters</em></td>
<td style="text-align: left;"><em>Outcome measures</em></td>
<td style="text-align: left;"><em>What outcomes were measured? Were they
broad enough? Did they capture key intended and unintended consequences?
Were they tracked for an appropriate period of time? Were all relevant
outcomes reported? How do we think they map to broader organizational
goals?</em></td>
</tr>
<tr>
<td style="text-align: left;"><em>Misjudging Generalizability</em></td>
<td style="text-align: left;"><em>Empirical setting and subgroup
analysis</em></td>
<td style="text-align: left;"><em>How similar is the setting of this
study to our business context? Does the context or time period of the
analysis make it more or less relevant to our decision? What is the
composition of the sample being studied, and how does it influence the
applicability of the results? Does the effect vary across subgroups or
settings? Does this tell us anything about the generalizability of the
results?</em></td>
</tr>
<tr>
<td style="text-align: left;"><em>Overweighting A Specific
Result</em></td>
<td style="text-align: left;"><em>Broader evidence and further data
collection</em></td>
<td style="text-align: left;"><em>Are there other analyses that validate
the results and approach? What additional data could we collect, and
would the benefit of gathering it outweigh the cost of collecting it?
How might this change our interpretation of the results?</em></td>
</tr>
</tbody>
</table>
<p><strong>― Where Data-Driven Decision-Making Can Go Wrong - Harvard
Business Review</strong> [<a
target="_blank" rel="noopener" href="https://hbr.org/2024/09/where-data-driven-decision-making-can-go-wrong">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Will Psychedelics Propel Your Career? - Harvard Business
Review</strong> [<a
target="_blank" rel="noopener" href="https://hbr.org/2024/09/will-psychedelics-propel-your-career">Link</a>]</p>
</blockquote>
<p>Do you want to take a 'trip'? lol</p>
<blockquote>
<p><strong>How Scalable Compute Resources Can Boost LLM Performance -
HuggingFace</strong> [<a
target="_blank" rel="noopener" href="https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute">Link</a>]</p>
</blockquote>
<p>This blog explains how to scale test-time compute for models like
OpenAI's o1 - apply dynamic inference strategies to improve performance
without increasing pretraining budgets. These techniques allow smaller
models to outperform larger models on tasks such as math problems.</p>
<blockquote>
<p><em>We introduce deliberative alignment, a training paradigm that
directly teaches reasoning LLMs the text of human-written and
interpretable safety specifications, and trains them to reason
explicitly about these specifications before answering. We used
deliberative alignment to align OpenAI’s o-series models, enabling them
to use chain-of-thought (CoT) reasoning to reflect on user prompts,
identify relevant text from OpenAI’s internal policies, and draft safer
responses.</em></p>
<p><strong>― Deliberative alignment: reasoning enables safer language
models - OpenAI</strong> [<a
target="_blank" rel="noopener" href="https://openai.com/index/deliberative-alignment/">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>Moravec’s paradox is the observation by artificial intelligence
and robotics researchers that, contrary to traditional assumptions,
reasoning requires very little computation, but sensorimotor and
perception skills require enormous computational resources. The
principle was articulated by Hans Moravec, Rodney Brooks, Marvin Minsky,
and others in the 1980s.</em></p>
<p><strong>― Common misconceptions about the complexity in robotics vs
AI - Harimus Blog</strong> [<a
target="_blank" rel="noopener" href="https://harimus.github.io//2024/05/31/motortask.html">Link</a>]</p>
</blockquote>
<p>Yes, as Yann LeCun mentioned in one of his previous campus lectures,
LLM might help but it is not the right solution for robotics. This
article made several good points:</p>
<ul>
<li>Sensorimotor Tasks Are More Complex. The source emphasizes that
sensorimotor tasks are harder than many people realize. It was once
assumed that perception and action were simple compared to reasoning,
but this has turned out to be incorrect. This idea is known as Moravec's
Paradox.</li>
<li>Real-World Interaction is the challenge. Robotics requires robots to
interact with a dynamic, chaotic, and complex real world. Tasks that
seem simple for humans, like picking up a coffee cup, involve complex,
unconscious processes that are hard to program for a robot. Even small
changes in the environment can require a complete rewrite of the robot's
"move commands". Robots need to break down movements into muscle
contractions and forces, which is more complex than it seems.</li>
<li>Data Requirements is another challenge. LLMs thrive on massive
amounts of data, like text and images from the internet. Robotics
requires precise, high-quality data that is hard to collect. The variety
and preciseness of the data are also important. Unlike LLMs where
quantity of data is key, in robotics, the quality of the data collected
matters more than the quantity.</li>
</ul>
<p>Regarding the question "do we need better hardware to learn", I think
we need a system of sensors that can capture every physical movement of
a body and every angle a body can perceive. In terms of a world model,
the system needs to be on a larger scale.</p>
<blockquote>
<p><strong>OpenAI has created an AI model for longevity science - MIT
Technology Review</strong> [<a
target="_blank" rel="noopener" href="https://www.technologyreview.com/2025/01/17/1110086/openai-has-created-an-ai-model-for-longevity-science/">Link</a>]</p>
</blockquote>
<p>OpenAI's success with GPT-4b micro demonstrates the potential of LLMs
to go beyond natural language processing and address highly specialized
scientific problems. The model's ability to redesign Yamanaka factors to
improve their effectiveness by 50x could be a game-changer in stem cell
research, accelerating advancements in regenerative medicine. This
development highlights a significant milestone in the use of AI for
scientific discovery, particularly in the field of protein engineering
and regenerative medicine.</p>
<blockquote>
<p><em>A classic pattern in technology economics, identified by Joel
Spolsky, is layers of the stack attempting to become monopolies while
turning other layers into perfectly-competitive markets which are
commoditized, in order to harvest most of the consumer surplus;
discussion and examples.</em></p>
<p><strong>― Laws of Tech: Commoditize Your Complement -</strong> [<a
target="_blank" rel="noopener" href="https://gwern.net/complement">Link</a>]</p>
</blockquote>
<p>This is exactly Meta's strategy initially competing with close-source
AI model businesses - <strong>commoditize their complements</strong> to
increase demand for their own products. And there are more examples
mentioned in this article.</p>
<ul>
<li><p><strong>Core Concept:</strong></p>
<p>Products have substitutes and complements. A substitute is an
alternative product that can be bought if the first product is too
expensive. A complement is a product usually bought together with
another product. Demand for a product increases when the price of its
complements decreases. Companies strategically try to
<strong>commoditize their complements</strong> to increase demand for
their own products. Commoditizing a complement means driving its price
down to a point where many competitors offer indistinguishable goods.
This strategy allows a company to become a quasi-monopolist and divert
the majority of the consumer surplus to themselves.</p></li>
<li><p><strong>How it works</strong>:</p>
<p>A company seeks a chokepoint or quasi-monopoly in a product composed
of multiple layers. It dominates one layer of the stack while fostering
competition in another layer. This drives down prices in the
commoditized layer, increasing overall demand. The company profits from
increased demand for its core product while the competitors in the
commoditized layer struggle with low margins. The goal is to make a
complement free or very cheap, to increase profits elsewhere. This
strategy is an alternative to vertical integration.</p></li>
<li><p><strong>Examples of Commoditization:</strong></p>
<ul>
<li><strong>Microsoft commoditized PC hardware</strong> by licensing its
OS to many manufacturers, making the PC itself a commodity and
increasing demand for MS-DOS.</li>
<li><strong>IBM commoditized the add-in market</strong> by using
off-the-shelf parts and documenting the interfaces, allowing other
manufacturers to produce add-on cards for their PCs, which increased the
demand for PCs.</li>
<li><strong>Netscape open-sourced its web browser</strong> to
commoditize browsers and increase demand for its server software.</li>
<li><strong>Various companies contribute to open-source
software</strong> to commoditize software and increase demand for
hardware and IT consulting services.</li>
<li><strong>Sun developed Java</strong> to make hardware more of a
commodity.</li>
<li><strong>The Open Game License (OGL)</strong> was created to
commoditize the <em>Dungeons and Dragons</em> system and drive sales of
core rulebooks.</li>
</ul></li>
<li><p><strong>Open Source as a Strategic Weapon:</strong></p>
<p>Open source can be a way for companies to commoditize their
complements. It allows companies to share development costs and compete
with dominant players. It can also neutralize advantages held by
competitors and shift the focus of competition. Open sourcing can
prevent a single company from locking up a technology.</p></li>
<li><p><strong>Generalization:</strong></p>
<p>Many products are composed of layers, each necessary but not
sufficient for the final product. The final product is valuable, but the
distribution of revenue among the different layers is contentious.
Commoditizing complements is a way to control the market without
vertical integration. The division of revenue is influenced by power
plays and market dynamics.</p></li>
<li><p><strong>Additional Examples:</strong></p>
<p>The sources list many examples of commoditization in various
industries, including hardware vs. software, banks vs. merchants, apps
vs. OSes, game portals vs. game devs, telecom vs. users, and many more.
The examples illustrate the breadth of this strategy across various tech
and non-tech sectors. There are examples of companies commoditizing
themselves, such as Stability AI, who commoditized image-generation
models and saw little profit themselves.</p></li>
<li><p><strong>Counter-Examples:</strong></p>
<ul>
<li>Sun Microsystems' strategy of making both hardware and software a
commodity was not successful.</li>
<li>Some companies, like Apple, try to control both the hardware and
software aspects of their products, which goes against the
commoditization strategy.</li>
</ul></li>
<li><p><strong>Other Factors:</strong></p>
<p>Antitrust actions can influence companies and prevent them from
crushing competitors. Fear of antitrust actions may have stopped
Microsoft from crushing Google.</p></li>
<li><p><strong>Consequences</strong>:</p>
<p>The commoditization of complements can lead to intense competition in
certain layers of the tech stack. It can also lead to a concentration of
power and revenue in the hands of companies that control key
chokepoints.</p></li>
</ul>
<h2 id="reports-and-papers">Reports and Papers</h2>
<blockquote>
<p><strong>Mixtral of Experts</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.04088">Link</a>]</p>
</blockquote>
<p>Key innovation: Sparse Mixture of Experts (SMoE) with TopK=2.</p>
<blockquote>
<p><strong>The state of Generative AI and Machine Learning at the end of
2023 - Intel Tiber AI Studio</strong> [<a
target="_blank" rel="noopener" href="https://cnvrg.io/ml-insider-results-2023/?utm_source=alphasignal&amp;utm_medium=newsletter&amp;utm_campaign=ml+insider">Link</a>]</p>
</blockquote>
<p>Trends and insights of AI development and deployment in the
enterprise - a survey result.</p>
<blockquote>
<p><strong>Does Prompt Formatting Have Any Impact on LLM
Performance?</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2411.10541">Link</a>]</p>
</blockquote>
<p>Prompt formats significantly affect LLM performance, with differences
as high as 40% observed in code translation tasks for GPT-3.5-turbo.
Larger models like GPT-4 demonstrate more resilience to prompt format
changes.</p>
<p>JSON format outperformed Markdown in certain tasks, boosting accuracy
by 42%. GPT-4 models exhibited higher consistency in responses across
formats compared to GPT-3.5 models.</p>
<blockquote>
<p><strong>Deliberative Alignment: Reasoning Enables Safer Language
Models</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.16339">Link</a>]</p>
</blockquote>
<p>Their training methodology has two stages: 1) supervised fine-tuning
on (prompt, CoT, output) datasets where CoTs explicitly reference safety
policies, 2) high-compute RL using a reward model informed by safety
policies, improving reasoning and adherence.</p>
<figure>
<img src="/di-blog/2025/01/04/2025-January/deliberative_alignment.png"
alt="deliberative_alignment" />
<figcaption aria-hidden="true">deliberative_alignment</figcaption>
</figure>
<blockquote>
<p><em>Genesis is a comprehensive physics simulation platform designed
for general purpose Robotics, Embodied AI, &amp; Physical AI
applications. It is simultaneously multiple things:</em></p>
<ul>
<li><em>A universal physics engine re-built from the ground up, capable
of simulating a wide range of materials and physical
phenomena.</em></li>
<li><em>A lightweight, ultra-fast, pythonic, and user-friendly robotics
simulation platform.</em></li>
<li><em>A powerful and fast photo-realistic rendering system.</em></li>
<li><em>A generative data engine that transforms user-prompted natural
language description into various modalities of data.</em></li>
</ul>
<p><strong>― Genesis: A Generative and Universal Physics Engine for
Robotics and Beyond</strong> [<a
target="_blank" rel="noopener" href="https://genesis-embodied-ai.github.io/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Agents - Julia Wiesinger, Patrick Marlow, and Vladimir
Vuskovic - Google</strong> [<a
target="_blank" rel="noopener" href="https://drive.google.com/file/d/1oEjiRCTbd54aSdB_eEe3UShxLBWK9xkt/view">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Agent AI: Surveying the Horizons of Multimodal
Interaction</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2401.03568">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Foundations of Large Language Models</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/pdf/2501.09223">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Atlas of Gray Matter Volume Differences Across Psychiatric
Conditions: A Systematic Review With a Novel Meta-Analysis That
Considers Co-Occurring Disorders</strong> [<a
target="_blank" rel="noopener" href="https://www.sciencedirect.com/science/article/pii/S0006322324017293#sec3">Link</a>]</p>
</blockquote>
<p>"Gray matter volume (GMV) differences across major mental disorders"
refers to variations in the amount or density of gray matter in the
brain when comparing individuals with mental disorders to those without.
Gray matter consists of neuronal cell bodies, dendrites, and synapses
and is essential for processing information, controlling movements, and
supporting higher cognitive functions like memory, attention, and
decision-making.</p>
<p><strong>Structural Abnormalities</strong>: Mental disorders are often
associated with changes in the brain's structure. GMV differences can
highlight specific brain regions that are smaller, larger, or
differently shaped in individuals with mental disorders.</p>
<p><strong>Neurobiological Insights</strong>: Identifying GMV changes
helps researchers understand the neurobiological basis of mental
disorders and how these changes may contribute to symptoms like mood
dysregulation, cognitive impairment, or altered behavior.</p>
<p><strong>Target for Interventions</strong>: Understanding these
differences can inform treatments such as targeted therapies,
neurostimulation, or cognitive training to address the affected brain
regions.</p>
<blockquote>
<p><strong>From Efficiency Gains to Rebound Effects: The Problem of
Jevons’ Paradox in AI’s Polarized Environmental Debate</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.16548">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via
Reinforcement Learning</strong> [<a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.12948">Link</a>]</p>
</blockquote>
<p>DeepSeek-R1 is an open-source reasoning model that matches OpenAI-o1
in math, reasoning, and code tasks.</p>
<h2 id="news">News</h2>
<blockquote>
<p><strong>NVIDIA Project DIGITS, A Grace Blackwell AI Supercomputer on
your desk - NVIDIA</strong> [<a
target="_blank" rel="noopener" href="https://www.nvidia.com/en-us/project-digits/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Constellation inks $1 billion deal to supply US government
with nuclear power - Yahoo</strong> [<a
target="_blank" rel="noopener" href="https://finance.yahoo.com/news/constellation-secures-1-billion-contracts-154447132.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly9zdWJzdGFjay5jb20v&amp;guce_referrer_sig=AQAAAB8KGM1c2Hoot4gsRD6v4xoHeHMYfu-vMzHMF8z5iJayPDPoaH0OeKiFQ3r0ORie_l9_FVbSeGIoJebg9sJ7Et8CFvDV3M14yxsop0E427ezu6aGm_mb6iQgaCaICBiH_exivFtpSvEoU_LNPjB1UQsaTtKZa2R6T2tuBdF78n1k">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Why 2025 will be the year of AI orchestration</strong> [<a
target="_blank" rel="noopener" href="https://venturebeat.com/ai/three-ways-2025-will-be-the-year-of-agentic-productivity/">Link</a>]</p>
</blockquote>
<p>2025 is anticipated to be the year of AI orchestration for several
reasons:</p>
<ul>
<li>In 2024, there was broad experimentation in AI, particularly with
agentic use cases. In 2025, these pilot programs, experiments, and new
use cases are expected to converge, leading to a greater focus on return
on investment.</li>
<li>As organizations deploy more AI agents into their workflows, the
need for infrastructure to manage them becomes more critical. This
includes managing both internal workflows and those that interact with
other services.</li>
<li>Decision-makers, especially those outside of the technology sector,
are seeking tangible results from their AI investments. They are moving
beyond experimentation and expect to see a return on their investment in
2025.</li>
<li>There will be a greater emphasis on productivity, which involves
understanding how multiple agents can be made more effective. This will
require a focus on accuracy and achieving higher productivity.</li>
<li>Many new orchestration options are emerging to address the
limitations of existing tools such as LangChain. Companies are building
orchestration layers to manage AI applications. These frameworks are
still early in development, and the field is expected to grow.</li>
<li>There will be a focus on integrating agents across different systems
and platforms, such as AWS's Bedrock and Slack, to allow for the
transfer of context between platforms.</li>
<li>The emergence of powerful reasoning models like OpenAI's o3 and
Google's Gemini 2.0 will make orchestrator agents more powerful.</li>
</ul>
<blockquote>
<p><strong>Perplexity AI makes a bid to merge with TikTok U.S. -
CNBC</strong> [<a
target="_blank" rel="noopener" href="https://www.cnbc.com/2025/01/18/perplexity-ai-makes-a-bid-to-merge-with-tiktok-us.html">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>OpenAI, Alphabet Inc.’s Google, AI media company Moonvalley and
several other AI companies are collectively paying hundreds of content
creators for access to their unpublished videos, according to people
familiar with the negotiations.</em></p>
<p><strong>― YouTubers Are Selling Their Unused Video Footage to AI
Companies - Bloomberg</strong> [<a
target="_blank" rel="noopener" href="https://www.bloomberg.com/news/articles/2025-01-10/youtubers-are-selling-their-unused-video-footage-to-ai-companies?embedded-checkout=true">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Stavridis says Trump’s plan for Greenland ‘not a crazy idea’
- The Hill</strong> [<a
target="_blank" rel="noopener" href="https://thehill.com/policy/international/5081040-stavridis-says-trumps-plan-for-greenland-not-a-crazy-idea/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>California’s Wildfire Insurance Catastrophe - WSJ</strong>
[<a
target="_blank" rel="noopener" href="https://www.wsj.com/opinion/california-fires-los-angeles-insurance-regulation-premiums-risk-fair-victoria-roach-gavin-newsom-1306d0a1">Link</a>]</p>
</blockquote>
<p>Rising premiums and limited coverage options could significantly
impact Californians, particularly in wildfire-prone areas. The article
calls out state leadership for failing to adapt policies to address
climate-related risks effectively.</p>
<blockquote>
<p>“<em>Our robotics team is focused on unlocking general-purpose
robotics and pushing towards AG</em> –<em>level intelligence in dynamic,
real-world settings. Working across the entire model stack, we integrate
cutting-edge hardware and software to explore a broad range of robotic
form factors. We strive to seamlessly blend high-level AI capabilities
with the physical constraints of physical.</em>“</p>
<p><strong>― OpenAI has begun building out its robotics team -
VentureBeat</strong> [<a
target="_blank" rel="noopener" href="https://venturebeat.com/ai/openai-has-begun-building-out-its-robotics-team/">Link</a>]</p>
</blockquote>
<p>It's surprising because I kind of remember in a public interview Sam
said he is not going to go hardware as it's going to be as efficient on
that as those companies with hardware foundations like Tesla, NVIDIA,
Meta, etc. Now, it's hiring its first hardware robotics roles as
announced by Caitlin Kalinowski.</p>
<blockquote>
<p><strong>OpenAI’s $500B ‘Stargate Project’ could aid Pentagon’s own AI
efforts, official says - Breaking Defense</strong> [<a
target="_blank" rel="noopener" href="https://breakingdefense.com/2025/01/openais-500b-stargate-project-could-aid-pentagons-own-ai-efforts-official-says/">Link</a>]</p>
</blockquote>
<p>This article highlights OpenAI's ambitious Stargate Project and its
potential impact on both commercial and government sectors, particularly
the U.S. Department of Defense (DoD). Stargate represents a bold step in
building the next generation of AI infrastructure, and its success could
profoundly influence the future of both private AI development and
national security capabilities. The collaboration between industry
leaders and government stakeholders will be key to overcoming technical
and financial hurdles.</p>
<p>Here are key takeaways:</p>
<p><strong>OpenAI's Stargate Project:</strong></p>
<ul>
<li><strong>Objective:</strong> Build $500 billion worth of AI
infrastructure, including new data centers and power solutions,
primarily aimed at training and operating large AI models.</li>
<li><strong>Initial Funding:</strong> $100 billion to be deployed
immediately, with ongoing development starting in Texas and other
potential sites in the U.S.</li>
<li><strong>Collaborators:</strong> Japan-based SoftBank, Oracle,
UAE-based MGX, NVIDIA, Microsoft, and Arm.</li>
</ul>
<p><strong>DoD Implications:</strong></p>
<ul>
<li><strong>AI Challenges in Defense:</strong> The DoD faces significant
bottlenecks in computing power to meet the demands of modern AI
applications, from battlefield decision-making to intelligence analysis
and coordinating multi-domain operations (CJADC2).</li>
<li><strong>Reliance on Private Sector:</strong> Stargate could provide
essential computing power to address the Pentagon's high-tech needs,
especially where DoD lacks in-house capacity.</li>
<li><strong>Field Applications:</strong> Supercomputing resources are
essential for training and retraining AI models in dynamic environments,
such as battlefield conditions where new inputs may arise.</li>
</ul>
<p><strong>Challenges:</strong></p>
<ul>
<li><strong>Energy Demands:</strong> Generative AI models like ChatGPT
consume immense electricity. The DoD must consider scalable and portable
power sources, such as compact nuclear plants.</li>
<li><strong>Funding Scrutiny:</strong> Despite public commitments,
concerns about the financial capability of Stargate’s backers, including
SoftBank, have raised questions.</li>
<li><strong>Technical Constraints:</strong> Effective use of AI in
military applications depends on robust, secure, and reliable
infrastructure to handle high-bandwidth connections and avoid
vulnerabilities to jamming.</li>
</ul>
<p><strong>Political and Economic Context:</strong></p>
<ul>
<li>The Stargate Project was announced at a high-profile White House
event, underscoring its perceived importance to national interests.</li>
<li>Skepticism from figures like Elon Musk about the financial
feasibility of such an enormous project adds to the intrigue surrounding
its rollout.</li>
</ul>
<blockquote>
<p><strong>Trump is planning 100 executive orders starting Day 1 on
border, deportations and other priorities - AP News</strong> [<a
target="_blank" rel="noopener" href="https://apnews.com/article/trump-day-one-border-executive-actions-30f78c3c983ae74555f281446fe22710">Link</a>]</p>
</blockquote>
<blockquote>
<p><em>A new neural-network architecture developed by researchers at
Google might solve one of the great challenges for large language models
(LLMs): extending their memory at inference time without exploding the
costs of memory and compute. Called <a
target="_blank" rel="noopener" href="https://arxiv.org/abs/2501.00663">Titans</a>, the architecture
enables models to find and store during inference small bits of
information that are important in long sequences.</em></p>
<p><em>Titans combines traditional LLM attention blocks with “neural
memory” layers that enable models to handle both short- and long-term
memory tasks efficiently. According to the researchers, LLMs that use
neural long-term memory can scale to millions of tokens and outperform
both classic LLMs and alternatives such as Mamba while having many fewer
parameters.</em></p>
<p><strong>― Google’s new neural-net LLM architecture separates memory
components to control exploding costs of capacity and compute</strong>
[<a
target="_blank" rel="noopener" href="https://venturebeat.com/ai/googles-new-neural-net-architecture-separates-memory-components-to-control-exploding-costs/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>TikTok restoring service after Trump vows to delay ban -
AXIOS</strong> [<a
target="_blank" rel="noopener" href="https://www.axios.com/2025/01/19/trump-tiktok-ban-delay-executive-order">Link</a>]</p>
<p><strong>TikTok's response to the Supreme Court decision</strong> [<a
target="_blank" rel="noopener" href="https://www.axios.com/2025/01/19/trump-tiktok-ban-delay-executive-order">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Amazon bought more renewable power last year than any other
company - TechCrunch</strong> [<a
target="_blank" rel="noopener" href="https://techcrunch.com/2025/01/17/amazon-bought-more-renewable-power-last-year-than-any-other-company/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly9zdWJzdGFjay5jb20v&amp;guce_referrer_sig=AQAAANgCe1tykMadeEH0yFtH9v_1g1GHsiJbFLgO77KwSQXHCpKAtX9XhhHufD_tUMK3Ekb7DDCuCQkjjoKJGv82u-C33K3kS5qyquoxotmWs7jRHfA7ppjxj3_HtivS7GDsqSk-PuXlj-G7s58VcuPCq-DR88TNQcyMK1mUSqcHD9Oc">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Ozempic, Wegovy and other drugs are among 15 selected for
Medicare’s price negotiations</strong> [<a
target="_blank" rel="noopener" href="https://apnews.com/article/drug-prices-medicare-biden-trump-aae2271614f5959b484e5f081313f2e1">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Waymo Finds a Way Around US Restrictions Targeting Chinese
Cars</strong> [<a
target="_blank" rel="noopener" href="https://www.wired.com/story/waymo-finds-a-way-around-us-restrictions-on-chinese-evs/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>More Speech and Fewer Mistakes - Meta News</strong> [<a
target="_blank" rel="noopener" href="https://about.fb.com/news/2025/01/meta-more-speech-fewer-mistakes/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>NVIDIA Cosmos - NVIDIA</strong> [<a
target="_blank" rel="noopener" href="https://www.nvidia.com/en-in/ai/cosmos/">Link</a>]</p>
</blockquote>
<blockquote>
<p><strong>Announcing The Stargate Project - OpenAI</strong> [<a
target="_blank" rel="noopener" href="https://openai.com/index/announcing-the-stargate-project/">Link</a>]</p>
</blockquote>
<p>OpenAI announces the Stargate Project, a <span
class="math inline">\(\$500\)</span> billion effort to create advanced
AI infrastructure. The project begins with an immediate <span
class="math inline">\(\$100\)</span> billion deployment for data
centers, starting in Texas. It supports OpenAI’s goal of scaling
artificial general intelligence (AGI) and training advanced AI models.
Focus on high-value fields like personalized medicine and
biotechnology.</p>
<p>NVIDIA GPUs power compute-intensive workloads. Oracle provides
high-capacity cloud infrastructure. Microsoft Azure supports scalable
distributed AI model training.</p>
<blockquote>
<p><strong>Introducing Operator - OpenAI</strong> [<a
target="_blank" rel="noopener" href="https://openai.com/index/introducing-operator/">Link</a>]</p>
</blockquote>
<p>It's an AI agent that automates tasks directly in a web browser. You
can use Operator to complete repetitive tasks like filling out forms,
booking travel, or ordering items online. It uses a new model called
Computer-Using Agent (CUA), which integrates GPT-4's vision capabilities
with reinforcement learning to interact with graphical user interfaces
(GUIs).</p>
<blockquote>
<p><strong>Introducing Citations on the Anthropic API -
Anthropic</strong> [<a
target="_blank" rel="noopener" href="https://www.anthropic.com/news/introducing-citations-api">Link</a>]</p>
</blockquote>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/di-blog/tags/readings/" rel="tag"># readings</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/di-blog/2024/12/29/Understanding-RLHF/" rel="prev" title="Understanding RLHF">
                  <i class="fa fa-angle-left"></i> Understanding RLHF
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/di-blog/2025/01/24/Persisting-Agent-State/" rel="next" title="Persisting Agent State">
                  Persisting Agent State <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Di Zhen</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/di-blog/js/comments.js"></script><script src="/di-blog/js/utils.js"></script><script src="/di-blog/js/motion.js"></script><script src="/di-blog/js/sidebar.js"></script><script src="/di-blog/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/di-blog/js/third-party/math/mathjax.js"></script>



</body>
</html>
